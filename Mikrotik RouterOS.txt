

    Creado por Māris B., actualizado por última vez por Edgars P. el abr 08, 2025 26 min de lectura

    Introduction
    Switch Configuration
        Switch Port Configuration
        L3HW Settings
            Basic Settings
            Advanced Settings
            Monitor
            Advanced Monitor
        Interface Lists
        MTU
        Layer 2 Dependency
        MAC telnet
        Inter-VLAN Routing
        L3HW MAC Address Range Limitation (DX2000/DX3000 series only)
    Route Configuration
        Suppressing HW Offload
        Routing Filters
        Offloading Fasttrack Connections
        Stateless Hardware Firewall
        Switch Rules (ACL) vs. Fasttrack HW Offloading
    Configuration Examples
        Inter-VLAN Routing with Upstream Port Behind Firewall/NAT
    Typical Misconfiguration
        VLAN interface on a switch port or bond
        Not adding the bridge interface to /interface/bridge/vlan/
        Creating multiple bridges
        Using ports that do not belong to the switch
        Relying on Fasttrack HW Offloading too much
        Trying to offload slow-path connections
    L3HW Feature Support
    L3HW Device Support
        CRS3xx: Switch DX3000 and DX2000 Series
            Partial offloading
        CCR2xxx, CRS3xx, CRS5xx: Switch DX8000 and DX4000 Series
            Partial offloading

Introduction

Layer 3 Hardware Offloading (L3HW, otherwise known as IP switching or HW routing) allows to offload some router features onto the switch chip. This allows reaching wire speeds when routing packets, which would simply not be possible with the CPU. 
Switch Configuration

To enable Layer 3 Hardware Offloading, set l3-hw-offloading=yes for the switch:
/interface/ethernet/switch set 0 l3-hw-offloading=yes
Switch Port Configuration

Layer 3 Hardware Offloading can be configured for each physical switch port. For example:
/interface/ethernet/switch/port set sfp-sfpplus1 l3-hw-offloading=yes

Note that l3hw settings for switch and ports are different:

    Setting l3-hw-offloading=no for the switch completely disables offloading - all packets will be routed by CPU.
    However, setting l3-hw-offloading=no for a switch port only disables hardware routing from/to this particular port. Moreover, the port can still participate in Fastrack connection offloading. 

To enable full hardware routing, enable l3hw on all switch ports:
/interface/ethernet/switch set 0 l3-hw-offloading=yes
/interface/ethernet/switch/port set [find] l3-hw-offloading=yes

To make all packets go through the CPU first, and offload only the Fasttrack connections, disable l3hw on all ports but keep it enabled on the switch chip itself:
/interface/ethernet/switch set 0 l3-hw-offloading=yes
/interface/ethernet/switch/port set [find] l3-hw-offloading=no

Packets are routed by hardware when both the ingress and egress ports have l3-hw-offloading=yes.

If both ingress and egress ports have l3-hw-offloading=no, packets will go through the CPU/Firewall while offloading only the Fasttrack connections.

It is possible to direct packets to go through the CPU/Firewall by setting l3-hw-offloading=no on just the egress port. However, setting l3-hw-offloading=no only the ingress port may cause unpredictable behavior, for example, packets might still be routed by hardware and completely bypass the CPU/firewall. 

The next example enables hardware routing on all ports but the upstream port (sfp-sfpplus16). Packets going to/from sfp-sfpplus16 will enter the CPU and, therefore, subject to Firewall/NAT processing.
/interface/ethernet/switch set 0 l3-hw-offloading=yes
/interface/ethernet/switch/port set [find] l3-hw-offloading=yes
/interface/ethernet/switch/port set sfp-sfpplus16 l3-hw-offloading=no

The existing connections may be unaffected by the l3-hw-offloading setting change.
L3HW Settings
Basic Settings

The L3HW Settings menu has been introduced in RouterOS version 7.6.

Sub-menu: /interface ethernet switch l3hw-settings
autorestart (yes | no; Default: no)	Automatically restarts the l3hw driver in case of an error. Otherwise, if an error occurs, l3-hw-offloading gets disabled, and the error code is displayed in the switch settings and #monitor. Autorestart does not work for system failures, such as OOM (Out Of Memory).
fasttrack-hw (yes | no; Default: yes (if supported))	Enables or disables FastTrack HW Offloading. Keep it enabled unless HW TCAM memory reservation is required, e.g., for dynamic switch ACL rules creation. Not all switch chips support FastTrack HW Offloading (see hw-supports-fasttrack).
ipv6-hw (yes | no; Default: no)	Enables or disables IPv6 Hardware Offloading. Since IPv6 routes occupy a lot of HW memory, enable it only if IPv6 traffic speed is significant enough to benefit from hardware routing.
icmp-reply-on-error (yes | no; Default: yes)	Since the hardware cannot send ICMP messages, the packet must be redirected to the CPU to send an ICMP reply in case of an error (e.g., "Time Exceeded", "Fragmentation required", etc.). Enabling icmp-reply-on-error helps with network diagnostics but may open potential vulnerabilities for DDoS attacks. Disabling icmp-reply-on-error silently drops the packets on the hardware level in case of an error.

Read-Only Properties
hw-supports-fasttrack (yes | no)	Indicates if the hardware (switch chip) supports FastTrack HW Offloading.
Advanced Settings

This menu allows tweaking l3hw settings for specific use cases.

It is NOT recommended to change the advanced L3HW settings unless instructed by MikroTik Support or MikroTik Certified Routing Engineer. Applying incorrect settings may break the L3HW operation.

Sub-menu: /interface ethernet switch l3hw-settings advanced
route-queue-limit-high (number; Default: 256)	

The switch driver stops route indexing when route-queue-size (see #monitor) exceeds this value. Lowering this value leads to faster route processing but increases the lag between a route's appearance in RouterOS and hardware memory.

Setting route-queue-limit-high=0 disables route indexing when there are any routes in the processing queue -  the most efficient CPU usage but the longest delay before hardware offloading. Useful when there are static routes only. Not recommended together with routing protocols (such as BGP or OSPF) when there are frequent routing table changes.
route-queue-limit-low (number; Default: 0)	

Re-enable route indexing when route-queue-size drops down to this value. Must not exceed the high limit.

Setting route-queue-limit-low=0 tells the switch driver to process all pending routes before the next hw-offloading attempt. While this is the desired behavior, it may completely block the hw-offloading under a constant BGP feed.
shwp-reset-counter  (number; Default: 128)	

Reset the Shortest HW Prefix (see ipv4-shortest-hw-prefix / ipv6-shortest-hw-prefix in #monitor) and try the full route table offloading after this amount of changes in the routing table. At a partial offload, when the entire routing table does not fit into the hardware memory and shorter prefixes are redirected to the CPU, there is no need to try offloading route prefixes shorter than SHWP since those will get redirected to the CPU anyway, theoretically. However, significant changes to the routing table may lead to a different index layout and, therefore, a different amount of routes that can be hw-offloaded. That's why it is recommended to do the full table re-indexing occasionally.

Lowering this value may allow more routes to be hw-offloaded but increases CPU usage and vice-versa. Setting shwp-reset-counter=0 always does full re-indexing after each routing table change.

This setting is used only during Partial Offloading and has no effect when ipv4-shortest-hw-prefix=0 (and ipv6, respectively).
partial-offload-chunk (number; Default: 1024, min: 16)	

The minimum number of routes for incremental adding in Partial Offloading. Depending on the switch chip model, routes are offloaded either as-is (each routing entry in RouterOS corresponds to an entry in the hardware memory) or getting indexed, and the index entries are the ones that are written into the hardware memory. This setting is used only for the latter during Partial Offloading.

Depending on index fragmentation, a single IPv4 route addition can occupy from -3 to +6 LPM blocks of HW memory (some route addition may lower the amount of required HW memory thanks to index defragmentation). Hence, it is impossible to predict the exact number of routes that may fit in the hardware memory. The switch driver uses a binary split algorithm to find the maximum number of routes that fit in the hardware.

Let's imagine 128k routes, all of them not fitting into the hardware memory. The algorithm halves the number and tries offloading 64k routes. Let's say offloading succeeded. In the next iteration, the algorithm picks 96k, let's say it fails; then 80k - fails again, 72k - succeeds, 76k, etc. until the difference between succeeded and failed numbers drops below the partial-offload-chunk value.

Lowering the partial-offload-chunk value increases the number of hw-offloaded routes but also raises CPU usage and vice-versa.
route-index-delay-min (time; Default: 1s)	

The minimum delay between route processing and its offloading. The delay allows processing more routes together and offloading them at once, saving CPU usage. It also makes offloading the entire routing table faster by reducing the per-route processing work. On the other hand, it slows down the offloading of an individual route.

If an additional route is received during the delay, the latter resets to the route-index-delay-min value. Adding more and more routes within the delay keeps resetting the timer until the route-index-delay-max is reached.
route-index-delay-max (time; Default: 10s)	

The maximum delay between route processing and its offloading. When the maximum delay is reached, the processed routes get offloaded despite more routes pending. However, route-queue-limit-high has higher priority than this, meaning that the indexing/offloading gets paused anyway when a certain queue size is reached.
neigh-keepalive-interval (time; Default: 15s, min: 5s)	

Neighbor (host) keepalive interval. When a host (IP neighbor) gets hw-offloaded, all traffic from/to it is routed by the switch chip, and RouterOS may think the neighbor is inactive and delete it. To prevent that, the switch driver must keep the offloaded neighbors alive by sending periodical refreshes to RouterOS.
neigh-discovery-interval (time; Default: 1m37s, min: 30s)	

Unfortunately, switch chips do not provide per-neighbor stats. Hence, the only way to check if the offloaded host is still active is by sending occasional ARP (IPv4) / Neighbor Discovery (IPv6) requests to the connected network. Increasing the value lowers the broadcast traffic but may leave inactive hosts in hardware memory for longer.

Neighbor discovery is triggered within the neighbor keepalive work. Hence, the discovery time is rounded up to the next keepalive session. Choose a value for neigh-discovery-interval not dividable by neigh-keepalive-interval to send ARP/ND requests in various sessions, preventing broadcast bursts.
neigh-discovery-burst-limit (number; Default: 64)	

The maximum number of ARP/ND requests that can be sent at once.
neigh-discovery-burst-delay (time; Default: 300ms, min: 10ms)	

The delay between ARP/ND subsequent bursts if the number of requests exceeds neigh-discovery-burst-limit.


Some settings only apply to certain switch models.
Monitor

The L3HW Monitor feature has been introduced in RouterOS version 7.10. It allows monitoring of switch chip and driver stats related to L3HW. 
/interface/ethernet/switch/l3hw-settings/monitor
        ipv4-routes-total: 99363
           ipv4-routes-hw: 61250
          ipv4-routes-cpu: 38112
  ipv4-shortest-hw-prefix: 24
               ipv4-hosts: 87
        ipv6-routes-total: 15
           ipv6-routes-hw: 11
          ipv6-routes-cpu: 4
  ipv6-shortest-hw-prefix: 0
               ipv6-hosts: 7
         route-queue-size: 118
     fasttrack-ipv4-conns: 2031
   fasttrack-hw-min-speed: 0
              nexthop-cap: 8192
            nexthop-usage: 93
    vxlan-mtu-packet-drop: 0

Stats
ipv4-routes-total	The total number of IPv4 routes handled by the switch driver.
ipv4-routes-hw	The number of hardware-offloaded IPv4 routes (a.k.a. hardware routes)
ipv4-routes-cpu	The number of IPv4 routes redirected to the CPU (a.k.a. software routes)
ipv4-shortest-hw-prefix	Shortest Hardware Prefix (SHWP) for IPv4. If the entire IPv4 routing table does not fit into the hardware memory, partial offloading is applied, where the longest prefixes are hw-offloaded while the shorter ones are redirected to the CPU. This field shows the shortest route prefix (/x) that is offloaded to the hardware memory. All prefixes shorter than this are processed by the CPU. "ipv4-shortest-hw-prefix=0" means the entire IPv4 routing table is offloaded to the hardware memory.
ipv4-hosts	The number of hardware-offloaded IPv4 hosts (/32 routes)
ipv6-routes-total 1	The total number of IPv6 routes handled by the switch driver.
ipv6-routes-hw 1	The number of hardware-offloaded IPv6 routes (a.k.a. hardware routes)
ipv6-routes-cpu 1	The number of IPv6 routes redirected to the CPU (a.k.a. software routes)
ipv6-shortest-hw-prefix 1	Shortest Hardware Prefix (SHWP) for IPv6. If the entire IPv6 routing table does not fit into the hardware memory, partial offloading is applied, where the longest prefixes are hw-offloaded while the shorter ones are redirected to the CPU. This field shows the shortest route prefix (/x) that is offloaded to the hardware memory. All prefixes shorter than this are processed by the CPU. "ipv6-shortest-hw-prefix=0" means the entire IPv6 routing table is offloaded to the hardware memory.
ipv6-hosts 1	The number of hardware-offloaded IPv6 hosts (/128 routes)
route-queue-size	The number of routes in the queue for processing by the switch chip driver. Under normal working conditions, this field is 0, meaning that all routes are processed by the driver.
nexthop-cap	The nexthop capacity.
nexthop-usage	The number of currently used nexthops.
vxlan-mtu-packet-drop	The number of dropped VXLAN packets due to exceeded interface MTU settings.
fasttrack-ipv4-conns 2	The number of hardware-offloaded FastTrack connections.
fasttrack-hw-min-speed 2	When the hardware memory for storing FastTrack is full, this field shows the minimum speed (in bytes per second) of a hw-offloaded FastTrack connection. Slower connections are routed by the CPU.

1 IPv6 stats appear only when IPv6 hardware routing is enabled (ipv6-hw=yes)

2 FastTrack stats appear only when hardware offloading of FastTrack connections is enabled (fasttrack-hw=yes)
Advanced Monitor

An enhanced version of Monitor with extra telemetry data for advanced users. Advanced Monitor contains all data from the basic monitor plus the fields listed below.
/interface/ethernet/switch/l3hw-settings/advanced> monitor once
        ipv4-routes-total: 29968
           ipv4-routes-hw: 29957
          ipv4-routes-cpu: 11
  ipv4-shortest-hw-prefix: 0
               ipv4-hosts: 3
        ipv6-routes-total: 4
           ipv6-routes-hw: 0
          ipv6-routes-cpu: 4
  ipv6-shortest-hw-prefix: 0
               ipv6-hosts: 0
         route-queue-size: 0
         route-queue-rate: 0
       route-process-rate: 0
     fasttrack-ipv4-conns: 0
     fasttrack-queue-size: 0
     fasttrack-queue-rate: 0
   fasttrack-process-rate: 0
   fasttrack-hw-min-speed: 0
   fasttrack-hw-offloaded: 0
    fasttrack-hw-unloaded: 0
                  lpm-cap: 54560
                lpm-usage: 31931
             lpm-bank-cap: 2728
           lpm-bank-usage: 46,0,0,0,2589,2591,1983,0,2728,2728,2728,2728,2728,2728,2728,2728,2728,170,0,0
                  pbr-cap: 8192
                pbr-usage: 0
             pbr-lpm-bank: 3
                nat-usage: 0
              nexthop-cap: 8192
            nexthop-usage: 85

Stats
route-queue-rate	The rate at which routes are added to the queue for the switch driver processing. In other words, the growth rate of route-queue-size (routes per second)
route-process-rate	The rate at which previously queued routes are processed by the switch driver. In other words, the shrink rate of route-queue-size (routes per second)
fasttrack-queue-size	The number of FastTrack connections in the queue for processing by the switch chip driver.
fasttrack-queue-rate	The rate at which FastTrack connections are added to the queue for the switch driver processing. In other words, the growth rate of fasttrack-queue-size (connections per second)
fasttrack-process-rate	The rate at which previously queued FastTrack connections are processed by the switch driver. In other words, the shrink rate of fasttrack-queue-size (connections per second)
fasttrack-hw-offloaded	The number of FastTrack connections offloaded to the hardware. The counter resets every second (or every monitor interval).
fasttrack-hw-unloaded	The number of FastTrack connections unloaded from the hardware (redirected to software routing). The counter resets every second (or every monitor interval).
lpm-cap	The size of the LPM hardware table (LPM = Longest Prefix Match). LPM stores route indexes for hardware routing. Not every switch chip model uses LPM. Others use TCAM.
lpm-usage	The number of used LPM blocks. lpm-usage / lpm-cap = usage percentage.
lpm-bank-cap	LPM memory is organized in banks - special memory units. The bank size depends on the switch chip model. This value shows the size of a single bank (in LPM blocks). lpm-cap / lpm-bank-cap = the number of banks (usually, 20).
lpm-bank-usage	Per-bank LPM usage (in LPM blocks)
pbr-cap	The size of the Policy-Based Routing (PBR) hardware table. PBR is used for NAT offloading of FastTrack connections.
pbr-usage	The number of used PBR entries. pbr-usage / pbr-cap = usage percentage.
pbr-lpm-bank	PBR shares LPM memory banks with routing tables. This value shows the LPM bank index shared with PBR (0 = the first bank).
nat-usage	The number of used NAT hardware entries (for FastTrack connections).
Interface Lists

It is impossible to use interface lists directly to control l3-hw-offloading because an interface list may contain virtual interfaces (such as VLAN) while the l3-hw-offloading setting must be applied to physical switch ports only. For example, if there are two VLAN interfaces (vlan20 and vlan30) running on the same switch port (trunk port), it is impossible to enable hardware routing on vlan20 but keep it disabled on vlan30.

However, an interface list may be used as a port selector. The following example demonstrates how to enable hardware routing on LAN ports (ports that belong to the "LAN" interface list) and disable it on WAN ports:
:foreach i in=[/interface/list/member/find where list=LAN] do={
    /interface/ethernet/switch/port set [/interface/list/member/get $i interface] l3-hw-offloading=yes
}

:foreach i in=[/interface/list/member/find where list=WAN] do={
    /interface/ethernet/switch/port set [/interface/list/member/get $i interface] l3-hw-offloading=no
}

Please take into account that since interface lists are not directly used in hardware routing control., modifying the interface list also does not automatically reflect in l3hw changes. For instance, adding a switch port to the "LAN" interface list does not automatically enable l3-hw-offloading on it. The user has to rerun the above script to apply the changes.
MTU

The hardware supports up to 8 MTU profiles, meaning that the user can set up to 8 different MTU values for interfaces: the default 1500 + seven custom ones.
It is recommended to disable l3-hw-offloading while changing the MTU/L2MTU values on the interfaces.
MTU Change Example
/interface/ethernet/switch set 0 l3-hw-offloading=no
/interface set sfp-sfpplus1 mtu=9000 l2mtu=9022
/interface set sfp-sfpplus2 mtu=9000 l2mtu=9022
/interface set sfp-sfpplus3 mtu=10000 l2mtu=10022
/interface/ethernet/switch set 0 l3-hw-offloading=yes
Layer 2 Dependency

Layer 3 hardware processing lies on top of Layer 2 hardware processing. Therefore, L3HW offloading requires L2HW offloading on the underlying interfaces. The latter is enabled by default, but there are some exceptions. For example, CRS3xx devices support only one hardware bridge. If there are multiple bridges, others are processed by the CPU and are not subject to L3HW. 

Another example is ACL rules. If a rule redirects traffic to the CPU for software processing, then hardware routing (L3HW) is not triggered:
ACL rule to disable hardware processing on a specific port
/interface/ethernet/switch/rule/add switch=switch1 ports=ether1 redirect-to-cpu=yes
It is recommended to turn off L3HW offloading during L2 configuration.

To make sure that Layer 3 is in sync with Layer 2 on both the software and hardware sides, we recommend disabling L3HW while configuring Layer 2 features. The recommendation applies to the following configuration:

    adding/removing/enabling/disabling bridge;
    adding/removing switch ports to/from the bridge;
    bonding switch ports / removing bond;
    changing VLAN settings;
    changing MTU/L2MTU on switch ports;
    changing ethernet (MAC) addresses.

In short, disable l3-hw-offloading while making changes under /interface/bridge/ and /interface/vlan/:
Layer 2 Configuration Template
/interface/ethernet/switch set 0 l3-hw-offloading=no

/interface/bridge
# put bridge configuration changes here

/interface/vlan
# define/change VLAN interfaces

/interface/ethernet/switch set 0 l3-hw-offloading=yes
MAC telnet

There is a limitation for MAC telnet when L3HW offloading is enabled on 98DX8xxx, 98DX4xxx, or 98DX325x switch chips. Packets from MAC Telnet are dropped and do not reach the CPU, thus access to the device will fail.

If MAC telnet is desired in combination with L3HW, certain ACL rule can be created to force these packets to the CPU.

For example, if MAC telnet access on sfp-sfpplus1 and sfp-sfpplus2 is needed, you will need to add this ACL rule. It is possible to select even more interfaces with the ports setting.
/interface ethernet switch rule
add dst-port=20561 ports=sfp-sfpplus1,sfp-sfpplus2 protocol=udp redirect-to-cpu=yes switch=switch1
Inter-VLAN Routing

Since L3HW depends on L2HW, and L2HW is the one that does VLAN processing, Inter-VLAN hardware routing requires a hardware bridge underneath. Even if a particular VLAN has only one tagged port member, the latter must be a bridge member. Do not assign a VLAN interface directly on a switch port! Otherwise, L3HW offloading fails and the traffic will get processed by the CPU:

/interface/vlan add interface=ether2 name=vlan20 vlan-id=20

Assign the VLAN interface to the bridge instead. This way, VLAN configuration gets offloaded to the hardware, and, with L3HW enabled, the traffic is subject to inter-VLAN hardware routing.
VLAN Configuration Example
/interface/ethernet/switch set 0 l3-hw-offloading=no
/interface/bridge/port add bridge=bridge interface=ether2
/interface/bridge/vlan add bridge=bridge tagged=bridge,ether2 vlan-ids=20
/interface/vlan add interface=bridge name=vlan20 vlan-id=20
/ip/address add address=192.0.2.1/24 interface=vlan20
/interface/bridge set bridge vlan-filtering=yes
/interface/ethernet/switch set 0 l3-hw-offloading=yes
For Inter-VLAN routing, the bridge interface must be a tagged member of every routable /interface/bridge/vlan/ entry.
L3HW MAC Address Range Limitation (DX2000/DX3000 series only)

Marvell Prestera DX2000 and DX3000 switch chips have a hardware limitation that allows configuring only the last (least significant) octet of the MAC address for each interface. The other five (most significant) octets are configured globally and, therefore, must be equal for all interfaces (switch ports, bridge, VLANs). In other words, the MAC addresses must be in the format "XX:XX:XX:XX:XX:??", where:

    "XX:XX:XX:XX:XX" part is common for all interfaces.
    "??" is a variable part.

This requirement applies only to Layer 3 (routing). Layer 2 (bridging) does not use the switch's ethernet addresses. Moreover, it does not apply to bridge ports because they use the bridge's MAC address.

The requirement for common five octets applies to:

    Standalone switch ports (not bridge members) with hardware routing enabled (l3-hw-offloading=yes).
    Bridge itself.
    VLAN interfaces (those that use the bridge's MAC address by default).

Route Configuration
Suppressing HW Offload

By default, all the routes are participating to be hardware candidate routes. To further fine-tune which traffic to offload, there is an option for each route to disable/enable suppress-hw-offload. 

For example, if we know that the majority of traffic flows to the network where servers are located, we can enable offloading only to that specific destination:
/ip/route set [find where static && dst-address!="192.168.3.0/24"] suppress-hw-offload=yes

Now only the route to 192.168.3.0/24 has H-flag, indicating that it will be the only one eligible to be selected for HW offloading:
[admin@MikroTik] > /ip/route print where static
Flags: A - ACTIVE; s - STATIC, y - COPY; H - HW-OFFLOADED
Columns: DST-ADDRESS, GATEWAY, DISTANCE
#     DST-ADDRESS       GATEWAY         D
0 As  0.0.0.0/0         172.16.2.1      1
1 As  10.0.0.0/8        10.155.121.254  1
2 AsH 192.168.3.0/24    172.16.2.1      1

H-flag does not indicate that the route is actually HW offloaded, it indicates only that the route can be selected to be HW offloaded.
Routing Filters

For dynamic routing protocols like OSFP and BGP, it is possible to suppress HW offloading using routing filters. For example, to suppress HW offloading on all OSFP instance routes, use "suppress-hw-offload yes" property:
/routing/ospf/instance
set [find name=instance1] in-filter-chain=ospf-input
/routing/filter/rule
add chain="ospf-input" rule="set suppress-hw-offload yes; accept"
Offloading Fasttrack Connections

Firewall filter rules have hw-offload option for Fasttrack, allowing fine-tuning connection offloading. Since the hardware memory for Fasttrack connections is very limited, we can choose what type of connections to offload and, therefore, benefit from near-the-wire-speed traffic. The next example offloads only TCP connections while UDP packets are routed via the CPU and do not occupy HW memory:
/ip/firewall/filter
add action=fasttrack-connection chain=forward connection-state=established,related hw-offload=yes protocol=tcp
add action=fasttrack-connection chain=forward connection-state=established,related hw-offload=no
add action=accept chain=forward connection-state=established,related
Stateless Hardware Firewall

While connection tracking and stateful firewalling can be performed only by the CPU, the hardware can perform stateless firewalling via switch rules (ACL). The next example prevents (on a hardware level) accessing a MySQL server from the ether1, and redirects to the CPU/Firewall packets from ether2 and ether3:
/interface ethernet switch rule
add switch=switch1 dst-address=10.0.1.2/32 dst-port=3306 ports=ether1 new-dst-ports=""
add switch=switch1 dst-address=10.0.1.2/32 dst-port=3306 ports=ether2,ether3 redirect-to-cpu=yes
Switch Rules (ACL) vs. Fasttrack HW Offloading

Some firewall rules may be implemented both via switch rules (ACL) and CPU Firewall Filter + Fasttrack HW Offloading. Both options grant near-the-wire-speed performance. So the question is which one to use?

First, not all devices support Fasttrack HW Offloading, and without HW offloading, Firewall Filter uses only software routing, which is dramatically slower than its hardware counterpart. Second, even if Fasttrack HW Offloading is an option, a rule of thumb is:

Always use Switch Rules (ACL), if possible.

Switch rules share the hardware memory with Fastrack connections. However, hardware resources are allocated for each Fasttrack connection while a single ACL rule can match multiple connections. For example, if you have a guest WiFi network connected to sfp-sfpplus1 VLAN 10 and you don't want it to access your internal network, simply create an ACL rule:
/interface/ethernet/switch/rule
add switch=switch1 ports=sfp-sfpplus1 vlan-id=10 dst-address=10.0.0.0/8 new-dst-ports=""

The matched packets will be dropped on the hardware level. It is much better than letting all guest packets to the CPU for Firewall filtering.

Of course, ACL rules cannot match everything. For instance, ACL rules cannot filter connection states: accept established, drop others. That is where Fasttrack HW Offloading gets into action - redirect the packets to the CPU by default for firewall filtering, then offload the established Fasttrack connections. However, disabling l3-hw-offloading for the entire switch, port is not the only option.

Define ACL rules with redirect-to-cpu=yes instead of setting l3-hw-offloading=no of the switch port for narrowing down the traffic that goes to the CPU.
Configuration Examples
Inter-VLAN Routing with Upstream Port Behind Firewall/NAT

This example demonstrates how to benefit from near-to-wire-speed inter-VLAN routing while keeping Firewall and NAT running on the upstream port. Moreover, Fasttrack connections to the upstream port get offloaded to hardware as well, boosting the traffic speed close to wire-level. Inter-VLAN traffic is fully routed by the hardware, not entering the CPU/Firewall, and, therefore, not occupying the hardware memory of Fasttrack connections.

We use the CRS317-1G-16S+ model with the following setup:

    sfp1-sfp4 - bridged ports, VLAN ID 20, untagged
    sfp5-sfp8 - bridged ports, VLAN ID 30, untagged
    sfp16 - the upstream port
    ether1 - management port


Setup interface lists for easy access:
Interface Lists
/interface list
add name=LAN
add name=WAN
add name=MGMT 

/interface list member
add interface=sfp-sfpplus1 list=LAN
add interface=sfp-sfpplus2 list=LAN
add interface=sfp-sfpplus3 list=LAN
add interface=sfp-sfpplus4 list=LAN
add interface=sfp-sfpplus5 list=LAN
add interface=sfp-sfpplus6 list=LAN
add interface=sfp-sfpplus7 list=LAN
add interface=sfp-sfpplus8 list=LAN
add interface=sfp-sfpplus16 list=WAN
add interface=ether1 list=MGMT 
Bridge Setup
/interface bridge
add name=bridge vlan-filtering=yes

/interface bridge port
add bridge=bridge interface=sfp-sfpplus1 pvid=20
add bridge=bridge interface=sfp-sfpplus2 pvid=20
add bridge=bridge interface=sfp-sfpplus3 pvid=20
add bridge=bridge interface=sfp-sfpplus4 pvid=20
add bridge=bridge interface=sfp-sfpplus5 pvid=30
add bridge=bridge interface=sfp-sfpplus6 pvid=30
add bridge=bridge interface=sfp-sfpplus7 pvid=30
add bridge=bridge interface=sfp-sfpplus8 pvid=30

/interface bridge vlan
add bridge=bridge tagged=bridge untagged=sfp-sfpplus1,sfp-sfpplus2,sfp-sfpplus3,sfp-sfpplus4 vlan-ids=20
add bridge=bridge tagged=bridge untagged=sfp-sfpplus5,sfp-sfpplus6,sfp-sfpplus7,sfp-sfpplus8 vlan-ids=30

Routing requires dedicated VLAN interfaces. For standard L2 VLAN bridging (without inter-VLAN routing), the next step can be omitted.
VLAN Interface Setup for Routing
/interface vlan
add interface=bridge name=vlan20 vlan-id=20
add interface=bridge name=vlan30 vlan-id=30

/ip address
add address=192.168.20.17/24 interface=vlan20 network=192.168.20.0
add address=192.168.30.17/24 interface=vlan30 network=192.168.30.0

Configure management and upstream ports, a basic firewall, NAT, and enable hardware offloading of Fasttrack connections:
Firewall Setup
/ip address
add address=192.168.88.1/24 interface=ether1
add address=10.0.0.17/24 interface=sfp-sfpplus16

/ip route
add gateway=10.0.0.1

/ip firewall filter
add action=fasttrack-connection chain=forward connection-state=established,related hw-offload=yes
add action=accept chain=forward connection-state=established,related

/ip firewall nat
add action=masquerade chain=srcnat out-interface-list=WAN

At this moment, all routing still is performed by the CPU. Enable hardware routing on the switch chip:
Enable Layer 3 Hardware Offloading
# Enable full hardware routing on LAN ports
:foreach i in=[/interface/list/member/find where list=LAN] do={ 
    /interface/ethernet/switch/port set [/interface/list/member/get $i interface] l3-hw-offloading=yes 
} 

# Disable full hardware routing on WAN or Management ports
:foreach i in=[/interface/list/member/find where list=WAN or list=MGMT] do={ 
    /interface/ethernet/switch/port set [/interface/list/member/get $i interface] l3-hw-offloading=no 
}

# Activate Layer 3 Hardware Offloading on the switch chip
/interface/ethernet/switch/set 0 l3-hw-offloading=yes

Results:

    Within the same VLAN (e.g., sfp1-sfp4), traffic is forwarded by the hardware on Layer 2 (L2HW).
    Inter-VLAN traffic (e.g. sfp1-sfp5) is routed by the hardware on Layer 3 (L3HW).
    Traffic from/to the WAN port gets processed by the CPU/Firewall first. Then Fasttrack connections get offloaded to the hardware (Hardware-Accelerated L4 Stateful Firewall). NAT applies both on CPU- and HW-processed packets.
    Traffic to the management port is protected by the Firewall.

Typical Misconfiguration

Below are typical user errors in configuring Layer 3 Hardware Offloading.
VLAN interface on a switch port or bond
/interface/vlan
add name=vlan10 vlan-id=10 interface=sfp-sfpplus1
add name=vlan20 vlan-id=20 interface=bond1

VLAN interface must be set on the bridge due to Layer 2 Dependency. Otherwise, L3HW will not work. The correct configuration is:
/interface/bridge/port
add bridge=bridge1 interface=sfp-sfpplus1 frame-types=admit-only-vlan-tagged
add bridge=bridge1 interface=bond1 frame-types=admit-only-vlan-tagged
 
/interface/bridge/vlan
add bridge=bridge1 tagged=bridge1,sfp-sfpplus1 vlan-ids=10
add bridge=bridge1 tagged=bridge1,bond1 vlan-ids=20
 
/interface/vlan
add name=vlan10 vlan-id=10 interface=bridge1
add name=vlan20 vlan-id=20 interface=bridge1
Not adding the bridge interface to /interface/bridge/vlan/

For Inter-VLAN routing, the bridge interface itself needs to be added to the tagged members of the given VLANs. In the next example, Inter-VLAN routing works between VLAN 10 and 11, but packets are NOT routed to VLAN 20. 
/interface bridge vlan
add bridge=bridge1 vlan-ids=10 tagged=bridge1,sfp-sfpplus1
add bridge=bridge1 vlan-ids=11 tagged=bridge1 untagged=sfp-sfpplus2,sfp-sfpplus3 
add bridge=bridge1 vlan-ids=20 tagged=sfp-sfpplus1 untagged=sfp-sfpplus4,sfp-sfpplus5

The above example does not always mean an error. Sometimes, you may want the device to act as a simple L2 switch in some/all VLANs. Just make sure you set such behavior on purpose, not due to a mistake.
Creating multiple bridges

The devices support only one hardware bridge. If there are multiple bridges created, only one gets hardware offloading. While for L2 that means software forwarding for other bridges, in the case of L3HW, multiple bridges may lead to undefined behavior.

Instead of creating multiple bridges, create one and segregate L2 networks with VLAN filtering.
Using ports that do not belong to the switch

Some devices have two switch chips or the management port directly connected to the CPU. For example, CRS312-4C+8XG has an ether9 port connected to a separate switch chip. Trying to add this port to a bridge or involve it in the L3HW setup leads to unexpected results. Leave the management port for management!
[admin@crs312] /interface/ethernet/switch> print
Columns: NAME, TYPE, L3-HW-OFFLOADING
# NAME     TYPE              L3-HW-OFFLOADING
0 switch1  Marvell-98DX8212  yes            
1 switch2  Atheros-8227      no   
           
[admin@crs312] /interface/ethernet/switch> port print
Columns: NAME, SWITCH, L3-HW-OFFLOADING, STORM-RATE
 # NAME         SWITCH   L3-HW-OFFLOADING  STORM-RATE
 0 ether9       switch2                             
 1 ether1       switch1  yes                      100
 2 ether2       switch1  yes                      100
 3 ether3       switch1  yes                      100
 4 ether4       switch1  yes                      100
 5 ether5       switch1  yes                      100
 6 ether6       switch1  yes                      100
 7 ether7       switch1  yes                      100
 8 ether8       switch1  yes                      100
 9 combo1       switch1  yes                      100
10 combo2       switch1  yes                      100
11 combo3       switch1  yes                      100
12 combo4       switch1  yes                      100
13 switch1-cpu  switch1                           100
14 switch2-cpu  switch2
Relying on Fasttrack HW Offloading too much

Since Fasttrack HW Offloading offers near-the-wire-speed performance at zero configuration overhead, the users are tempted to use it as the default solution. However, the number of HW Fasttrack connections is very limited, leaving the other traffic for the CPU. Try using the hardware routing as much as possible, reduce the CPU traffic to the minimum via switch ACL rules, and then fine-tune which Fasttrack connections to offload with firewall filter rules.
Trying to offload slow-path connections

Using certain configurations (e.g. enabling bridge "use-ip-firewall" setting, creating bridge nat/filter rules) or running specific features like sniffer or torch can disable RouterOS FastPath, which will affect the ability to properly FastTrack and HW offload connections. If HW offloaded Fasttrack is required, make sure that there are no settings that disable the FastPath and verify that connections are getting the "H" flag or use the L3HW monitor command to see the amount of HW offloaded connections.
L3HW Feature Support

    HW - the feature is supported and offloaded to the hardware.
    CPU - the feature is supported but performed by software (CPU)
    N/A - the feature is not available together with L3HW. Layer 3 hardware offloading must be completely disabled (switch l3-hw-offloading=no) to make this feature work.
    FW - the feature requires l3-hw-offloading=no for a given switch port. On the switch level, l3-hw-offloading=yes.


IPv4 Unicast Routing	HW	
	7.1
IPv6 Unicast Routing	HW	

/interface/ethernet/switch/l3hw-settings/set ipv6-hw=yes

	7.6
IPv4 Multicast Routing	CPU	
	
IPv6 Multicast Routing	CPU	
	
ECMP	HW	Multipath routing	7.1
Blackholes	HW	

/ip/route add dst-address=10.0.99.0/24 blackhole

	7.1
gateway=<interface_name>	CPU/HW	

/ip/route add dst-address=10.0.0.0/24 gateway=ether1 

This works only for directly connected networks. Since HW does not know how to send ARP requests,
CPU sends an ARP request and waits for a reply to find out the DST MAC address on the first received packet of the connection that matches a DST IP address.
After DST MAC is determined, HW entry is added and all further packets will be processed by the switch chip.
	7.1
Bridge	HW	Routing from/to hardware-offloaded bridge interface.	7.1
VLAN	HW	

Routing between VLAN interfaces that are created on hardware-offloaded bridge interface with vlan-filtering.

/interface/vlan

	7.1
Bonding	HW	

Routing between bonding interfaces.

/interface/bonding

 Only 802.3ad and balance-xor bonding modes are hardware offloaded.
	7.1
IPv4 Firewall	FW	Users must choose either HW-accelerated routing or firewall.
Firewall rules get processed by the CPU. Fasttrack connections get offloaded to HW.	7.1
IPv4 NAT	FW	NAT rules applied to the offloaded Fasttrack connections get processed by HW too.	7.1
MLAG	N/A	
	 
VRF	N/A	Only the main routing table gets offloaded. If VRF is used together with L3HW and packets arrive on a switch port with l3-hw-offloading=yes, packets can be incorrectly routed through the main routing table. To avoid this, disable L3HW on needed switch ports or use ACL rules to redirect specific traffic to the CPU.	
VRRP	N/A	
	
Controller Bridge and Port Extender	N/A	
	
VXLAN	HW	

Support for hardware-offloaded VXLAN data plane, VXLAN encapsulation and decapsulation. This allows for static one-to-one VLAN-to-VXLAN mappings within a vlan-filtering bridge.

At this point, some known features are not yet implemented.

Underlay (routing encapsulated VXLAN packets):

1. VTEPs are not supported over ECMP

2. VTEPs are not supported over bond, VLAN interface

3. VTEPs are not supported over multicast

4. VTEPs cannot operate within VRFs

5. VTEPs are not supported with IPv6

Overlay (forwarding between Ethernet and VXLAN):

1. VLAN tagging over VXLAN is not supported

2. Routing between different VXLAN VNIs is not supported

3. VTEPs are isolated, and there is no mechanism to control "horizon" between them.

4. Bridged VXLAN interfaces do not support IGMP snooping. When snooping is enabled, MDB entries on VXLAN are not offloaded, and multicast traffic gets restricted between Ethernet and VXLAN.

5. Bridged VXLAN interfaces are not supported by MLAG.  

/interface/vxlan

	7.18
MTU	HW	The hardware supports up to 8 MTU profiles.	7.1
QinQ Routing	CPU	Stacked routable VLAN interfaces will lose L3HW offloading, while routable VLAN interfaces created directly on the bridge interface can still use HW offloading.	 

Only the devices listed in the table below support L3 HW Offloading.
L3HW Device Support

Only the devices listed in the table below support L3 HW Offloading.
CRS3xx: Switch DX3000 and DX2000 Series

The devices below are based on Marvell 98DX224S, 98DX226S, or 98DX3236 switch chip models.

Below are some important features that these devices are missing when compared to other switch models:

    Fasttrack and NAT connection offloading;
    per-VLAN packet and byte counters.

The 98DX3255 and 98DX3257 models are exceptions, which have a feature set of the DX8000 rather than the DX3000 series.
CRS305-1G-4S+	98DX3236	7.1	13312	3328	4K	8
CRS310-1G-5S-4S+	98DX226S	7.1	13312	3328	4K	8
CRS310-8G+2S+	98DX226S	7.1	13312	3328	4K	8
CRS318-1Fi-15Fr-2S	98DX224S	7.1	13312	3328	4K	8
CRS318-16P-2S+	98DX226S	7.1	13312	3328	4K	8
CRS320-8P-8B-4S+RM	98DX226S	7.1	13312	3328	4K	8
CRS326-24G-2S+	98DX3236	7.1	13312	3328	4K	8
CRS304-4XG-IN	98DX2528	7.1	13312	3328	4K	8
CRS328-24P-4S+	98DX3236	7.1	13312	3328	4K	8
CRS328-4C-20S-4S+	98DX3236	7.1	13312	3328	4K	8

1 Since the total amount of routes that can be offloaded is limited, prefixes with higher netmask are preferred to be forwarded by hardware (e.g., /32, /30, /29, etc.), any other prefixes that do not fit in the HW table will be processed by the CPU. Directly connected hosts are offloaded as /32 (IPv4) or /128 (IPv6) route prefixes. The number of hosts is also limited by max-neighbor-entries in IP Settings / IPv6 Settings.

2 IPv4 and IPv6 routing tables share the same hardware memory.

3 If a route has more paths than the hardware ECMP limit (X), only the first X paths get offloaded.
Partial offloading

In the case of DX3000/DX2000 switch chip serries, it is quite simple: one RouterOS route entry (/ip/route/) reflects into one HW IPv4 route prefix entry. Connected hosts (/32 routes) also occupy the same table. As long as the total number of routes ("ip/route print count-only") + connected host count ("/ip/arp print count-only where status=reachable or status=stale") , 13312 (13k), everything gets offloaded. Exceeding the number, routes with shorter prefixes stay on the CPU.
CCR2xxx, CRS3xx, CRS5xx: Switch DX8000 and DX4000 Series

The devices below are based on Marvell 98DX8xxx, 98DX4xxx switch chips, or 98DX325x model.
CRS309-1G-8S+	98DX8208	7.1	16K - 36K	16K	4K - 6K	8K	8K	4.5K	3.9K	+
CRS312-4C+8XG	98DX8212	7.1	16K - 36K	16K	4K - 6K	8K	8K	2.25K	2.25K	+
CRS317-1G-16S+	98DX8216	7.1	120K - 240K	64K	30K - 40K	32K	8K	4.5K	4K	+
CRS326-24S+2Q+	98DX8332	7.1	16K - 36K	16K	4K - 6K	8K	8K	2.25K	2.25K	+
CRS326-4C+20G+2Q+	98DX8332	7.1	16K - 36K	16K	4K - 6K	8K	8K	2.25K	2.25K	+
CRS354-48G-4S+2Q+, CRS354-48P-4S+2Q+	98DX3257 6	7.1	16K - 36K	16K	4K - 6K	8K	8K	2.25K	2.25K	+
CRS504-4XQ	98DX4310	7.1	60K - 120K	64K	15K - 20K	32K	8K	4.5K	4K	+
CRS510-8XS-2XQ	98DX4310	7.3	60K - 120K	64K	15K - 20K	32K	8K	4.5K	4K	+
CRS518-16XS-2XQ	98DX8525	7.3	60K - 120K	64K	15K - 20K	32K	8K	4.5K	4K	+
CRS520-4XS-16XQ-RM	98CX8410	7.3	120K - 240K	64K	30K - 40K	32K	8K	4.5K	4K	+
CCR2116-12G-4S+	98DX32556	7.1	16K - 36K	16K	4K - 6K	8K	8K	2.25K	2.25K	+
CCR2216-1G-12XS-2XQ	98DX8525	7.1	60K - 120K	64K	15K - 20K	32K	8k	4.5K	4K	+
RDS2216-2XG-4S+4XS-2XQ	98DX4310	7.17	60K - 120K	64K	15K - 20K	32K	8K	4.5K	4K	+

1 Depends on the complexity of the routing table. Whole-byte IP prefixes (/8, /16, /24, etc.) occupy less HW space than others (e.g., /22). Starting with RouterOS v7.3, when the Routing HW table gets full, only routes with longer subnet prefixes are offloaded (/30, /29, /28, etc.) while the CPU processes the shorter prefixes. In RouterOS v7.2 and before, Routing HW memory overflow led to undefined behavior. Users can fine-tune what routes to offload via routing filters (for dynamic routes) or suppressing hardware offload of static routes. IPv4 and IPv6 routing tables share the same hardware memory.

2 When the HW limit of Fasttrack or NAT entries is reached, other connections will fall back to the CPU. MikroTik's smart connection offload algorithm ensures that the connections with the most traffic are offloaded to the hardware.

3 Fasttrack connections share the same HW memory with ACL rules. Depending on the complexity, one ACL rule may occupy the memory of 3-6 Fasttrack connections.

4 MPLS shares the HW memory with Fasttrack connections. Moreover, enabling MPLS requires the allocation of the entire memory region, which could otherwise store up to 768 (0.75K) Fasttrack connections. The same applies to the Bridge Port Extender. However, MPLS and BPE may use the same memory region, so enabling them both doesn't double the limitation of Fasttrack connections.

5 If a Fasttrack connection requires Network Address Translation, a hardware NAT entry is created. The hardware supports both SRCNAT and DSTNAT.

6 The switch chip has a feature set of the DX8000 series.

7 DX4000/DX8000 switch chips store directly connected hosts, IPv4 /32, and IPv6 /128 route entries in the FDB table rather than the routing table. The HW memory is shared between regular FDB L2 entries (MAC), IPv4, and IPv6 addresses. The number of hosts is also limited by max-neighbor-entries in IP Settings / IPv6 Settings.

8 IPv4 and IPv6 routing tables share the same hardware memory.
Partial offloading

The DX8000/DX4000 have entirely different routing tables. Instead of prefixes, we have to offload route indexes. The entire IPv4 address range (same for IPv6) must be indexed, i.e., 0.0.0.0 - 255.255.255.255. Adding new route entries causes index rebuild, increasing hardware memory by 0-5 entries depending on the complexity of the routing table. That's why no exact numbers are given. For example, some routing tables containing 240K entries can be fully offloaded to CRS317 HW, while others with 160K entries barely fit. And you will never know until you try.

When indexing the entire IP address range (0.0.0.0 - 255.255.255.255), you can offload as many routes as needed, as long as you also have a default route (0.0.0.0/0) using the same next-hop.

For example, on a CCR2216 router around 950k routes with a /30 prefix are created, all using the same next-hop along with a default route. As a result, all routes were offloaded, while the lmp-usage remained minimal.
[admin@MikroTik] > interface/ethernet/switch/l3hw-settings/advanced/monitor 
        ipv4-routes-total: 942338
           ipv4-routes-hw: 942326
          ipv4-routes-cpu:     11
  ipv4-shortest-hw-prefix:      0
               ipv4-hosts:      1
         route-queue-size:      0
         route-queue-rate:      0
       route-process-rate:      0
              nexthop-cap:   8192
            nexthop-usage:     85
    vxlan-mtu-packet-drop:      0
     fasttrack-ipv4-conns:      0
     fasttrack-queue-size:      0
     fasttrack-queue-rate:      0
   fasttrack-process-rate:      0
   fasttrack-hw-min-speed:      0
   fasttrack-hw-offloaded:      0
    fasttrack-hw-unloaded:      0
                  lpm-cap:  27200
                lpm-usage:     11
             lpm-bank-cap:   1360
           lpm-bank-usage:      1
                                0
                                0
                                0
                                1
                                0
                                0
                                0
                                4
                                0
                                0
                                0
                                5
                                0
                                0
                                0
                                0
                                0
                                0
                                0
                  pbr-cap:   8192
                pbr-usage:      0
             pbr-lpm-bank:      2
                nat-usage:      0

However, if there are "gaps" in the address range, such as not using a default route or having multiple next-hops, this consumes HW table. When the routing HW table gets full, only routes with longer subnet prefixes are offloaded (/30, /29, /28, etc.) while the CPU processes the shorter prefixes. Here is what happens when the default route gets disabled or different next-hops are used: only 37k routes with a /30 prefix fit in the HW table. This is the worst-case scenario for the CCR2216.
[admin@MikroTik] > interface/ethernet/switch/l3hw-settings/advanced/monitor 
        ipv4-routes-total: 942337
           ipv4-routes-hw:  37729
          ipv4-routes-cpu: 904608
  ipv4-shortest-hw-prefix:     30
               ipv4-hosts:      1
         route-queue-size:      0
         route-queue-rate:      0
       route-process-rate:      0
              nexthop-cap:   8192
            nexthop-usage:     85
    vxlan-mtu-packet-drop:      0
     fasttrack-ipv4-conns:      0
     fasttrack-queue-size:      0
     fasttrack-queue-rate:      0
   fasttrack-process-rate:      0
   fasttrack-hw-min-speed:      0
   fasttrack-hw-offloaded:      0
    fasttrack-hw-unloaded:      0
                  lpm-cap:  27200
                lpm-usage:  22392
             lpm-bank-cap:   1360
           lpm-bank-usage:   1022
                             1033
                             1027
                             1028
                             1221
                             1033
                             1040
                              678
                             1358
                             1245
                             1254
                             1242
                             1246
                             1249
                             1273
                             1260
                             1101
                             1024
                             1031
                             1027
                  pbr-cap:   8192
                pbr-usage:      0
             pbr-lpm-bank:      2
                nat-usage:      0

In many cases, the default behavior "offloading only routes with longer subnet prefixes" is not optimal, especially if the ratio of CPU-handled routes to HW-offloaded routes is too high. When this happens, the chances of a packet being hardware-forwarded drop significantly.

If HW memory is insufficient and partial offloading occurs, a better approach for you as a network administrator would be to offload only the routes that carry the most traffic while keeping less demanding routes on the CPU, and not letting the partial offloading to happen.

Fortunately, there are several ways to manage this. There is per-switch-port and static route suppression, and filtering dynamic routes using a wide range of attributes. One example is to use as-path to filter most demanding prefixes (Google, Meta), while all other routes gets L3HW suppressed.




    Creado por Edgars P., actualizado por última vez por GG el mar 28, 2024 3 min de lectura

    Overview
    Basic Configuration Example
    Property Reference
        Interface settings
        Profile settings

Overview

The MACsec (Media Access Control Security) protocol is a standard security technology employed in Ethernet networks to ensure the confidentiality, integrity, and authenticity of data transmitted over the physical medium. MACsec is defined by IEEE standard 802.1AE.

MACsec utilizes GCM-AES-128 encryption over Ethernet and secures all LAN traffic, including DHCP, ARP, LLDP, and higher-layer protocols.

RouterOS MACsec implementation is in the early stage, it does not support dynamic key management via Dot1x (manual key configuration is required) and hardware-accelerated encryption (maximum throughput is highly limited by the device CPU).
Basic Configuration Example

Imagine Host1 ether1 is connected to Switch ether1 and Host2 ether1 is connected to Switch ether2. In this example, we will create two MACsec interface pairs and use a bridge to create a secure Layer2 connection between both end devices. 

First, configure MACsec interfaces on Host1 and Host2. We can specify only the Ethernet interface and RouterOS will automatically generate the Connectivity Association Key (CAK) and connectivity association name (CKN). Use the print command to see the values:
# Host1
/interface macsec
add interface=ether1 name=macsec1

[admin@Host2] /interface/macsec print
Flags: I - inactive, X - disabled, R - running 
 0   name="macsec1" mtu=1468 interface=ether1 status="negotiating" cak=71a7c363794da400dbde595d3926b0e9
     ckn=f2c4660060169391d29d8db8a1f06e5d4b84a128bad06ad43ea2bd4f7d21968f profile=default

# Host2
/interface macsec
add interface=ether1 name=macsec1

[admin@Host2] /interface/macsec print
Flags: I - inactive, X - disabled, R - running 
 0   name="macsec1" mtu=1468 interface=ether1 status="negotiating" cak=dc47d94291d19a6bb26a0c393a1af9a4
     ckn=e9bd0811dad1e56f06876aa7715de1855f1aee0baf5982ac8b508d4fc0f162d9 profile=default

On the Switch device, to enable MACsec we need to configure the matching CAK and CKN values for the appropriate Ethernet interface:
# Switch
/interface macsec
add comment=Host1 cak=71a7c363794da400dbde595d3926b0e9 ckn=f2c4660060169391d29d8db8a1f06e5d4b84a128bad06ad43ea2bd4f7d21968f interface=ether1 name=macsec1
add comment=Host2 cak=dc47d94291d19a6bb26a0c393a1af9a4 ckn=e9bd0811dad1e56f06876aa7715de1855f1aee0baf5982ac8b508d4fc0f162d9 interface=ether2 name=macsec2

Once the pre-shared keys are successfully exchanged, the MACsec Key Agreement (MKA) protocol is activated. MKA is responsible for ensuring the continuity of MACsec on the link and determines which side becomes the key server in a point-to-point connection. The key server generates a Secure Association Key (SAK) that is shared exclusively with the device on the other end of the link. This SAK is used to secure all data traffic passing through the link. Periodically, the key server generates a new randomly-created SAK and shares it over the point-to-point link to maintain MACsec functionality.

In RouterOS, the MACsec interface can be configured like any Ethernet interface. It can be used as a routable interface with an IP address, or placed inside a bridge. On Host1 and Host2 we will add an IP address from the same network. On Switch, we will use a bridge. 
# Host1
/ip address
add address=192.168.10.10/24 interface=macsec1

# Host2
/ip address
add address=192.168.10.20/24 interface=macsec1

# Switch
/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=macsec1
add bridge=bridge1 interface=macsec2

Last, confirm that Host1 can reach Host2 using a ping.
 [admin@Host1] > ping 192.168.10.20
  SEQ HOST                                     SIZE TTL TIME       STATUS
    0 192.168.10.20                              56  64 1ms438us  
    1 192.168.10.20                              56  64 818us     
    2 192.168.10.20                              56  64 791us     
    3 192.168.10.20                              56  64 817us     
    4 192.168.10.20                              56  64 783us     
    sent=5 received=5 packet-loss=0% min-rtt=783us avg-rtt=929us max-rtt=1ms438us
Property Reference
Interface settings

Sub-menu: /interface/macsec

Configuration settings for the MACsec interface.
cak (string; Default: )	A 16-byte pre-shared connectivity association key (CAK). To enable MACsec, configure the matching CAK and CKN on both ends of the link. When not specified, RouterOS will automatically generate a random value.
ckn (string; Default: )	A 32-byte connectivity association name (CKN). To enable MACsec, configure the matching CAK and CKN on both ends of the link. When not specified, RouterOS will automatically generate a random value.
comment (string; Default: )	Short description of the interface.
disabled (yes | no; Default: no)	Changes whether the interface is disabled.
interface (name; Default: )	Ethernet interface name where MACsec is created on, limited to one MACsec interface per Ethernet.
mtu (integer; Default: 1468)	

Sets the maximum transmission unit. The l2mtu will be set automatically according to the associated interface (subtracting 32 bytes corresponding to the MACsec encapsulation). The l2mtu cannot be changed.
name (string; Default: macsec1)	Name of the interface.
profile (name; Default: default)	

Sets MACsec profile, used for determining the key server in a point-to-point connection.
status (read-only: disabled |initializing | invalid | negotiating | open-encrypted)	

Shows the current MACsec interface status.
Profile settings

Sub-menu: /interface/macsec/profile

Configuration settings for the MACsec profile.
name (string; Default: )	Name of the profile.
server-priority (integer: 0..255; Default: 10)	Sets the priority for determining the key server in a point-to-point connection, a lower value means higher priority. In case of a priority match, the interface with the lowest MAC address will be acting as a key server.



    Creado por Edgars P., actualizado por última vez el jun 26, 2025 3 min de lectura

    Overview
    Basic Configuration Example
    Property Reference

Overview

The MACVLAN provides a means to create multiple virtual network interfaces, each with its own unique Media Access Control (MAC) address, attached to a physical network interface. This technology is utilized to address specific network requirements, such as obtaining multiple IP addresses or establishing distinct PPPoE client connections from a single physical Ethernet interface while using different MAC addresses. Unlike traditional VLAN (Virtual LAN) interfaces, which rely on Ethernet frames tagged with VLAN identifiers, MACVLAN operates at the MAC address level, making it a versatile and efficient solution for specific networking scenarios.

RouterOS MACVLAN interfaces are not supported by Container, as it exclusively utilizes VETH (Virtual Ethernet) interfaces for its networking.

A MACVLAN interface can only receive broadcast packets, packets addressed to its own MAC address, and a limited number of multicast addresses. If the physical interface has a VLAN configured, the MACVLAN interface cannot receive packets from that VLAN.

For bridging and more complex Layer2 solutions involving VLANs, a dedicated switch should be used instead.


Basic Configuration Example

Picture a scenario where the ether1 interface connects to your ISP, and your router needs to lease two IP addresses, each with a distinct MAC address. Traditionally, this would require the use of two physical Ethernet interfaces and an additional switch. However, a more efficient solution is to create a virtual MACVLAN interface. 

To create a MACVLAN interface, select the needed Ethernet interface. A MAC address will be automatically assigned if not manually specified:
/interface macvlan
add interface=ether1 name=macvlan1

/interface macvlan print
Flags: R - RUNNING
Columns: NAME, MTU, INTERFACE, MAC-ADDRESS, MODE
#   NAME       MTU  INTERFACE  MAC-ADDRESS        MODE  
0 R macvlan1  1500  ether1     76:81:BF:68:69:83  bridge

Now, a DHCP client can be created on ether1 and macvlan1 interfaces:
/ip dhcp-client
add interface=ether1
add interface=macvlan1
Property Reference

Sub-menu: /interface/macvlan

Configuration settings for the MACVLAN interface.
arp (disabled | enabled | local-proxy-arp | proxy-arp | reply-only; Default: enabled)	Address Resolution Protocol setting

    disabled - the interface will not use ARP
    enabled - the interface will use ARP
    local-proxy-arp -  the router performs proxy ARP on the interface and sends replies to the same interface
    proxy-arp - the router performs proxy ARP on the interface and sends replies to other interfaces
    reply-only - the interface will only reply to requests originating from matching IP address/MAC address combinations, which are entered as static entries in the IP/ARP table. No dynamic entries will be automatically stored in the IP/ARP table. Therefore, for communications to be successful, a valid static entry must already exist.

arp-timeout (auto | integer; Default: auto)	Sets for how long the ARP record is kept in the ARP table after no packets are received from IP. Value auto equals to the value of arp-timeout in /ip/settings/, default is 30s.
comment (string; Default: )	Short description of the interface.
disabled (yes | no; Default: no)	Changes whether the interface is disabled.
interface (name; Default: )	

The name of the underlying interface on which the MACVLAN will operate. MACVLAN interfaces can be created on any interface that has a MAC address.

    Adding a VLAN interface on top of a MACVLAN interface is not supported.
    Adding MACVLAN on interface which is already bridged or bonded is not supported.

loop-protect (on | off | default; Default: default)	Enables or disables loop protect on the interface, the default works as turned off.
loop-protect-disable-time (time interval | 0; Default: 5m)	Sets how long the selected interface is disabled when a loop is detected. 0 - forever.
loop-protect-send-interval (time interval; Default: 5s)	Sets how often loop protect packets are sent on the selected interface.
mac-address (MAC; Default: )	Static MAC address of the interface. A randomly generated MAC address will be assigned when not specified.
mode (private | bridge; Default: bridge)	

Sets MACVLAN interface mode:

    private - does not allow communication between MACVLAN instances on the same parent interface.
    bridge - allows communication between MACVLAN instances on the same parent interface.

mtu (integer; Default: 1500)	

Sets Layer 3 Maximum Transmission Unit. For the MACVLAN interface, it cannot be higher than the parent interface.
name (string; Default: )	Interface name.



    Creado por Edgars P., actualizado por última vez el jun 06, 2025 34 min de lectura

    Overview
    QoS Terminology
    QoS Device Support
    Applications and Usage Examples
        Basic Configuration Example
        Dante
        RDMA over Converged Ethernet (RoCE)
    QoS Marking
        Understanding Map ranges
        Understanding Port, Profile, and Map relation
        QoS Marking via Switch Rules (ACL)
    QoS Enforcement
        Hardware Queues
        Hardware Resources
        Resource Saving
        Traffic Prioritization
    Active Queue Management (AQM)
        Weighted Random Early Detection (WRED)
        Explicit Congestion Notification (ECN)
        Priority-based Flow Control (PFC)
    Property Reference
        Switch settings
        Port settings
            Port Stats
            Port Resources/Usage
            Port PFC Stats
        QoS Menu
        QoS Settings
        QoS Monitor
        QoS Profile
        QoS Mapping
            VLAN Map
            DSCP Map
        Transmission Manager
            Transmission Queue Scheduler
        Priority-based Flow Control (PFC)

Overview

This document defines Quality of Service (QoS) usage in RouterOS based on Marvell Prestera DX switch chips (CRS3xx, CRS5xx series switches, and CCR2116, CCR2216 routers). 

QoS is a set of features in network switches that allow network administrators to prioritize traffic and allocate network resources to ensure that important data flows smoothly and with low latency.

The primary function of QoS in network switches is to manage network traffic in a way that meets the specific requirements of different types of network applications. For example, voice and video data require low latency and minimal packet loss to ensure high-quality communication, while file transfers and other data applications can tolerate higher levels of latency and packet loss.

QoS works by identifying the type of traffic flowing through the switch and assigning it a priority level based on its requirements. The switch can then use this information to alter packet headers and prioritize the flow of traffic, ensuring that higher-priority traffic is given preferential treatment over lower-priority traffic.

RouterOS v7.15+ is required to support all QoS features:

    QoS Marking. QoS profile matching by ingress packet headers, then egress header alternation according to the assigned QoS profiles.
    QoS Enforcement. Avoid or resolve congestion based on the assigned QoS profiles and traffic shaping.
    QoS Policy. Assign QoS profiles via ACL rules.
    Active Queue Management: WRED (Weighted Random Early Detection), ECN notification, and processing, PFC (Priority-based Flow Control).
    Traffic shaping.

QoS Terminology

These terms will be used throughout the article.

    QoS - Quality of Service.
    ACL - Access Control List, a set of switch rules used to filter network traffic based on specified criteria.
    AQM - Active Queue Management.
    DSCP - Differentiated Services Code Point, a 6-bit field in the IP header used to prioritize network traffic.
    ECN - Explicit Congestion Notification.
    ETS - Enhanced Transmission Selection.
    PCP - Priority Code Point, a 3-bit field in the VLAN header used to prioritize traffic within a VLAN.
    PFC - Priority-based Flow Control (IEEE 802.1Qbb).
    RoCE - RDMA over Converged Ethernet.
    WRED - Weighted Random Early Detection.
    /in/eth/sw/ a shortcut for /interface/ethernet/switch/. The shortcut works in CLI, too.

QoS Device Support
CCR2116-12G-4S+	98DX3255	1024	12	15	✔	✔	8	Unreliable 1
CCR2216-1G-12XS-2XQ	98DX8525	1024	12	15	✔	✔	8	Max fill 2
CRS305-1G-4S+	98DX3236	128	1	8	
	
	-	Current values
CRS309-1G-8S+	98DX8208	1024	12	15	✔	✔	8	Unreliable
CRS310-1G-5S-4S+	98DX226S	128	1	8	
	
	-	Current values
CRS312-4C+8XG	98DX8212	1024	12	15	✔	✔	8	Unreliable
CRS317-1G-16S+	98DX8216	1024	12	15	✔	✔	8	Unreliable
CRS318-1Fi-15Fr-2S	98DX224S	128	1	8	
	
	-	Current values
CRS318-16P-2S+ 	98DX226S	128	1	8	
	
	-	Current values
CRS320-8P-8B-4S+	98DX226S	128	1	8	
	
	-	Current values
CRS326-24G-2S+	98DX3236	128	1	8	
	
	-	Current values
CRS304-4XG	98DX2528	128	1	8	
	
	-	Current values
CRS326-24S+2Q+	98DX8332	1024	12	15	✔	✔	8	Unreliable
CRS328-24P-4S+	98DX3236	128	1	8	
	
	-	Current values
CRS328-4C-20S-4S+	98DX3236	128	1	8	
	
	-	Current values
CRS354-48G-4S+2Q+, CRS354-48P-4S+2Q+	98DX3257
	1024	12	15	✔	✔	8 5	Unreliable
CRS504-4XQ	98DX4310	1024	12	15	✔	✔	8	Max fill
CRS510-8XS-2XQ	98DX4310	1024	12	15	✔	✔	8	Max fill
CRS518-16XS-2XQ	98DX8525	1024	12	15	✔	✔	8	Max fill
CRS520-4XS-16XQ	98CX8410	1024	12	15	✔	✔	8 5	Unavailable 4

1 Due to hardware limitations, some switch chip models may break traffic flow while accessing QoS port/queue usage data.

2 The device gathers max queue fill statistics instead of displaying the current usage values. Use the reset-counters command to reset those stats.

3 The devices without PFC profiles do not support Priority-based Flow Control.

4 Usage data for individual queues on a port are unavailable, only the total usage for the entire port can be accessed.

5 Due to hardware limitations, PFC settings cannot be configured on certain switch ports. For CRS354 series models, PFC is not supported on ports ether37 to ether48. For the CRS520-4XS-16XQ model, PFC is not supported on ports qsfp28-4-1 to qsfp28-7-4.
Applications and Usage Examples
Basic Configuration Example

In this example, we define just one QoS level - VoIP (IP Telephony) on top of the standard "Best Effort" class. Let's imagine that we have a CRS326-24G-2S+ device where:

    all ports are bridged and using vlan-filtering;
    sfp-sfpplus1 is a VLAN trunk connected to another switch;
    ether1-ether9 are dedicated ports for IP phones;
    ether10-ether24 are standard ports for host connection;

First, we need to define QoS profiles. Defined dscp and pcp values that will be used in forwarded packets on egress:
/interface ethernet switch qos profile
add dscp=46 name=voip pcp=5 traffic-class=5

Port-based QoS profile assignment on dedicated ports for IP phones applies to ingress traffic. Other Ethernet ports will use the default profile (where dscp=0 and pcp=0):
/interface ethernet switch qos port
set ether1 profile=voip
set ether2 profile=voip
set ether3 profile=voip
set ether4 profile=voip
set ether5 profile=voip
set ether6 profile=voip
set ether7 profile=voip
set ether8 profile=voip
set ether9 profile=voip

The trunk port receives both types of QoS traffic. We need to create VLAN priority mapping with the QoS profile and enable trust-l2 to differentiate them:
/interface ethernet switch qos map vlan
add pcp=5 profile=voip

/interface ethernet switch qos port
set sfp-sfpplus1 trust-l2=trust

Finally, enable QoS hardware offloading for the above settings to start working:
/interface ethernet switch
set switch1 qos-hw-offloading=yes

It is possible to verify the port QoS settings with print command:
[admin@MikroTik] /interface/ethernet/switch/qos/port print
Columns: NAME, SWITCH, PROFILE, MAP, TRUST-L2, TRUST-L3
 # NAME          SWITCH   PROFILE  MAP      TRUST-L2  TRUST-L3  TX-MANAGER
 0 ether1        switch1  voip     default  ignore    ignore    default
 1 ether2        switch1  voip     default  ignore    ignore    default
 2 ether3        switch1  voip     default  ignore    ignore    default
 3 ether4        switch1  voip     default  ignore    ignore    default
 4 ether5        switch1  voip     default  ignore    ignore    default
 5 ether6        switch1  voip     default  ignore    ignore    default
 6 ether7        switch1  voip     default  ignore    ignore    default
 7 ether8        switch1  voip     default  ignore    ignore    default
 8 ether9        switch1  voip     default  ignore    ignore    default
 9 ether10       switch1  default  default  ignore    ignore    default
10 ether11       switch1  default  default  ignore    ignore    default
11 ether12       switch1  default  default  ignore    ignore    default
12 ether13       switch1  default  default  ignore    ignore    default
13 ether14       switch1  default  default  ignore    ignore    default
14 ether15       switch1  default  default  ignore    ignore    default
15 ether16       switch1  default  default  ignore    ignore    default
16 ether17       switch1  default  default  ignore    ignore    default
17 ether18       switch1  default  default  ignore    ignore    default
18 ether19       switch1  default  default  ignore    ignore    default
19 ether20       switch1  default  default  ignore    ignore    default
20 ether21       switch1  default  default  ignore    ignore    default
21 ether22       switch1  default  default  ignore    ignore    default
22 ether23       switch1  default  default  ignore    ignore    default
23 ether24       switch1  default  default  ignore    ignore    default
24 sfp-sfpplus1  switch1  default  default  trust     ignore    default
25 sfp-sfpplus2  switch1  default  default  ignore    ignore    default
26 switch1-cpu   switch1   

Now incoming packets on ports ether1-ether9 are marked with a Priority Code Point (PCP) value of 5 and a Differentiated Services Code Point (DSCP) value of 46, and incoming packets on ports ether10-ether24 are marked with PCP and DSCP values of 0. When packets are incoming to sfp-sfpplus1 port, any packets with a PCP value of 5 will retain their PCP value of 5 and DSCP value of 46, while all other packets will be marked with PCP and DSCP values of 0.
Dante

Starting from RouterOS v7.15, all MikroTik QoS-Capable devices comply with Dante. 

Dante hardware use the following DSCP / Diffserv priority values for traffic prioritization.
High	Time critical PTP events	CS7	56
Medium	Audio, PTP	EF	46
Low	(reserved)	CS1	8
None	Other traffic	BE	0

The example assumes that the switch is using its default configuration, which includes a default "bridge" interface and all Ethernet interfaces added as bridge ports, and any of these interfaces could be used for Dante.

First, create QoS Profiles to match Dante traffic classes, there is already a pre-existing "default" profile that corresponds to Dante's None priority.
/interface/ethernet/switch/qos/profile
add name=dante-ptp dscp=56 pcp=7 traffic-class=7
add name=dante-audio dscp=46 pcp=5 traffic-class=5
add name=dante-low dscp=8 pcp=1 traffic-class=0

Then, create a QoS mapping to match QoS profiles based on DSCP values. 
/interface/ethernet/switch/qos/map/ip
add dscp=56 profile=dante-ptp
add dscp=46 profile=dante-audio
add dscp=8 profile=dante-low

Configure hardware queues to enforce QoS on Dante traffic.
/interface/ethernet/switch/qos/tx-manager/queue
set [find where traffic-class>=2] schedule=strict-priority
set [find where traffic-class<2] schedule=low-priority-group weight=1

Dante's High and Medium priority traffic is scheduled in strict order. The devices transmits time-critical PTP packets until queue7 gets empty, then proceed with audio (queue5). Low and other traffic gets transmitted only when PTP and audio queues are empty. Since Dante does not define priority order between Low and Other traffic (usually, CS1 has lower priority than Best Effort), and the Low traffic class is reserved for future use anyway, we treat both traffic types equally by putting both into the same group with the same weight. Feel free to change the CS1/BE traffic scheduling according to the requirements if some Dante hardware in your network uses the low-priority traffic class.

The next step is to enable trust mode for incoming Layer3 packets (IP DSCP field):
/interface/ethernet/switch/qos/port
set [find] trust-l3=keep

Finally, enable QoS hardware offloading for the above settings to start working:
/interface ethernet switch
set switch1 qos-hw-offloading=yes

When using Dante in multicast mode, it is beneficial to enable IGMP snooping on the switch. This feature directs traffic only to ports with subscribed devices, preventing unnecessary flooding. Additionally, enabling an IGMP querier (if not already enabled on another device in the same LAN), adjusting query intervals, and activating fast-leave can further optimize multicast performance.
/interface/bridge
set [find name=bridge] igmp-snooping=yes multicast-querier=yes query-interval=60s

/interface/bridge/port
set [find] fast-leave=yes
RDMA over Converged Ethernet (RoCE)

RoCE allows you to directly access memory on remote storage systems using Ethernet networks without involving the host CPU. This capability significantly reduces latency and CPU overhead, making RoCE ideal for high-performance computing and data center environments. RoCE also enables a converged network, where various services (such as data storage, networking, and multimedia) run over a single Ethernet infrastructure. This simplifies network management and reduces the cost and complexity of maintaining separate networks.

RoCE achieves this through the use of ECN and PFC mechanisms. These features help prevent network congestion and packet loss, ensuring reliable, lossless communication. See the device feature table for compatible switches. Although switches can support RoCE environments, the end hosts must also be compatible with the RoCE protocol and equipped with RDMA-capable network interface cards (NICs).

There are two main versions of RoCE. RoCEv1 operates as an Ethernet link layer protocol and uses Ethertype 0x8915. RoCEv2 works over standard IP networks, using UDP destination port number 4791. ECN bits in the IP header are marked to signal network congestion, and a Congestion Notification Packet (CNP) is used to acknowledge congestion to the sender. For traffic prioritization, DSCP 26 is used for RoCEv2 traffic, while DSCP 48 for CNPs.

The following example can be used for lossless RoCEv2 with PFC and ECN and it assumes that the switch is using its default configuration, which includes a default "bridge" interface and all Ethernet interfaces added as bridge ports. The minimal recommended RouterOS version is 7.17.

First, configure additional profiles. Non-RoCE traffic will be assigned to already existing "default" profile with traffic-class 1, RoCEv2 to traffic-class 3, and CNP to traffic-class 6.
/interface ethernet switch qos profile
add name=roce traffic-class=3
add name=cnp traffic-class=6

Create a QoS mapping to match QoS profiles based on DSCP values.
/interface ethernet switch qos map ip
add dscp=26 profile=roce
add dscp=48 profile=cnp

Configure hardware queues and scheduler. We are using ETS (schedule=high-priority-group) for traffic-class 1 and traffic-class 3 with 50% bandwith assigment each (weight=1), and strict priority scheduling for traffic-class 6. Additionally, configure a separate shared memory pool (shared-pool-index=1) for lossless traffic in traffic-class 3 and enable ECN (ecn=yes) to mark IP packets in the switch that experience congestion.
/interface ethernet switch qos tx-manager queue
set 1 schedule=high-priority-group weight=1
set 3 schedule=high-priority-group weight=1 shared-pool-index=1 ecn=yes
set 6 schedule=strict-priority

Although using schedule=low-priority-group allows you to create separate ETS scheduling and bandwidth allocation for a different set of traffic-classes, it is not recommended to use this setting together with lldp-dcbx=yes. The reason is that the ETS Configuration/Recommendation TLVs are designed to handle a single bandwidth allocation across traffic classes, thus schedule=high-priority-group should be used instead.

Configure PFC profile for traffic-class 3 to ensure a lossless environment for RoCEv2 traffic.
/interface ethernet switch qos priority-flow-control
add name=pfc-tc3 rx=yes traffic-class=3 tx=yes

Set Layer3 trust mode (trust-l3=keep) on switch ports where RoCEv2 traffic is expected, set PFC (pfc=pfc-tc3) and egress-rate for queue3 to comply with PFC requirements (egress-rate-queue3=10.0Gbps). In this example, 10Gbps SFP+ interfaces are used, and the egress rate can be set to match the physical speed of the interface. Change this property depending on your interface speeds.
/interface ethernet switch qos port
set sfp-sfpplus1 egress-rate-queue3=10.0Gbps pfc=pfc-tc3 trust-l3=keep
set sfp-sfpplus2 egress-rate-queue3=10.0Gbps pfc=pfc-tc3 trust-l3=keep
set sfp-sfpplus3 egress-rate-queue3=10.0Gbps pfc=pfc-tc3 trust-l3=keep
set sfp-sfpplus4 egress-rate-queue3=10.0Gbps pfc=pfc-tc3 trust-l3=keep

Enable QoS hardware offloading for the above settings to start working.
/interface ethernet switch
set switch1 qos-hw-offloading=yes

Enable the LLDP Data Center Bridging Capability Exchange Protocol (DCBX) to share QoS settings and capabilities with other neighboring devices.
/ip neighbor discovery-settings
set lldp-dcbx=yes

As an optional step, increase the L2MTU to accommodate larger data packets.
/interface ethernet
set [find switch=switch1] l2mtu=9500
QoS Marking
Understanding Map ranges

In order to avoid defining all possible PCP and DSCP mappings, RouterOS allows setting multiple values and ranges for PCP and DSCP values for QoS Profile mapping.

In the following example, PCP values 0 and 2 use the default QoS profile, 1, 3-4 - streaming, 5 - voip, and 6-7 - control.
/interface ethernet switch qos map vlan
add pcp=1,3-4 profile=streaming
add pcp=5 profile=voip
add pcp=6-7 profile=control
Understanding Port, Profile, and Map relation

Each switch port has Layer2 and Layer3 trust settings that will change how ingress packets are classified into QoS profiles and what PCP and DSCP values will be used. Below are tables that describe all possible options:
ignore	ignore	The port is considered untrusted. Both headers are ignored, and the port's profile is forced to all ingress packets. This is the default setting.
ignore	trust	Trust the Layer 3 header. Use the DSCP field from the IP header of ingress packets for QoS profile lookup (see /in/eth/sw/qos/map/ip). If the lookup fails (no QoS profiles are mapped to the given DSCP value), the default QoS profile is used (not the switch port's QoS profile). The switch port's profile field is used only for non-IP traffic.
ignore	keep	Trust the Layer 3 header. Use the DSCP field from the IP header of ingress packets for QoS profile lookup (see /in/eth/sw/qos/map/ip). If the lookup fails, the default QoS profile is used. The switch port's profile field is used only for non-IP traffic. If the forwarded/routed packet is VLAN-tagged, its PCP value is set from the selected QoS profile. However, the original DSCP value of the packet is kept intact.
trust	ignore	Trust the Layer 2 header, but ignore L3. If an ingress packet is VLAN-tagged, use the PCP field from the VLAN header for QoS profile lookup (see /in/eth/sw/qos/map/vlan). If the lookup fails (no QoS profiles are mapped to the given PCP value), the default QoS profile is used. The switch port's profile field is used only for untagged traffic.
trust	trust	Trust both headers, but Layer 3 has higher precedence. In the case of an IP packet, use the DSCP field for QoS profile lookup (see /in/eth/sw/qos/map/ip). If the DSCP-to-QoS lookup fails, use the default profile. If the packet is not an IP packet but is VLAN-tagged, use the PCP field from the VLAN header for QoS profile lookup (see /in/eth/sw/qos/map/vlan).  If the VLAN-to-QoS lookup fails, use the default QoS profile. Non-IP untagged packets use the switch port's profile.
trust	keep	The same as trust+trust, but the original DSCP value is preserved in forwarded/routed packets.
keep	ignore	Trust the Layer 2 header but ignore L3. If an ingress packet is VLAN-tagged, use the PCP field from the VLAN header for QoS profile lookup (see /in/eth/sw/qos/map/vlan). If the lookup fails (no QoS profiles are mapped to the given PCP value), the default QoS profile is used. The switch port's profile field is used only for untagged traffic. If the packet is VLAN-tagged on both ingress and egress, the original PCP value is kept.
keep	trust	Trust both headers, but Layer 3 has higher precedence. In the case of an IP packet, use the DSCP field for QoS profile lookup (see /in/eth/sw/qos/map/ip). If the DSCP-to-QoS lookup fails, use the default profile. If the packet is not an IP packet but is VLAN-tagged, use the PCP field from the VLAN header for QoS profile lookup (see /in/eth/sw/qos/map/vlan).  If the VLAN-to-QoS lookup fails, use the default QoS profile. Non-IP untagged packets use the switch port's profile. If the packet is VLAN-tagged on both ingress and egress, the original PCP value is kept. The DSCP value in forwarded/routed packets is set from the selected QoS profile.
keep	keep	Trust both headers, but Layer 3 has higher precedence. In the case of an IP packet, use the DSCP field for QoS profile lookup (see /in/eth/sw/qos/map/ip). If the DSCP-to-QoS lookup fails, use the default profile. If the packet is not an IP packet but is VLAN-tagged, use the PCP field from the VLAN header for QoS profile lookup (see /in/eth/sw/qos/map/vlan).  If the VLAN-to-QoS lookup fails, use the default QoS profile. Non-IP untagged packets use the switch port's profile. Keep both the original PCP and/or DSCP values intact in cases of VLAN-tagged and/or IP packets, respectively.
Port settings
	The selected QoS profile and the source for PCP / DSCP field values in forwarded/routed packets
qos-trust-l2
 	qos-trust-l3
	VLAN-Tagged IP	Untagged IP	VLAN-Tagged Non-IP	Untagged Non-IP
QoS Profile	PCP	DSCP	QoS Profile	PCP 1	DSCP	QoS Profile	PCP	DSCP	QoS Profile	PCP 1	DSCP
ignore	ignore	profile	profile	profile	profile	profile	profile	profile	profile	-	profile	profile	-
ignore	trust	map/ip	map/ip	map/ip	map/ip	map/ip	map/ip	profile	profile	-	profile	profile	-
ignore	keep	map/ip	map/ip	original	map/ip	map/ip	original	profile	profile	-	profile	profile	-
trust	ignore	map/vlan	map/vlan	map/vlan	profile	profile	profile	map/vlan	map/vlan	-	profile	profile	-
trust	trust	map/ip	map/ip	map/ip	map/ip	map/ip	map/ip	map/vlan	map/vlan	-	profile	profile	-
trust	keep	map/ip	map/ip	original	map/ip	map/ip	original	map/vlan	map/vlan	-	profile	profile	-
keep	ignore	map/vlan	original	map/vlan	profile	profile	profile	map/vlan	original	-	profile	profile	-
keep	trust	map/ip	original	map/ip	map/ip	profile	map/ip	map/vlan	original	-	profile	profile	-
keep	keep	map/ip	original	original	map/ip	profile	original	map/vlan	original	-	profile	profile	-

1 applies only when ingress traffic is untagged, but the egress needs to be VLAN-tagged.
QoS Marking via Switch Rules (ACL)

Starting from RouterOS v7.15, it is possible to assign QoS profiles via Switch Rules (ACL).

Sub-menu: /interface/ethernet/switch/rule
new-qos-profile (name)	The name of the QoS profile to assign to the matched packets.
keep-qos-fields (yes | no; Default: no)	Should the original values of QoS fields (PCP, DSCP) be kept (yes), or replace them with the ones from the assigned QoS profile (no)? Relevant only if new-qos-profile is set.
new-vlan-priority (0..7)	Deprecated and should be replaced with the respective new-qos-profile. Kept for backward compatibility. Relevant only if qos-hw-offloading=no.

The following example assigns a QoS profile based on the source MAC address.
/interface ethernet switch rule
add new-qos-profile=stream ports=ether1,ether2 src-mac-address=00:01:02:00:00:00/FF:FF:FF:00:00:00 switch=switch1
add new-qos-profile=voip ports=ether1,ether2 src-mac-address=04:05:06:00:00:00/FF:FF:FF:00:00:00 switch=switch1
QoS Enforcement
Hardware Queues

Each switch port has eight hardware transmission (tx) queues (queue0..queue7). Each queue corresponds to a traffic class (tc0..tc7) set by a QoS profile. Each ingress packet gets assigned to a QoS profile, which, in turn, determines the traffic class for tx queue selection on the egress port.

Hardware queues are of variable size - set by the Transmission Manager. Moreover, multiple ports and/or queues can share resources with each other (so-called Shared Buffers). For example, a device with 25 ports has memory (buffers) to queue 1200 packets in total. If we split the resources equally, each port gets 48 exclusive buffers with a maximum of 6 packets per queue (48/8) - which is usually insufficient to absorb even a short burst of traffic. However, choosing to share 50% of the buffers leaves each port with 24 exclusive buffers (3 per queue), but at the same time, a single queue can grow up to 603 buffers (3 exclusive + 600 shared).

RouterOS allows enabling/disabling the shared pool for each queue individually - for example, to prevent low-priority traffic from consuming the entire hardware memory. In addition, port buffer limits may prevent a single low-speed port from consuming the entire shared pool. See QoS Settings and  Transmission Manager for details.

The default, best-effort (PCP=0, DSCP=0) traffic class is 1, while the lowest priority (PCP=1) has traffic class 0.
Hardware Resources

The hardware (switch chips) has limited resources (memory). There are two main hardware resources that are relevant to QoS:

    Packet descriptors - contain packet control information (target port, header alternation, etc).
    Data buffers - memory chunks containing the actual payload. Buffer size depends on the switch chip model. Usually - 256 bytes.

One packet descriptor may use multiple buffers (depending on the payload size); buffers may be shared by multiple descriptors - in cases of multicast/broadcast. If the hardware does not have enough free descriptors or buffers, the packet gets dropped (tail-drop).

Hardware resources can be limited per destination type (multicast/unicast), per port, and per each tx queue. If any limits are reached, no more packets can be enqueued for transmission, and further packets get dropped.

RouterOS obscures low-level hardware information, allowing to set resource limits either in terms of packets or a percentage of the total amount. RouterOS automatically calculates the required hardware descriptor and buffer count based on the user-specified packet limit and port's MTU. Moreover, RouterOS comes with preconfigured hardware resources, so there is no need to do a manual configuration in common QoS environments.

Changing any hardware resource allocation parameter in runtime results in a temporary device halt when no packets can be enqueued nor transmitted. Temporary packet loss is expected while the device is forwarding traffic.
Resource Saving

Since reallocating hardware resources in runtime is not an option, RouterOS cannot automatically free queue buffers reserved for inactive ports. Those buffers remain unused. However, if the user knows that the specific ports will never be used (e.g., stay physically disconnected), the respective queue resources can be manually freed by using the built-in "offline" tx-manager with minimum resources:
/interface/ethernet/switch/qos/port
set [find where !running] tx-manager=offline

When configuring tx-manager setting to QSFP+ or QSFP28 interfaces, you must apply the same configuration to all four sub-interfaces of a port. For example, if the interface qsfp28-1-1 is active and linked at 100Gbps, while sub-interfaces (qsfp28-1-2, qsfp28-1-3, qsfp28-1-4) are showing a non-running flag, do not assign the "offline" tx-manager to thouse non-running sub-interfaces. Doing so will impact the 100Gbps link as well. However, if none of the four sub-interfaces are running, it is safe to assign the "offline" tx-manager setting.
Traffic Prioritization

The hardware provides two types of traffic transmission prioritization:

    Strict Priority - traffic from higher queues is always transmitted first;
    Enhanced Transmission Selection (ETS) - multiple queues participate in packet transmission scheduling at the same time.

Strict priority queues are straightforward. If the highest priority queue (Q7) has packets, those are transmitted first. When Q7 is empty, packets from Q6 get transmitted, and so on. The packets from the lowest priority queue (Q0) are transmitted only if all other queues are empty.

The downside of strict prioritization is increased latency in lower queues while "overprioritizing" higher queues. Suppose the acceptable latency of TC5 is 20ms, TC3 - 50ms. Traffic appearing in Q5 gets immediately transmitted due to the strict priority of the queue, adding extra latency to every packet in the lower queues (Q4..Q0). A packet burst in Q5 (e.g., a start of a voice call) may temporarily "paralyze" Q3, increasing TC3 latencies over the acceptable 50ms (or even causing packet drops due to full queue) while TC5 packets get transmitted at <1ms (way below the 20ms limit). Slightly sacrificing TC5 latency by transmitting TC3 packets in between would make everybody happy. That ETS is for.

Enhanced Transmission Selection (ETS) schedule traffic for transmission from multiple queues (group members) in a weighted round-robin manner. A queue's weight sets the number of packets transmitted from the queue in each round. For example, if Q2, Q1, and Q0 are the group members, and their weights are 3, 2, and 1, respectively, the scheduler transmits 3 packets from Q2, 2 - from Q1, and 1 - from Q0. The actual Tx order is "Q2, Q1, Q0, Q2, Q1, Q2" - for even fairer scheduling.

There are two hardware groups: low-priority-group and high-priority-group. There is a strict priority ordering between the two groups: the low-priority-group is transmitting only when all queues in the high-priority-group are empty. However, it is possible to use only one group for all queues.

The default (built-in) RouterOS queue setup is listed below. Q3-Q5 share the bandwidth within the high-priority group, where packets are transmitted while Q6 and Q7 are empty. Q0-Q2 are the members of the low-priority-group, where packets are transmitted while Q3-Q7 are empty.
[admin@MikroTik] /interface/ethernet/switch/qos/tx-manager/queue> print 
Columns: TX-MANAGER, TRAFFIC-CLASS, SCHEDULE, WEIGHT, QUEUE-BUFFERS, USE-SHARED-BUFFERS
#  TX-MANAGER  TRAFFIC-CLASS  SCHEDULE             WEIGHT  QUEUE-BUFFERS  USE-SHARED-BUFFERS
0  default     0              low-priority-group   1       auto           no                
1  default     1              low-priority-group   2       auto           yes                
2  default     2              low-priority-group   3       auto           yes                
3  default     3              high-priority-group  3       auto           yes               
4  default     4              high-priority-group  4       auto           yes               
5  default     5              high-priority-group  5       auto           yes               
6  default     6              strict-priority              auto           yes               
7  default     7              strict-priority              auto           yes 

It is recommended that all group members are adjacent to each other.
Active Queue Management (AQM)
Weighted Random Early Detection (WRED)

WRED is a per-queue congestion control mechanism that signals congestion events to the end-points by dropping packets. WRED relies on the existence of rate throttling mechanisms in the end-points that react to packet loss, such as TCP/IP. WRED uses a randomized packet drop algorithm in an attempt to anticipate congestion events and respond to them by throttling traffic rates before the congestion actually happens. The randomness property of WRED prevents throughput collapse related to the global synchronization of TCP flows.

WRED can be enabled/disabled per each queue in each Tx Manager. Disable WRED for lossless traffic! Also, there is no reason to enable WRED on high-speed ports where congestion should not happen in the first place.

The behavior is controlled via WRED threshold. WRED threshold is the maximum number of packets/bytes that can exceed the queue shared buffer limit (cap). A random packet drop begins when queue usage exceeds their respective capacities:

    queueX-packet-use > queueX-shared-packet-cap or
    queueX-byte-use > queueX-shared-byte-cap.

The more usage exceeds capacity, the higher the packet drop chance, reaching 100% at queueX-shared-packet-cap + wred-packet-threshold (or byte).

RouterOS automatically chooses the actual WRED threshold values according to queue or shared pool capacities. The user may shift the thresholds in one way or another via QoS Settings.

WRED requires the respective Tx queues to use shared buffers (use-shared-buffers=yes).

Choosing a WRED threshold value is a tradeoff between congestion anticipation and burst absorption. Setting a higher WRED threshold may lead to earlier traffic rate throttling and, therefore, resolve congestion. On the other hand, a high threshold leads to packet drops in limited traffic bursts that could be absorbed by the queue buffers and transformed losslessly if WRED didn't kick in. For instance, initiating a remote database connection usually starts with heavier traffic ("packet burst") at the initialization phase; then, the traffic rate drops down to a "reasonable" level. Any packet drop during the initialization phase leads to nothing but a slower database connection due to the need for retransmission. Hence, lowering the WRED threshold or entirely disabling WRED on such traffic is advised. The opposite case is video streaming. Early congestion detection helps select a comfortable streaming rate without losing too much bandwidth on retransmission or/and "overshooting" by sacrificing the quality level by too much.

Use Switch Rules (ACL) or other QoS Marking techniques to differentiate traffic and put packets into queues with desired WRED settings.

The following script only applies WRED to TCP/IP traffic by redirecting it to queue2. UDP and other packets are left in queue1 - since their end-points usually cannot respond to early drops. Queue1 and queue2 are scheduled equally - without prioritizing one queue over another.
/interface/ethernet/switch/qos/profile
add name=tcp-wred traffic-class=2 pcp=0 dscp=0

# move TCP traffic to queue2
/interface/ethernet/switch/rule
add new-qos-profile=tcp-wred ports=ether1,ether2,ether3,ether4 protocol=tcp switch=switch1

# set the same scheduling priority (weight) between queue1 and queue2
# apply WRED only to queue2 - TCP traffic
/interface/ethernet/switch/qos/tx-manager/queue/
set [find where traffic-class=1] weight=2 schedule=low-priority-group use-shared-buffers=yes shared-pool-index=0 wred=no
set [find where traffic-class=2] weight=2 schedule=low-priority-group use-shared-buffers=yes shared-pool-index=0 wred=yes
Explicit Congestion Notification (ECN)

Some switch chips can perform ECN marking of IP packets on the hardware level, according to RFC 3168. Hardware ECN marking is based on the WRED mechanism, but instead of dropping IP packets, they are marked with CE (Congestion Experienced, binary 11) in the ECN field (two least significant bits in IPv4/TOS or IPv6/TrafficClass octet). Only ECN-Capable IP packets may be marked - those with the ECN field value of ECT(1) or ECT(0)  (binary 01 or 10, respectively). Not ECN-Capable Transport packets (ECN=00) never get marked. If a packet already has the CE mark (ECN=11), it never gets cleared, even if the device does not experience congestion.

Set ecn=yes on Tx Manager Queue to enable ECN marking.

ECN marking mechanism requires the respective Tx queues to use shared buffers (use-shared-buffers=yes).

The packet receives the CE mark if all conditions below are met:

    The packet is either IPv4 or IPv6.
    The ECN field value in IP header is either ECT(1) or ECT(0).
    Egress port's Tx Queue has ecn=yes and uses shared buffers (use-shared-buffers=yes).
    queueX-packet-use > queueX-shared-packet-cap or queueX-byte-use > queueX-shared-byte-cap.

Since enabling ECN (ecn=yes) prevents ECN-capable packet drop, queue usage may exceed WRED thresholds if the traffic sender doesn't react to congestion notification in time.
Priority-based Flow Control (PFC)

Priority-Based Flow Control (PFC) provides lossless operation for up to eight traffic classes, so that congestion in one traffic class does not pause other traffic classes. In addition, PFC enables co-existence of loss-sensitive traffic types with loss tolerant traffic type in the same network.

PFC-capable switch chips are complaint with IEEE 802.1Qbb PFC, meaning that the respective devices are capable of generating and responding to PFC frames. On the triggering part, the PFC frame is sent by the source port and traffic class experiencing the congestion. The timer values of the generated PFC frames are 0xFFFF for pause (XOFF) and 0x0 for resume (XON), and the appropriate bit in the priority enable vector is set. On the response part, the received PFC frame pauses the specific priority queues on the port that received the PFC frame for the duration specified by the PFC frame.

In RouterOS, PFC configuration is organized in profiles, where each port can be assigned to a specific profile. A PFC profile defines the traffic classes to enable PFC on, pause/resume thresholds to send XOFF/XON PFC frames, respectively, and whenever the assigned ports should transmit or/and receive PFC frames.

While congestion occurs on egress ports, PFC is triggered on the ingress port. Shared buffers must be used to associate the amount of ingressed traffic with the respective packets waiting in Tx queues. For each PFC-enabled traffic class, set use-shared-buffers=yes to the respective Tx Queues. It is also recommended that a separate shared pool (shared-pool-index) be used for each PFC-enabled queue, especially not to mix it with PFC-disabled traffic classes.

RouterOS implements 1:1 mapping between traffic classes and Tx queues. Packets with assigned traffic class 0 get enqueued in queue0, TC1 - queue1, etc., up to TC7-Q7. Hence, the terms "traffic class" and "tx queue" are used interchangeably in this text.

When choosing pause and resume thresholds, consider a delay in transmitting a PFC frame and processing it by the other side. For example, device A experienced congestion at time T, transmitted a PFC pause frame to device B, and B processed the frame and halted transmission at time T+D. During the delta time D, device B still kept sending traffic. If device A has configured the pause threshold to 100%, it has no free buffers available, and, therefore, packets may drop, which is unacceptable for lossless traffic classes. Lowering the pause threshold, let's say, down to 80% issues a PFC pause frame while still having free memory to accumulate traffic during the delta time D. The same applies to resume threshold. Setting it to 0% keeps the device idle during the delta time, lowering the overall throughput.

PFC Rx requires setting the egress rate to all associated queues to calculate pause time, even if it matches the wire speed. For example, if PFC runs on traffic class 3, the assigned ports require the egress-rate-queue3 setting.
/interface/ethernet/switch/qos/priority-flow-control add name=pfctc3 traffic-class=3 rx=yes
/interface/ethernet/switch/qos/port set sfp-sfpplus1,sfp-sfpplus2 pfc=pfctc3 egress-rate-queue3=10G
Property Reference
Switch settings

Sub-menu: /interface/ethernet/switch

Switch QoS settings (in addition to the existing ones).
qos-hw-offloading (yes | no; Default: no)	Allows enabling QoS for the given switch chip (if the latter supports QoS).

When you enable QoS, turning off the qos-hw-offloading setting will not completely revert to the previous functionality. It is recommended to reboot the device after disabling it.
Port settings

Sub-menu: /interface/ethernet/switch/qos/port

Switch port QoS settings. Assigns a QoS profile to ingress packets on the given port. The assigned profile can be changed via match rules if the port is considered trusted.

By default, ports are untrusted and receive the default QoS profile (Best-Effort, PCP=0, DSCP=0), where priority fields are cleared from the egress packets.
egress-rate-queue0 .. egress-rate-queue7 (integer: 0..18446744073709551615; Default !egress-rate-queuex)	Sets egress traffic limitation (bits per second) for specific output queue. It is possible to specify the limit using suffixes like k, M, or G to represent kbps, Mbps, or Gbps. This setting can be combined with the overall per-port limit egress-rate (see /in/eth/sw/port).
map (name; Default: default)	Allows user-defined QoS priority-to-profile mapping in the case of a trusted port or host (see /in/eth/sw/qos/map).
pfc (name; Default: disabled)
	The name of the PFC profile to control ingress priority-based traffic flow (see /in/eth/sw/qos/priority-flow-control).
profile (name; Default: default)	The name of the QoS profile to assign to the ingress packets by default (see /in/eth/sw/qos/profile).
trust-l2 (ignore | trust | keep; Default: ignore)	

Whenever to trust the Layer 2 headers of the incoming packets (802.1p PCP field):

    ignore - ignore L2 header; use the port's profile value for all incoming packets;
    trust - use PCP field of VLAN-tagged packets for QoS profile lookup in map. Untagged packets use the port's profile value. Forwarded VLAN or priority-tagged packets receive the PCP value from the selected QoS profile (overwriting the original value).
    keep - trust but keep the original PCP value in forwarded packets. 

trust-l3 (ignore | trust | keep; Default: ignore)	

Whenever to trust the Layer 3 headers of the incoming packets (IP DSCP field):

    ignore - ignore L3 header; use either L2 header or the port's profile (depends on trust-l2).
    trust - use DSCP field of IP packets for QoS profile lookup in map. Forwarded/routed IP packets receive the DSCP value from the selected QoS profile (overwriting the original value).
    keep - trust but keep the original DSCP value in forwarded/routed packets.

tx-manager (name; Default: default)	

The name of the Transmission Manager that is responsible for enqueuing and transmitting packets from the given port (see /in/eth/sw/qos/tx-manager).

L3 trust mode has higher precedence than L2 unless trust-l3=ignore or the packet does not have an IP header.

Forwarded/routed packets obtain priority field values (PCP, DSCP) from the selected QoS profile, overwriting the original values unless the respective trust mode is set to keep.

Commands.
print	Print the above properties in a human-friendly format.
print stats	Print port statistics: total and per-queue transmitted/dropped packets/bytes.
reset-counters	Reset all counters in port statistics to zero.
print usage	Print queue usage/resources.
print pfc
	Pring Priority Flow Control stats
print rates
	Print per-queue egress traffic limitation (set by egress-rate-queueX)
Port Stats
Example
[admin@Mikrotik] /interface/ethernet/switch/qos/port> print stats where name=ether2
                  name:     ether2
             tx-packet:      2 887
               tx-byte:  3 938 897
           drop-packet:      1 799
             drop-byte:  2 526 144
      tx-queue0-packet:         50
      tx-queue1-packet:      1 871
      tx-queue3-packet:        774
      tx-queue5-packet:        192
        tx-queue0-byte:      3 924
        tx-queue1-byte:  2 468 585
        tx-queue3-byte:  1 174 932
        tx-queue5-byte:    291 456
    drop-queue1-packet:      1 799
      drop-queue1-byte:  2 526 144
name	Port name.
tx-packet	The total number of packets transmitted via this port.
tx-byte	The total number of bytes transmitted via this port.
drop-packet	The total number of packets should have been transmitted via this port but were dropped due to a lack of resources (e.g., queue buffers) or QoS Enforcement.
drop-byte	The total number of bytes should have been transmitted via this port but were dropped.

tx-queue0-packet .. tx-queue7-packet
	The number of packets transmitted via this port from the respective queue.

tx-queue0-byte .. tx-queue7-byte
	The number of bytes transmitted via this port from the respective queue.

drop-queue0-packet .. drop-queue7-packet
	The number of packets dropped from the respective queue (or not enqueued at all due to lack of resources).

drop-queue0-byte .. drop-queue7-byte
	The number of bytes dropped from the respective queue.
Port Resources/Usage

Due to hardware limitations, some switch chip models may break traffic flow while accessing QoS port usage data. Use port usage for diagnostics/troubleshooting only. For monitoring, use QoS monitor or Port stats instead.


Example
[admin@crs326] /interface/ethernet/switch/qos/port> print usage where name=ether2
                 name:  ether2
           packet-cap:     136
           packet-use:       5
             byte-cap:  35 840
             byte-use:   9 472
    queue0-packet-cap:     130
    queue0-packet-use:       1
    queue1-packet-cap:       5
    queue1-packet-use:       4
    queue3-packet-cap:      65
    queue3-packet-use:       2
      queue0-byte-cap:  24 576
      queue0-byte-use:     256
      queue1-byte-cap:   7 680
      queue1-byte-use:   6 144
      queue3-byte-cap:  14 080
      queue3-byte-use:   3 072
name	Port name.
packet-cap	Port's packet capacity. The maximum number of packets that can be enqueued for transmission via the port.
packet-use 1	Port's packet usage. The number of packets that are currently enqueued in all port's queues.
byte-cap	Port's byte capacity (buffer size). The maximum number of bytes that can be enqueued for transmission via the port.
byte-use 1	Port's byte usage. The size of hardware buffers (in bytes) that are currently allocated for packets the enqueued packets. Since the buffers are allocated by blocks (usually - 256B each), the allocated buffer size can be bigger than the actual payload.
queue0-packet-cap .. queue7-packet-cap 2	Individual queue capacity. The maximum number of packets that can be enqueued in the respective queues (unless the Shared Buffers are enabled).
queue0-shared-packet-cap .. queue7-shared-packet-cap 2	Shared queue capacity (individual queue capacity + shared buffers). The maximum number of packets that can be enqueued in the respective queues.
queue0-packet-use .. queue7-packet-use 2	Queue packet usage. The number of enqueued packets in the respective queues.
queue0-byte-cap .. queue7-byte-cap 2	Individual queue capacity. The maximum number of bytes that can be enqueued in the respective queues (unless the Shared Buffers are enabled).
queue0-shared-byte-cap .. queue7-shared-byte-cap 2	Shared queue capacity (individual queue capacity + shared buffers). The maximum number of bytes that can be enqueued in the respective queues.
queue0-byte-use .. queue7-byte-use 2	Queue buffer usage (in bytes). The size of hardware buffers (in bytes) that are currently allocated for packets in the respective queues.
queue0-byte-max .. queue7-byte-max 2	Maximum queue buffer fill level (in bytes). Available only on devices that provide the queue statistics service. Use the reset-counters command to reset values.

1 Port's packet/byte usage can exceed the capacity if Shared Buffers are enabled.

2 Only the queues in use are printed.
Port PFC Stats
Example
[admin@crs317] /interface/ethernet/switch/qos/port> print pfc interval=1 where running
                 name:  sfp-sfpplus1 sfp-sfpplus2   ether1
                  pfc:          roce     disabled disabled
               pfc-tx:            46            
        pfc-paused-tc:             3            
 pfc3-pause-threshold:     1 048 576            
pfc3-resume-threshold:        10 240            
             pfc3-use:     1 075 200
name	Port name.
pfc	PFC profile name.
pfc-rx
	Received PFC frame count.
pfc-tx	Transmitted PFC frame count.

pfc-paused-tc
	The list of traffic classes should be paused (from the sender's perspective). PFC pause frames (XOFF) are periodically sent with the listed timers set from this port.
pfc0-pause-threshold .. pfc7-pause-threshold
	Pause thresholds of the respective traffic classes. Only PFC-enabled traffic classes are displayed.
pfc0-resume-threshold .. pfc7-resume-threshold	Resume thresholds of the respective traffic classes. Only PFC-enabled traffic classes are displayed.

pfc0-use .. pfc7-use
	The current buffer usage of the respective traffic classes (in bytes). In other words, it is the total size of all queued packets on all ports that were received from this port. Only PFC-enabled traffic classes are displayed.
QoS Menu

Sub-menu: /interface/ethernet/switch/qos

Almost the entire QoS HW configuration is located under /in/eth/sw/qos. Such an approach allows storing all QoS-related configuration items in one place, easy monitoring and exporting (/in/eth/sw/qos/export).

QoS entries have two major flags:

    H - Hardware-offloaded.
    I - Inactive.

QoS Settings

Sub-menu: /interface/ethernet/switch/qos/settings
multicast-buffers (percent: 1..90; Default: 10)	Maximum amount of packet buffers for multicast/broadcast traffic (% of the total buffer memory). 
shared-buffers (percent: 0..90; Default: 40)	Maximum amount of packet buffers that are shared between ports (% of the total buffer memory). Setting it to 0 disables buffer sharing. The remaining buffer memory is split between the ports.
shared-buffers-color (all | green-only | yellow-and-green; Default: all)	Restricts shared buffer usage for specific traffic colors only.
shared-pool0 .. shared-pool7 (percent: 0..100; Default: auto)	If the device supports multiple shared buffer pools, these settings allows adjusting the size of each pool (% of the shared buffer memory, where 100% means all shared buffers allocated by the shared-buffers setting). For example, if shared-buffers=40 and shared-pool0=50, the shared pool #0 (the first one) receives 20% of the total buffer memory (50% of 40% or "0.5 * 0.4 = 0.2"). Auto mode tries to equally allocate available resources between pools that uses auto setting, and provides at least a minimum of 10% of the total shared buffer size if the sum of other manually configured pools are exceeded. The default setting (auto). 
treat-yellow-as (green | red; Default: red)	For devices that support only two-color traffic marking (red/green). This setting allows using the same QoS profiles for the devices with two- and three-color traffic marking.
wred-threshold (low | medium | high; Default: medium) 
	A relative amount of packets above a shared queue cap ("queueX-shared-packet-cap" or "queueX-shared-byte-cap") where random drops take place. This threshold is applied only to queues with enabled Weighed Random Early Detection (wred=yes) that use shared buffers (use-shared-buffers=yes). The higher the queue buffer fill level, the higher the packet drop chance. The low threshold means the random tail drop starts later; the high - sooner.
QoS Monitor

Command: /interface/ethernet/switch/qos/monitor
Example
[admin@crs312] /interface/ethernet/switch/qos> monitor once
                   total-packet-cap: 11 480
                   total-packet-use: 454
                     total-byte-cap: 3072.0KiB
                     total-byte-use: 681.0KiB
               multicast-packet-cap: 1 148
               multicast-packet-use: 0
                 multicast-byte-cap: 307.0KiB
                 multicast-byte-use: 0
            shared-pool0-packet-cap: 2 296
            shared-pool0-packet-use: 0
            shared-pool3-packet-cap: 2 296
            shared-pool3-packet-use: 190
              shared-pool0-byte-cap: 614.2KiB
              shared-pool0-byte-use: 0
              shared-pool3-byte-cap: 614.2KiB
              shared-pool3-byte-use: 610.5KiB
                    wred-packet-cap: 512
                      wred-byte-cap: 128.0KiB

Monitors hardware QoS resources.
total-packet-cap (integer)	Total packet capacity. The maximum number of hardware packet descriptors that the device can store is all queues.
total-packet-use (integer)	Total packet usage. The current number of packet descriptors residing in the hardware memory.
total-byte-cap (byte)	Total tx memory capacity.
total-byte-use (byte)	Total tx memory usage. The current number of bytes occupied by the packets in all tx queues.
multicast-packet-cap (integer)	Multicast packet capacity. The maximum number of hardware packet descriptors that can be used by multicast/broadcast traffic. Depends on the multicast-buffers setting.
multicast-packet-use (integer)	Multicast packet usage. The hardware makes a copy of the packet descriptor for each multicast destination.
shared-packet-cap (integer)	Shared packet capacity. The maximum number of hardware packet descriptors that can be shared between ports and tx queues. Depends on the shared-buffers setting.
shared-packet-use (integer)	Shared packet usage. The current number of shared packet descriptors used by all tx queues.
shared-byte-cap (byte)	Shared tx memory capacity. Depends on the shared-buffers setting.
shared-byte-use (byte)	Shared tx memory usage. The current number of shared buffers occupied by the packets in all tx queues.
shared-pool0-packet-cap .. shared-pool7-packet-cap (integer)	Shared packet capacity of the each shared pool. Only the shared pools in use are displayed. These fields are omitted if the device does not support multiple shared pools.
shared-pool0-packet-use .. shared-pool7-packet-use (integer)	Per-pool shared packet usage. Only the shared pools in use are displayed. These fields are omitted if the device does not support multiple shared pools.
wred-packet-cap (integer)	The maximum packet count that a queue can use above the shared cap ("queueX-shared-packet-cap" in "/in/eth/sw/qos/port print usage") to trigger a random tail drop. For example, if "queue1-shared-packet-cap=3072" and "wred-packet-cap=512", WRED triggers when queue1-packet-use exceeds 3072, reaching 100% drop rate at 3072+512=3584 packets.
wred-byte-cap (integer)	The maximum byte count that a queue can use above the shared cap ("queueX-shared-byte-cap") to trigger a random tail drop. For example, if "queue1-shared-byte-cap=768KiB" and "wred-byte-cap=128KiB", WRED triggers when queue1-packet-use exceeds 768KiB, reaching 100% drop rate at 768+128=896KiB.
QoS Profile

Sub-menu: /interface/ethernet/switch/qos/profile

QoS profiles determine priority field values (PCP, DSCP) for the forwarded/routed packets. Congestion avoidance/resolution is based on QoS profiles. Each packet gets a QoS profile assigned based on the ingress switch port QoS settings (see /in/eth/sw/port).
color (green | yellow | red; Default: green)	Traffic color for color-aware drop precedence management. Leave the default value (green) for color-blind drop precedence management.
dscp (integer: 0..63; Default: 0)	IPv4/IPv6 DSCP field value for the egress packets assigned to the QoS profile.
name (string; Default: )	The user-defined name of the QoS profile. 
pcp (integer: 0..7; Default: 0)	VLAN priority value (IEEE 802.1q PCP - Priority Code Point). Used only if the egress packets assigned to the QoS profile are VLAN-tagged (have the 802.1q header). The value can be further altered via the QoS Egress Map.
traffic-class (integer: 0..7; Default: 0)	The traffic class determines the packet priority and the egress queue (see tx-manager). The queue number is usually the same as the traffic class (packets with tc0 go into queue0, tc1 - queue1, ... tc7 - queue7). Unlike pcp, where 0 means the default priority but 1 - the lowest one (and further customizable), traffic classes are strictly ordered. TC0 always selects the lowest priority, etc.
QoS Mapping

Sub-menu: /interface/ethernet/switch/qos/map

Priority-to-profile mapping table(-s) for trusted packets. All switch chips have one built-in map - default. In addition, some models allow the user to define custom mapping tables and assign different maps to various switch ports via the qos-map property:

    devices based on Marvell Prestera 98DX224S, 98DX226S, or 98DX3236 switch chip models support only one map - default.
    devices based on Marvell Prestera 98DX8xxx, 98DX4xxx switch chips, or 98DX325x model devices support up to 12 maps (the default + 11 user-defined).

name (string; Default: )	The user-defined name of the mapping table.
VLAN Map

Sub-menu: /interface/ethernet/switch/qos/map/vlan

Matches VLAN priorities (802.1p PCP/DEI fields) to QoS profiles. By default, all values are matched to the default QoS profile.
dei-only (yes | no; Default: no)	Map only packets with DEI (formerly CFI) bit set in the VLAN header.
map (name; Default: default)	The name of the mapping table.
profile (name; Default: )	The name of the QoS profile to assign to the matched packets.
pcp (range: 0..7; Default: 0)	VLAN priority (PCP) value(-s) for the lookup. 
DSCP Map

Sub-menu: /interface/ethernet/switch/qos/map/ip

Matches DSCP values to QoS profiles.
dscp (range: 0..63; Default: 0)	DSCP value(-s) for the lookup.
map (name; Default: default)	The name of the mapping table. If not set, the standard (built-in) mapping table gets altered.
profile (name; Default: )	The name of the QoS profile to assign to the matched packets.
Transmission Manager

Sub-menu: /interface/ethernet/switch/qos/tx-manager

Transmission (Tx) Manager controls packet enqueuing for transmission and packet tx order. Different switch ports can be assigned to different Tx managers. The maximum number of hardware Tx managers depends on the switch chip model. 
name (string; Default: )	The user-defined name of the Tx Manager
queue-buffers (percent: 0%..100% | bytes | auto; Default: auto)	The total amount of hardware Tx buffers allocated to all ports linked to this Tx Manager. Any value but auto is NOT scaled by the number of ports. For example, if queue-buffers=30%, and there are 3 ports using this Tx Manager, each respective port receives 10% of total available resources. Adding two more ports to the Tx Manager drops per-port buffers down to 6% (30/5).

Port status has not effect on the allocated resources. Running ports receive the same amount of queue buffers as disconnected or disabled ones if all of them are assigned to the same Tx Manager.
Transmission Queue Scheduler

Sub-menu: /interface/ethernet/switch/qos/tx-manager/queue

Each port has eight Tx queues. The assigned Tx Manager controls packet enqueuing and schedules transmission orders. Each queue can have either strict priority (where packets with the highest traffic class are always transmitted first) or grouped together for a weighted round-robin tx schedule.

Creating a Tx Manager automatically creates all eight respective queue schedulers.

Changing any properties of Tx manager or queues completely halts traffic enqueueing and transmission during the offload process. Temporary packet loss is expected while the device is forwarding traffic.


tx-manager (name; read-only)	The linked Tx Manager
traffic-class (integer: 0..7;  read-only)	The traffic class (tc0..tc7) and the respective port queue (queue0..queue7) that the scheduler controls.
schedule (strict-priority | high-priority-group | low-priority-group )	

    strict-priority - packets in the respective queue are always scheduled before moving to lower traffic classes. Packets with lower traffic classes are not transmitted until the current queue is empty.
    high-priority-group - all queues in the group are scheduled together by using a weighted round-robin principle. For example, if TC5 has weight 4, TC4 - 3, and TC3 - 2, then the scheduler transmits 4 packets from queue5, 3 packets from Q4, and 2 packets from Q3 in a single round. To achieve lower latency, each round is "sliced" between all queues in the group. In other words, the packet order in each round of the above example is "Q5, Q4, Q3, Q5, Q4, Q3, Q5, Q4, Q5".
    low-priority-group - similar logic to the high-priority-group, but the low-priority-group is scheduled only when all queues in the high-priority-group are empty.

weight (integer: 0..255; Default: 1)	The weight value for the traffic class if it is a member of a schedule group. The field is not used in the case of strict priority schedule.
queue-buffers (percent: 0%..100% | bytes | auto; Default: auto)	The amount of hardware Tx buffers allocated to this queue. Any value but auto is NOT scaled by the number of ports, i.e., the value gets split on ports linked to the Tx Manager. When given in percent, it means percentage of the tx-manager's queue-buffers value.
use-shared-buffers (yes | no)	Allow the queue to use the shared buffer pool when queue-buffers are full. If the queue is full and the shared buffers are disabled, the packet gets dropped. If the shared buffers are enabled, the queue may use up to shared-packet-cap or shared-poolX-packet-cap (see QoS Settings for details) packets from the shared pool.
shared-pool-index (integer; Default: 0)
	The shared pool index for the queue to use. Relevant only if use-shared-buffers=yes and the device supports multiple shared pools.
wred (yes | no; Default: no)	Enables/disables Weighted Random Early Detection for the given queue.
ecn (yes | no; Default: no)	Enables/disables ECN marking of the transmitted packets.
wred-actual (yes | no;  read-only)
	The actual WRED value.
ecn-actual (yes | no;  read-only)	The actual ECN value.

On some device models, due to hardware limitations, enabling ECN on one queue turns on CE marking of ECN-capable packets on all queues. In such cases, ecn-actual=yes despite ecn=no.
Priority-based Flow Control (PFC)

Sub-menu: /interface/ethernet/switch/qos/priority-flow-control

PFC configuration is organized in profiles. Different switch ports can be assigned to different PFC profiles. The maximum number of hardware Tx managers depends on the switch chip model. The builtin profile named "disabled" cannot be changed.
name (string; Default: )	The user-defined name of the PFC profile
pause-threshold (percent: 0%..100% | bytes | auto; Default: auto)	Transmits a pause frame (XOFF) when the total size of enqueued packets reaches this threshold. Enqueued packets are counted per ingress port. Applies only when tx=yes. The value can be given either explicitly in bytes or percent of the respective shared pool size (shared-poolX-byte-cap).
resume-threshold (percent: 0%..100% | bytes | auto; Default: auto)	Transmits a resume frame (XON) when the total size of enqueued packets drops down to this threshold. Enqueued packets are counted per ingress port. Applies only when tx=yes. The value can be given either explicitly in bytes or percent of the respective shared pool size (shared-poolX-byte-cap).
rx (yes | no; Default: no)	Enables receiving of PFC frames. The received PFC frame pauses the specific priority queues on the port that received the PFC frame for the duration specified by the PFC frame. Disabling rx disables queue pausing.
traffic-class (integer array: 0..7)
	The list of PFC-enabled traffic classes.
tx (yes | no; Default: no)	Enables transmition of PFC frames.

