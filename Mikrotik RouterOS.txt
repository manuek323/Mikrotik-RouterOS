

    Creado por Artūrs C., actualizado por última vez por GG el abr 17, 2024 6 min de lectura

Introduction

Queues in RouterOS are processed using CPU resources, so limiting traffic with queues on devices with relatively weak CPUs is not an effective configuration. In other words, switch-based units will be overloaded very fast, because they are meant to process layer 2 traffic by using a switch-chip, not CPU. To avoid such inefficiency, RouterOS allows limiting traffic using switch chips.
CRS3xx, CRS5xx series, and CCR2116, CCR2216 devices

This paragraph applies to CCR2116, CCR2216 devices, and CRS3xx, CRS5xx series switches. It doesn't apply to CRS1xx/CRS2xx series switches.

For CRS3xx series switches, it is possible to limit ingress traffic that matches certain parameters with ACL rules and it is possible to limit ingress/egress traffic per port basis. The policer is used for ingress traffic, the shaper is used for egress traffic. The ingress policer controls the received traffic with packet drops. Everything that exceeds the defined limit will get dropped. This can affect the TCP congestion control mechanism on end hosts and the achieved bandwidth can be actually less than defined. The egress shaper tries to queue packets that exceed the limit instead of dropping them. Eventually, it will also drop packets when the output queue gets full, however, it should allow utilizing the defined throughput better.

Port-based traffic police (ingress) and shaper (egress):
/interface ethernet switch port
set ether1 ingress-rate=10M egress-rate=5M

MAC-based traffic policer:
/interface ethernet switch rule
add ports=ether1 switch=switch1 src-mac-address=64:D1:54:D9:27:E6/FF:FF:FF:FF:FF:FF rate=10M

VLAN-based traffic policer:
/interface bridge
set bridge1 vlan-filtering=yes
/interface ethernet switch rule
add ports=ether1 switch=switch1 vlan-id=11 rate=10M

Protocol-based traffic policer:
/interface ethernet switch rule
add ports=ether1 switch=switch1 mac-protocol=ipx rate=10M
CRS1xx/CRS2xxSeries devices

This subsection does not apply to CRS3xx series devices!
Configuration schemes

MAC based traffic scheduling and shaping: [MAC address in UFDB] -> [QoS Group] -> [Priority] -> [Queue] -> [Shaper]

VLAN based traffic scheduling and shaping: [VLAN id in VLAN table] -> [QoS Group] -> [Priority] -> [Queue] -> [Shaper]

Protocol based traffic scheduling and shaping: [Protocol in Protocol VLAN table] -> [QoS Group] -> [Priority] -> [Queue] -> [Shaper]

PCP/DEI based traffic scheduling and shaping: [Switch port PCP/DEI mapping] -> [Priority] -> [Queue] -> [Shaper]

DSCP based traffic scheduling and shaping: [QoS DSCP mapping] -> [Priority] -> [Queue] -> [Shaper]
MAC based traffic scheduling using internal Priority

In Strict Priority scheduling mode, the highest priority queue is served first. The queue number represents the priority and the queue with the highest queue number has the highest priority. Traffic is transmitted from the highest priority queue until the queue is empty, and then moves to the next highest priority queue, and so on. If no congestion is present on the egress port, the packet is transmitted as soon as it is received. If congestion occurs at the port where high-priority traffic keeps coming, the lower-priority queues starve.

On all CRS switches the scheme where MAC-based egress traffic scheduling is done according to internal Priority would be the following: [MAC address] -> [QoS Group] -> [Priority] -> [Queue];
In this example, host1 (E7:16:34:00:00:01) and host2 (E7:16:34:00:00:02) will have higher priority 1 and the rest of the hosts will have lower priority 0 for transmitted traffic on port ether7. Note that CRS has a maximum of 8 queues per port.
/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=ether6 hw=yes
add bridge=bridge1 interface=ether7 hw=yes
add bridge=bridge1 interface=ether8 hw=yes

Create a QoS group for use in UFDB:
/interface ethernet switch qos-group
add name=group1 priority=1

Add UFDB entries to match specific MACs on ether7 and apply QoS group1:
/interface ethernet switch unicast-fdb
add mac-address=E7:16:34:00:00:01 port=ether7 qos-group=group1 svl=yes
add mac-address=E7:16:34:00:00:02 port=ether7 qos-group=group1 svl=yes

Configure ether7 port queues to work according to Strict Priority and QoS scheme only for destination address:
/interface ethernet switch port
set ether7 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-prior\
    ity:0,strict-priority:0,strict-priority:0,strict-priority:0" priority-to-queue=0:0,1:1 \
    qos-scheme-precedence=da-based
MAC based traffic shaping using internal Priority

The scheme where MAC based traffic shaping is done according to internal Priority would be following: [MAC address] -> [QoS Group] -> [Priority] -> [Queue] -> [Shaper];
In this example, unlimited traffic will have priority 0 and limited traffic will have priority 1 with a bandwidth limit of 10Mbit. Note that CRS has a maximum of 8 queues per port.

Create a group of ports for switching:
/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=ether6 hw=yes
add bridge=bridge1 interface=ether7 hw=yes
add bridge=bridge1 interface=ether8 hw=yes

Create a QoS group for use in UFDB:
/interface ethernet switch qos-group
add name=group1 priority=1

Add UFDB entry to match specific MAC on ether8 and apply QoS group1:
/interface ethernet switch unicast-fdb
add mac-address=E7:16:34:A1:CD:18 port=ether8 qos-group=group1 svl=yes

Configure ether8 port queues to work according to Strict Priority and QoS scheme only for destination address:
/interface ethernet switch port
set ether8 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-prior\
    ity:0,strict-priority:0,strict-priority:0,strict-priority:0" priority-to-queue=0:0,1:1 \
    qos-scheme-precedence=da-based

Apply bandwidth limit for queue1 on ether8:
/interface ethernet switch shaper
add port=ether8 rate=10M target=queue1

If the CRS switch supports Access Control List, this configuration is simpler:
/interface ethernet switch acl policer
add name=policer1 yellow-burst=100k yellow-rate=10M

/interface ethernet switch acl
add mac-dst-address=E7:16:34:A1:CD:18 policer=policer1
VLAN-based traffic scheduling + shaping using internal Priorities

A best practice is to assign lower internal QoS Priority for traffic limited by shaper to make it also less important in the Strict Priority scheduler. (higher priority should be more important and unlimited)

In this example:
Switch port ether6 is using a shaper to limit the traffic that comes from ether7 and ether8.
When a link has reached its capacity, the traffic with the highest priority will be sent out first.
VLAN10 -> QoS group0 = lowest priority
VLAN20 -> QoS group1 = normal priority
VLAN30 -> QoS group2 = highest priority
/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=ether6 hw=yes
add bridge=bridge1 interface=ether7 hw=yes
add bridge=bridge1 interface=ether8 hw=yes

Create QoS groups for use in the VLAN table:
/interface ethernet switch qos-group
add name=group0 priority=0
add name=group1 priority=1
add name=group2 priority=2

Add VLAN entries to apply QoS groups for certain VLANs:
/interface ethernet switch vlan
add ports=ether6,ether7,ether8 qos-group=group0 vlan-id=10
add ports=ether6,ether7,ether8 qos-group=group1 vlan-id=20
add ports=ether6,ether7,ether8 qos-group=group2 vlan-id=30

Configure ether6, ether7, ether8 port queues to work according to Strict Priority and QoS scheme only for VLAN-based QoS:
/interface ethernet switch port
set ether6 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-prior\
    ity:0,strict-priority:0,strict-priority:0,strict-priority:0" priority-to-queue=0:0,1:1,2:2 \
    qos-scheme-precedence=vlan-based
set ether7 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-prior\
    ity:0,strict-priority:0,strict-priority:0,strict-priority:0" priority-to-queue=0:0,1:1,2:2 \
    qos-scheme-precedence=vlan-based
set ether8 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-prior\
    ity:0,strict-priority:0,strict-priority:0,strict-priority:0" priority-to-queue=0:0,1:1,2:2 \
    qos-scheme-precedence=vlan-based

Apply bandwidth limit on ether6:
/interface ethernet switch shaper
add port=ether6 rate=10M
PCP based traffic scheduling

By default, CRS1xx/CRS2xx series devices will ignore the PCP/CoS/802.1p value and forward packets based on FIFO (First-In-First-Out) manner. When the device's internal queue is not full, then packets are in a FIFO manner, but as soon as a queue is filled, then higher-priority traffic will be sent out first. Let's consider a scenario when ether1 and ether2 are forwarding data to ether3, but when ether3 is congested, then packets are going to be scheduled, we can configure the switch to hold lowest priority packets until all higher priority packets are sent out, this is a very common scenario for VoIP type setups, where some traffic needs to be prioritized.

To achieve such a behavior, switch together ether1, ether2, and ether3 ports:
/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=ether1 hw=yes
add bridge=bridge1 interface=ether2 hw=yes
add bridge=bridge1 interface=ether3 hw=yes

Enable Strict Policy for each internal queue on each port:
/interface ethernet switch port
set ether1,ether2,ether3 per-queue-scheduling="strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0,strict-priority:0"

Map each PCP value to an internal priority value, for convenience reasons simply map PCP to an internal priority 1-to-1:
/interface ethernet switch port
set ether1,ether2,ether3 pcp-based-qos-priority-mapping=0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7

Since the switch will empty the largest queue first and you need the highest priority to be served first, then you can assign this internal priority to a queue 1-to-1:
/interface ethernet switch port
set ether1,ether2,ether3 priority-to-queue=0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7

Finally, set each switch port to schedule packets based on the PCP value:
/interface ethernet switch port
set ether1,ether2,ether3 qos-scheme-precedence=pcp-based
Bandwidth Limiting

Both Ingress Port policer and Shaper provide bandwidth limiting features for CRS switches:

Ingress Port Policer sets RX limit on port:
/interface ethernet switch ingress-port-policer
add port=ether5 meter-unit=bit rate=10M

Shaper sets TX limit on port:
/interface ethernet switch shaper
add port=ether5 meter-unit=bit rate=10M
Traffic Storm Control

The same Ingress Port policer also can be used for traffic storm control to prevent disruptions on Layer 2 ports caused by broadcast, multicast, or unicast traffic storms.

Broadcast storm control example on ether5 port with 500 packet limit per second:
/interface ethernet switch ingress-port-policer
add port=ether5 rate=500 meter-unit=packet packet-types=broadcast 

Example with multiple packet types that include ARP and ND protocols and unregistered multicast traffic. Unregistered multicast is the traffic which is not defined in the Multicast Forwarding database:
/interface ethernet switch ingress-port-policer
add port=ether5 rate=5k meter-unit=packet packet-types=broadcast,arp-or-nd,unregistered-multicast



    Creado por GG, actualizado por última vez por Gļebs K. el jun 02, 2025 24 min de lectura

    Summary
    Monitoring
    STP and RSTP
        Default values
        Election process
        Examples
            Root path cost example
            STP example
    Multiple Spanning Tree Protocol
        MSTP Regions
        Election process
        MST Instance
        MST Override
        Monitoring
        MSTP example

Summary

The purpose of the spanning tree protocol is to provide the ability to create loop-free Layer 2 topologies while having redundant links. While connecting multiple bridges or just cross-connecting bridge ports, it's possible to create network loops that can severely impact the stability of the network. Spanning tree protocol aims to resolve this problem by introducing the concept of the root bridge, all bridges in the same Layer 2 domain will exchange information about the shortest path to the root bridge. Afterward, each bridge will negotiate which ports to use to reach the root bridge. This information exchange is done with the help of Bridge Protocol Data Units (BPDUs). STP will disable certain ports for each bridge to avoid loops, while still ensuring that all bridges can communicate with each other. For an in-depth description of protocol please refer to IEEE 802.1D.

As a best practice, it is always recommended to manually set up each bridge's priority, port priority, and port path cost to ensure proper Layer2 functionality at all times. Leaving STP related values to defaults is acceptable for a network that consists of 1 to 2 bridges running with (R/M)STP enabled, but it is highly recommended to manually set these values for larger networks. Since STP elects a root bridge and root ports by checking STP related values from bridges over the network, then leaving STP settings to automatic may elect an undesired root bridge and root ports and in case of a hardware failure can result in an inaccessible network.

RouterOS bridge does not work with PVST and its variants. The PVST BPDUs (with a MAC destination 01:00:0C:CC:CC:CD) are treated by RouterOS bridges as typical multicast packets. In simpler terms, they undergo RouterOS bridge/switch forwarding logic and may get tagged or untagged. 
Monitoring

You can check the STP status of a bridge by using the /interface bridge monitor  command, for example:
interface/bridge/monitor bridge1
                    state: enabled                         
      current-mac-address: 74:4D:28:6F:31:10               
                bridge-id: 0x8000.74:4D:28:6F:31:10        
              root-bridge: no                              
           root-bridge-id: 0.74:4D:28:11:70:6B             
  regional-root-bridge-id: 0.74:4D:28:11:70:6B             
           root-path-cost: 0                               
                root-port: combo1                          
               port-count: 2                               
    designated-port-count: 0                               
        mst-config-digest: 4e22fbb9ede77faa45ec995c4ffa8085
             fast-forward: no                              
         multicast-router: yes                             
             igmp-querier: none                            
              mld-querier: none                            
        declared-vlan-ids: 1                               
      registered-vlan-ids: 1      

Note that the root bridge doesn't have any root ports, only designated ports.

You can check the STP status of a bridge port by using the /interface bridge port monitor command, for example:
/interface bridge port monitor [find interface=sfp-sfpplus2]
                  interface: combo1             
                     status: in-bridge          
                    port-id: 0x80.1             
                       role: root-port          
                  edge-port: no                 
        edge-port-discovery: yes                
        point-to-point-port: yes                
               external-fdb: no                 
               sending-rstp: yes                
                   learning: yes                
                 forwarding: yes                
           actual-path-cost: 2000               
    internal-root-path-cost: 2000               
       designated-bridge-id: 0.74:4D:28:11:70:6B
   designated-internal-cost: 0                  
         designated-port-id: 0x80.1             
  designated-remaining-hops: 20                 
                 bpdu-tx-rx: 3/7791             
        discard-transitions: 0                  
        forward-transitions: 1                  
                   tc-tx-rx: 2/2                
           topology-changes: 1                  
       last-topology-change: 4h19m43s           
           multicast-router: no                 
           hw-offload-group: switch1            
          declared-vlan-ids: 1                  
                             100                
        registered-vlan-ids: 1                  
                             100                
                             200-203     

Note that root-bridge-id consists of the bridge priority and the bridge's MAC address, for non-root bridges the root bridge will be shown as designated-bridge.

When using bridges that are set to use 802.1Q as EtherType, they will send out BPDUs to 01:80:C2:00:00:00, which are used by MSTP, RSTP, and STP. When using 802.1ad as bridge VLAN protocol, the BPDUs are not compatible with 802.1Q bridges and they are sent to 01:80:C2:00:00:08. (R/M)STP will not function properly if there are different bridge VLAN protocols across the Layer2 network.
STP and RSTP

STP and Rapid STP are used widely across many networks, but almost all networks have switched over to using only RSTP because of its benefits. STP is a very old protocol and has a convergence time (the time needed to fully learn network topology changes and to continue properly forwarding traffic) of up to 50 seconds. RSTP has a lot of smaller convergence time, a few seconds or even a few milliseconds. It is recommended to use RSTP instead of STP since it is a lot faster and is also backward compatible with STP. One of the reasons why RSTP is faster is because of reduced possible port states, below is a list of possible STP port states:

    Forwarding - port participates in traffic forwarding and is learning MAC addresses, and is receiving BPDUs.
    Listening - port does not participate in traffic forwarding and is not learning MAC addresses, is receiving BPDUs.
    Learning - port does not participate in traffic forwarding but is learning MAC addresses.
    Blocking - port is blocked since it is causing loops but is receiving BPDUs.
    Disabled - port is disabled or inactive.

In RSTP the disabled, listening, and blocking port states are replaced with just one state called the Discarding state:

    Forwarding - port participates in traffic forwarding and is learning MAC addresses, is receiving BPDUs (forwarding=yes).
    Learning - port does not participate in traffic forwarding but is learning MAC addresses (learning=yes).
    Discarding - port does not participate in traffic forwarding and is not learning MAC addresses, is receiving BPDUs (forwarding=no).

In STP ports are primarily categorized by states (e.g., Forwarding, Listening, Learning, Blocking, Disabled). Port behavior is determined dynamically based on the spanning tree algorithm but without explicitly assigning roles. The logic of forwarding or blocking traffic is derived from the calculation of Root Bridge, Root Ports, and Designated Ports, but these are considered part of the spanning tree topology rather than formalized port roles. RSTP explicitly defined port roles and introduces the concept of backup paths, which are explicitly represented through the Alternate Port and Backup Port roles. These roles did not exist in STP because STP treated blocked ports generically, without distinguishing their function as potential backups.

Here is a breakdown of the port roles for RSTP protocols: 

    Root Port - port that is facing towards the root bridge and has the best (lowest cost) path to the root bridge. Only one root port is elected per bridge (except the root bridge itself). 
    Designated Port - port that is facing away from the root bridge and forwards traffic away from the root bridge to downstream devices. 

    Alternate Port - port that is facing towards the root bridge, but is not going to forward traffic. Port provides a backup path to the root bridge if the current root port fails.

    Backup Port - port that is facing away from the root bridge, but is not going to forward traffic. Port that serves as a backup for a designated port on the same segment.

    Disabled Port - disabled or inactive port.

In STP connectivity between bridges is determined by sending and receiving BPDUs between neighbor bridges. Designated ports are sending BPDUs to root ports. If a BPDU is not received 3 times the HelloTime in a row, then the connection is considered as unavailable and network topology convergence will commence. IT is possible to reduce STP convergence time in certain scenarios by reducing the forward-delay timer, which is responsible for how long can the port be in the learning/listening state.

In RouterOS, it is possible to specify which bridge ports are edge ports. Edge ports are ports that are not supposed to receive any BPDUs, this is beneficial since this allows STP to skip the learning and the listening state and directly go to the forwarding state. This feature is sometimes called PortFast· You can leave this parameter to the default value, which is auto, but you can also manually specify it, you can set a port as an edge port manually for ports that should not have any more bridges behind it, usually these are access ports.

Additionally, bridge port point-to-point , specifies if a bridge port is connected to a bridge using a point-to-point link for faster convergence in case of failure. By setting this property to yes, you are forcing the link to be a point-to-point link, which will skip the checking mechanism, which detects and waits for BPDUs from other devices from this single link, by setting this property to no, you are implying that a link can receive BPDUs from multiple devices. By setting the property to yes, you are significantly improving (R/M)STP convergence time. In general, you should only set this property to no , if it is possible that another device can be connected between a link, this is mostly relevant to Wireless mediums and Ethernet hubs. If the Ethernet link is full-duplex, auto enables point-to-point functionality. This property has no effect when protocol-mode is set to none.
Default values

When creating a bridge or adding a port to the bridge the following are the default values that are assigned by RouterOS:

    Default bridge priority: 32768 / 0x8000
    Default bridge port path cost: based on interface speed
    Default bridge port priority: 0x80
    BPDU message age increment: 1
    HelloTime: 2
    Default max message age: 20

The bridge interface setting port-cost-mode changes the port path-cost and internal-path-cost mode for bridged ports, utilizing automatic values based on interface speed. This setting does not impact bridged ports with manually configured path-cost  or internal-path-cost properties. Below are examples illustrating the path-costs corresponding to specific data rates (with proportionate calculations for intermediate rates):
10 Mbps	2,000,000	100
100 Mbps	200,000	19
1 Gbps	20,000	4
10 Gbps	2,000	2
25 Gbps	800	1
40 Gbps	500	1
50 Gbps 	400	1
100 Gbps	200	1

For bonded interfaces, the highest path-cost among all bonded member ports is applied, this value remains unaffected by the total link speed of the bonding. For virtual interfaces (such as VLAN, EoIP, VXLAN), as well as wifi, wireless, and 60GHz interfaces, a path-cost of 20,000 is assigned for long mode, and 10 for short mode. For dynamically bridged interfaces (e.g. wifi, wireless, PPP, VPLS), the path-cost defaults to 20,000 for long mode and 10 for short mode. However, this can be manually overridden by the service that dynamically adds interfaces to bridge, for instance, by using the CAPsMAN datapath.bridge-cost setting. RouterOS versions prior to 7.13 does not change port path cost based on the link speed, for 10M, 100M, 1000M, and 10000M link speeds the default path cost value when a port is added to a bridge was always 10.

The age of a BPDU is determined by how many bridges have the BPDU passed times the message age since RouterOS uses 1 as the message age increment, then the BPDU packet can pass as many bridges as specified in the max-message-age parameter. By default this value is set to 20, this means that after the 20th bridge the BPDU packet will be discarded and the next bridge will become a root bridge, note that if max-message-age=20 is set, then it is hard to predict which ports will be the designated port on the 21st bridge and may result in traffic not being able to be forwarded properly.

In case bridge filter rules are used, make sure you allow packets with DST-MAC address 01:80:C2:00:00:00 since these packets carry BPDUs that are crucial for STP to work properly.
Election process

To properly configure STP in your network you need to understand the election process and which parameters are involved in which order. In RouterOS, the root bridge will be elected based on the smallest priority and the smallest MAC address in this particular order:

    Bridge priority (lowest)
    Bridge MAC address (lowest)

In RouterOS root ports are elected based on the lowest Root port path cost, lowest bridge identifier, and lowest bridge port ID in this particular order:

    Root port path cost (lowest)
    Bridge identifier (lowest)
    Bridge port ID (lowest)

First, when the device considers which of its ports to elect as the root port, it will check the root path cost seen by its ports. If the root path cost is the same for two or more ports then the Bridge identifier of the upstream device will be checked and the port connected to the lowest bridge identifier will become the root port. If the same bridge identifier is seen on two or more ports, then the Bridge port ID of the upstream device will be checked.

Explanation of attributes:

Root path cost, all bridges have a Root Path Cost. The root bridge has a root path cost of 0. For all other Bridges, it is the sum of the Port Path Costs on the least-cost path to the Root Bridge. You can modify the local port path cost under "/interface bridge port".

The bridge identifier is a combination of "bridge priority" and "bridge MAC", configurable under "/interface bridge"

Bridge port ID is a combination of "unique ID" and "bridge port priority", the unique ID is automatically assigned to the bridge port upon adding it to the bridge, it cannot be edited. It can be seen in WinBox under the "Bridge Port" "Port Number" column, or with "/interface bridge port monitor", as "port-number".

Make sure you are using path cost and priority on the right ports. For example, setting path cost on ports that are in a root bridge has no effect, only port priority affects them. Root path cost affects ports that are facing towards the root bridge and port priority affects ports that are facing away from the root bridge. And bridge identifier doesn’t impact the device's own root port election, instead, it affects the root port election for downstream devices.

In RouterOS it is possible to set any value for bridge priority between 0 and 65535, the IEEE 802.1W standard states that the bridge priority must be in steps of 4096. This can cause incompatibility issues between devices that do not support such values. To avoid incompatibility issues, it is recommended to use only these priorities: 0, 4096, 8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, 61440.
Examples
Root path cost example

This example outlines how the root path cost works. SW1 will be the root bridge, due to it having the lowest priority of 0x1000, as the root bridge. Each bridge will calculate the path cost to the root bridge. When calculating root path cost bridges take into account the configured path cost on their ports + root path cost advertised by neighboring bridges. 

SW1: due to it being the root bridge, it advertises a root path cost of 0 to its neighbors, even though it has a configured path cost of 10. 

SW2:  ether1. has a root path cost of 0 + 25=25. On the ether2 path cost will be 10+10+10+0=30

SW3:  ether2, has a root path cost of 0 + 10=10. On the ether4 path cost will be 10+5+25+0=40

SW4:  ether1, has a root path cost of 0+25+5=30. On ether4 path cost will be 10+10+0=20

The Port with the lowest path cost will be elected as the root port. Every bridge in STP topology needs a path to the root bridge, after the best path has been found, the redundant path will be blocked, in this case, the path between SW2 and SW4.

You can configure path cost on the root bridge, but it will only be taken into account when the bridge loses its root status. 
STP example

In this example, we want to ensure Layer2 redundancy for connections from ServerA to ServerB. If a port is connected to a device that is not a bridge and not running (R)STP, then this port is considered as an edge port, in this case, ServerA and ServerB are connected to an edge port. This is possible by using STP in a network. Below are configuration examples for each switch.

    Configuration for SW1:

/interface bridge
add name=bridge priority=0x1000
/interface bridge port
add bridge=bridge interface=ether1 priority=0x60
add bridge=bridge interface=ether2 priority=0x50
add bridge=bridge interface=ether3 priority=0x40
add bridge=bridge interface=ether4 priority=0x30
add bridge=bridge interface=ether5

    Configuration for SW2:

/interface bridge
add name=bridge priority=0x2000
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=ether2
add bridge=bridge interface=ether3

    Configuration for SW3:

/interface bridge
add name=bridge priority=0x3000
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=ether2
add bridge=bridge interface=ether3

    Configuration for SW4:

/interface bridge
add name=bridge priority=0x4000
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=ether2 path-cost=20
add bridge=bridge interface=ether3

In this example, SW1 is the root bridge since it has the lowest bridge priority. SW2 and SW3 have ether1,ether2 connected to the root bridge, and ether3 is connected to SW4. When all switches are working properly, the traffic will be flowing from ServerA through SW1_ether2, through SW2, and through SW4 to ServerB. In the case of SW1 failure, the SW2 becomes the root bridge because of the next lowest priority, indicated by the dotted line in the diagram. Below is a list of ports and their role for each switch:

    root-port - SW2_ether2, SW3_ether2, SW4_ether1
    alternate-port - SW2_ether1, SW3_ether1, SW4_ether2
    designated-port - SW1_ether1, SW1_ether2, SW1_ether3, SW1_ether4, SW1_ether5, SW2_ether3, SW2_ether3, SW4_ether3

Note: By the 802.1Q recommendations, you should use bridge priorities in steps of 4096. To set a recommended priority it is more convenient to use hexadecimal notation, for example, 0 is 0x0000, 4096 is 0x1000, 8192 is 0x2000, and so on (0..F).
Multiple Spanning Tree Protocol

Multiple Spanning Tree Protocol (MSTP) is used on a bridge interface to ensure loop-free topology across multiple VLANs, MSTP can also provide Layer2 redundancy and can be used as a load balancing technique for VLANs since it has the ability to have different paths across different VLANs. MSTP is operating very similarly to (R)STP and many concepts from (R)STP can be applied to MSTP and it is highly recommended to understand the principles behind (R)STP before using MSTP, but there are some differences that must be taken into account when designing an MSTP enabled network.

In case (R)STP is used, the BPDUs are sent across all physical interfaces in a bridge to determine loops and stop ports from being able to forward traffic if it causes a loop. In case there is a loop inside a certain VLAN, (R)STP might not be able to detect it. Some STP variants solve this problem by running an STP instance on every single VLAN (PVST), but this has been proven to be inefficient and some STP variants solve this problem by running a single STP instance across all VLANs (CST), but it lacks the possibility to do load balancing for each VLAN or VLAN group. MSTP tends to solve both problems by using MST instances that can define a group of VLANs (VLAN mapping) that can be used for load balancing and redundancy, this means that each VLAN group can have a different root bridge and a different path. Note that it is beneficial to group multiple VLANs in a single instance to reduce the amount of CPU cycles for each network topology change.

 In RouterOS with MSTP enabled the bridge priority is the CIST's root bridge priority, as stated in the IEEE 802.1Q standard the bridge priority must be in steps of 4096, the 12 lowest bits are ignored. These are valid bridge priorities: 0, 4096, 8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, 61440. When setting an invalid bridge priority, RouterOS will warn you about it and trunk the value to a valid value, but will save the original value in the configuration since invalid bridge priority values can still be used in (R)STP between devices running RouterOS, though it is recommended to use valid a bridge priority instead.
MSTP Regions

MSTP works in groups called regions, for each region there will be a regional root bridge, and between regions, there will be a root bridge elected. MSTP will use an Internal Spanning Tree (IST) to build the network topology inside a region and a Common Spanning Tree (CST) outside a region to build the network topology between multiple regions, MSTP combines these two protocols into Common and Internal Spanning Tree (CIST), which holds information about topology inside a region and between regions. From CST's perspective, a region will seemingly be as a single virtual bridge, because of this MSTP is considered very scalable for large networks. For bridges to be in the same region, their configuration must match, BPDUs will not include VLAN mappings since they can be large, rather a computed hash is being transmitted. If a bridge receives a BPDU through a port and the configuration does not match, then MSTP will consider that port as a boundary port and that it can be used to reach other regions. Below is a list of parameters that need to match for MSTP to consider a BPDU from the same region:

    Region name
    Region revision
    VLAN mappings to MST Instance IDs (computed hash)

It is possible to create MSTP enabled network without regions, though to be able to do load balancing per VLAN group it is required for a bridge to receive a BPDU from a bridge that is connected to it with the same parameters mentioned above. In RouterOS the default region name is empty and the region revision is 0, which are valid values, but you must make sure that they match to get multiple bridges in a single MSTP region. A region cannot exist if its bridges are scattered over the network, these bridges must be connected at least in one way, in which they can send and receive BPDUs without leaving the region, for example, if a bridge with different region related parameters is between two bridges that have the same region related parameters, then there will exist at least 3 different MSTP regions.

The downside of running every single bridge in a single MSTP region is the excess CPU cycles. In comparison, PVST(+) creates a Spanning Tree Instance for each VLAN ID that exists on the network, since there will be very limited paths that can exist in a network, then this approach creates a lot of overhead and unnecessary CPU cycles, this also means that this approach does not scale very well and can overload switches with not very powerful CPUs. MSTP solves this problem by dividing the network into MSTP regions, where each bridge inside this region will exchange and process information about VLANs that exist inside the same region, but will run a single instance of Spanning Tree Protocol in the background to maintain the network topology between regions. This approach has been proven to be much more effective and much more scalable, this means that regions should be used for larger networks to reduce CPU cycles.

In regions, you can define MST Instances, which are used to configure load balancing per VLAN group and to elect the regional root bridge. It is worth mentioning that in each region there exists a pre-defined MST Instance, in most documentations, this is called as MSTI0· This MST Instance is considered as the default MST Instance, there are certain parameters that apply to this special MST Instance. When traffic passes through an MSTP enabled bridge, MSTP will look for an MST Instance that has a matching VLAN mapping, but if a VLAN mapping does not exist for a certain VLAN ID, then traffic will fall under MSTI0.

Since MSTP requires VLAN filtering on the bridge interface to be enabled, then make sure that you have allowed all required VLAN IDs in /interface bridge vlan, otherwise, the traffic will not be forwarded and it might seem as if MSTP is misconfigured, although this is a VLAN filtering misconfiguration.
Election process

The election process in MSTP can be divided into two sections, intra-region and inter-region. For MSTP to work properly there will always need to be a regional root, that is the root bridge inside a region, and a CIST root, that is the root bridge between regions. A regional root is the root bridge inside a region, regional root bridge will be needed to properly set up load balancing for VLAN groups inside a region. CIST root will be used to configure which ports will be alternate/backup ports (inactive) and which ports will be root ports (active).

Between regions, there is no load balancing per VLAN group, root port election process, and port blocking between MSTP regions is done the same way as in (R)STP. If CIST has blocked a port that is inside an MSTP region to prevent traffic loops between MSTP regions, then this port can still be active for IST to do load balancing per VLAN group inside an MSTP region.

    The following parameters are involved in electing a regional root bridge or root ports inside a MSTP region:

priority (integer: 0..65535 decimal format or 0x0000-0xffff hex format; Default: 32768 / 0x8000)	/interface bridge msti, MST Instance priority, used to elect a regional root inside an MSTP region.
internal-path-cost (integer: 1..200000000; Default: )	/interface bridge port, path cost to the regional root for unknown VLAN IDs (MSTI0), used on a root port inside an MSTP region.
priority (integer: 0..240; Default: 128)	/interface bridge port mst-override, MST port priority for a defined MST Instance, used on a bridge port on the regional root bridge.
internal-path-cost (integer: 1..200000000; Default: )	/interface bridge port mst-override, MST port path cost for a defined MST Instance, used on a non-root bridge port inside an MSTP region.

    The following parameters are involved in electing a CIST root bridge or CIST root ports:

priority (integer: 0..65535 decimal format or 0x0000-0xffff hex format; Default: 32768 / 0x8000)	/interface bridge, CIST bridge priority, used to elect a CIST root bridge.
priority (integer: 0..240; Default: 128)	/interface bridge port, CIST port priority, used on a CIST root bridge to elect CIST root ports.
path-cost (integer: 1..200000000; Default: )	/interface bridge port, CIST port path cost, used on a CIST non-root bridge port to elect CIST root ports.

 The sequence of parameters in which MSTP checks to elect root bridge/ports is the same as in (R)STP, you can read more about it in the (R)STP Election Process section.
MST Instance

Sub-menu: /interface bridge msti

This section is used to group multiple VLAN IDs into a single instance to create a different root bridge for each VLAN group inside an MSTP region.
bridge (text; Default: )	Bridge to which assigns an MST instance.
identifier (integer: 1..31; Default: )	MST instance identifier.
priority (integer: 0..65535 decimal format or 0x0000-0xffff hex format; Default: 32768 / 0x8000)	MST instance priority, is used to determine the root bridge for a group of VLANs in an MSTP region.
vlan-mapping (integer: 1..4094; Default: )	The list of VLAN IDs to assign to MST instance. This setting accepts the VLAN ID range, as well as comma, separated values. E.g. vlan-mapping=100-115,120,122,128-130
MST Override

Sub-menu: /interface bridge port mst-override

This section is used to select the desired path for each VLAN mapping inside an MSTP region.
disabled (yes | no; Default: no)	Whether the entry is disabled.
internal-path-cost (integer: 1..200000000; Default: )	Path cost for an MST instance's VLAN mapping, used on VLANs that are facing towards the root bridge to manipulate path selection, lower path cost is preferred.
identifier (integer: 1..31; Default: )	MST instance identifier.
priority (integer: 0..240; Default: 128)	The priority of an MST instance's VLAN, used on VLANs that are facing away from the root bridge to manipulate path selection, lower priority is preferred.
interface (name; Default: )	Name of the port on which use configured MST instance's VLAN mappings and defined path cost and priority.
Monitoring

Similarly to (R)STP, it is also possible to monitor MSTP status. By monitoring the bridge interface itself it is possible to see the current CIST root bridge and the current regional root bridge for MSTI0, it is also possible to see the computed hash of MST Instance identifiers and VLAN mappings, this is useful when making sure that certain bridges are in the same MSTP region. Below you can find an example of monitoring an MSTP bridge:
/interface bridge monitor bridge
                    state: enabled
      current-mac-address: 6C:3B:6B:7B:F0:AA
                bridge-id: 0x8000.6C:3B:6B:7B:F0:AA 
              root-bridge: no
           root-bridge-id: 0x1000.64:D1:54:24:23:72
  regional-root-bridge-id: 0x4000.6C:3B:6B:7B:F0:AA
           root-path-cost: 10
                root-port: ether4
               port-count: 5
    designated-port-count: 3
        mst-config-digest: 74edbeefdbf82cf63a70cf60e43a56f3
             fast-forward: no                              
         multicast-router: yes                             
             igmp-querier: none                            
              mld-querier: none                            
        declared-vlan-ids: 1                               
      registered-vlan-ids: 1

In MSTP it is possible to monitor the MST Instance, this is useful to determine the current regional root bridge for a certain MST Instance and VLAN group, below you can find an example to monitor an MST Instance:
/interface bridge msti monitor 1
                    state: enabled
               identifier: 2
      current-mac-address: 6C:3B:6B:7B:F0:AA
                bridge-id: 0x8000.6C:3B:6B:7B:F0:AA
              root-bridge: no
           root-bridge-id: 0.00:00:00:00:00:00
  regional-root-bridge-id: 0x1002.6C:3B:6B:7B:F9:08
           root-path-cost: 0
                root-port: ether2
               port-count: 5
    designated-port-count: 1

It is also possible to monitor a certain MST Override entry, this is useful to determine the port role for a certain MST Instance when configuring root ports and alternate/backup ports in an MSTP region, below you can find an example to monitor an MST Override entry:
/interface bridge port mst-override monitor 1
                      port: ether3
                    status: active
                identifier: 2
                   port-id: 0x80.1     
                      role: alternate-port
                  learning: no
                forwarding: no
   internal-root-path-cost: 15
         designated-bridge: 0x1002.6C:3B:6B:7B:F9:08
  designated-internal-cost: 0
        designated-port-id: 0x80.1  
 designated-remaining-hops: 20                      
                tx-rx-bpdu: 3/7991                  
       discard-transitions: 0                       
       forward-transitions: 1                       
                  tx-rx-tc: 2/2                     
          topology-changes: 1                       
MSTP example

Let's say that we need to design topology and configure MSTP in a way that VLAN 10,20 will be forwarded in one path, but VLAN 30,40 will be forwarded in a different path, while all other VLAN IDs will be forwarded in one of those paths. This can easily be done by setting up MST Instances and assigning port path costs, below you can find a network topology that needs to do load balancing per VLAN group with 3 separate regions as an example:

The topology of an MSTP-enabled network with load balancing per VLAN group

Start by adding each interface to a bridge, initially, you should create a (R)STP bridge without VLAN filtering enabled, this is to prevent losing access to the CPU. Each device in this example is named by the region that it is in (Rx) and a device number (_x). For larger networks configuring MSTP can be confusing because of the number of links and devices, we recommend using The Dude to monitor and design a network topology.

    Use the following commands on R1_1, R1_3, R2_1, R2_3, R3_1, R3_3:

/interface bridge
add name=bridge protocol-mode=rstp vlan-filtering=no
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=ether2
add bridge=bridge interface=ether3
add bridge=bridge interface=ether4

    Use the following commands on R1_2, R2_2, R3_2:

/interface bridge
add name=bridge protocol-mode=rstp vlan-filtering=no
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=ether2

    Make sure you allow the required VLAN IDs on these devices, here we will consider that each device will receive tagged traffic that needs to be load balanced per VLAN group, use these commands on R1_1, R1_3, R2_1, R2_3, R3_1, R3_3:

/interface bridge vlan
add bridge=bridge tagged=ether1,ether2,ether3,ether4 vlan-ids=10,20,30,40

    Use the following commands on R1_2, R2_2, R3_2:

/interface bridge vlan
add bridge=bridge tagged=ether1,ether2 vlan-ids=10,20,30,40

 Make sure you add all the needed VLAN IDs and ports to the bridge VLAN table, otherwise, your device will not forward all required VLANs, and/or you will lose access to the device.

We need to assign a region name for each bridge that we want to be in a single MSTP region, you can also specify the region revision, but it is optional, though they need to match. In this example, if all bridges will have the same region name, then they will all be in a single MSTP bridge. In this case, we want to separate a group of 3 bridges in a different MSTP region to do load balancing per VLAN group and to create diversity and scalability.

    Set the appropriate region name (and region revision) for each bridge, and use the following commands on each device (change the region name!):

/interface bridge
set bridge region-name=Rx region-revision=1

After we have created 3 different MSTP regions, we need to decide which device is going to be a regional root for each VLAN group. For consistency, we are going to set the first device (_1) in each region as the regional root for VLAN 10,20 and the third device (_3) in each region as the regional root for VLAN 30,40. This can be done by creating an MST Instance for each VLAN group and assigning a bridge priority to it. The MST Instance identifier is only relevant inside an MSTP region, outside an MSTP region these identifiers can be different and mapped to a different VLAN group.

    Use the following commands on R1_1, R2_1, R3_1:

/interface bridge msti
add bridge=bridge identifier=1 priority=0x1000 vlan-mapping=10,20
add bridge=bridge identifier=2 priority=0x3000 vlan-mapping=30,40

    Use the following commands on R1_3, R2_3, R3_3:

/interface bridge msti
add bridge=bridge identifier=1 priority=0x3000 vlan-mapping=10,20
add bridge=bridge identifier=2 priority=0x1000 vlan-mapping=30,40

    Use the following commands on R1_2, R2_2, R3_2:

/interface bridge msti
add bridge=bridge identifier=1 priority=0x2000 vlan-mapping=10,20
add bridge=bridge identifier=2 priority=0x2000 vlan-mapping=30,40

Now we need to override the port path-cost and/or port priority for each MST Instance. This can be done by adding an MST-Override entry for each port and each MST Instance. To achieve that for a certain MST Instance the traffic flow path is different, we simply need to make sure that the port path cost and/or priority is larger. We can either increase the port path cost or decrease the port path cost to ports that are facing toward the regional root bridge. It doesn't matter if you increase or decrease all values, it is important that in the end, one port's path cost is larger than the other's.

    Use the following commands on R1_1, R2_1, R3_1:

/interface bridge port mst-override
add identifier=2 interface=ether1 internal-path-cost=5
add identifier=2 interface=ether2 internal-path-cost=15

    Use the following commands on R1_2, R2_2, R3_2:

/interface bridge port mst-override
add identifier=1 interface=ether1 internal-path-cost=5
add identifier=2 interface=ether2 internal-path-cost=9

    Use the following commands on R1_3, R2_3, R3_3:

/interface bridge port mst-override
add identifier=1 interface=ether2 internal-path-cost=5
add identifier=1 interface=ether3 internal-path-cost=9

In this case for VLAN 10,20 to reach the third device from the first device, it would choose between ether1 and ether2, one port will be blocked and set as an alternate port, and ether1 will have path cost as 5+9=14 and ether2 will have path cost as 10, ether2 will be elected as the root port for MSTI1 on the third device. In case for VLAN 30,40 to reach the first device from the third device, ether1 will have path cost as 5+9=14 and ether2 will have path cost as 15, ether1 will be elected as the root port for MSTI2 on the third device.

Now we can configure the root ports for MSTI0, which will fall under all VLANs that are not assigned to a specific MST Instance, like in our example VLAN 10,20, and VLAN 30,40. To configure this special MST Instance, you will need to specify internal-path-cost to a bridge port. This value is only relevant to MSTP regions, it does not have any effect outside an MSTP region. In this example will choose that all unknown VLANs will be forwarded over the same path as VLAN 30,40, we will simply increase the path cost on one of the ports.

    Use the following commands on R1_3, R2_3, R3_3:

/interface bridge port
set [find where interface=ether3] internal-path-cost=25

At this point, a single region MSTP can be considered as configured, and in general, MSTP is fully functional. It is highly recommended to configure the CIST part, but for testing purposes, it can be left with the default values. Before doing any tests, you need to enable MSTP on all bridges.

    Use the following commands on all devices:

/interface bridge
set bridge protocol-mode=mstp vlan-filtering=yes

When MSTP regions have been configured, you can check if they are properly configured by forwarding traffic, for example, send tagged traffic from the first device to the third device and change the VLAN ID for the tagged traffic to observe different paths based on VLAN ID. When this is working as expected, then you can continue to configure CIST related parameters to elect a CIST root bridge and CIST root ports. For consistency we will choose the first device in the first region to be the CIST root bridge and to ensure consistency in case of failure we can set a higher priority to all other bridges.

    Use the following commands on R1_1:

/interface bridge
set bridge priority=0x1000

    Use the following commands on R1_2:

/interface bridge
set bridge priority=0x2000

    ...

    Use the following commands on R3_3:

/interface bridge
set bridge priority=0x9000

We also need to elect a root port on each bridge, for simplicity we will choose the port that is closest to Ŗ1_1 as the root port and has the least hops. At this point, the procedure to elect root ports is the same as the procedure in (R)STP.

    Use the following commands on R3_3:

/interface bridge port
set [find where interface=ether2] path-cost=30
set [find where interface=ether3] path-cost=40
set [find where interface=ether4] path-cost=20

    Use the following commands on R1_3 and R2_3:

/interface bridge port
set [find where interface=ether2] path-cost=20
set [find where interface=ether3] path-cost=30

    Use the following commands on R1_2:

/interface bridge port
set [find where interface=ether1] path-cost=30



    Creado por Usuario desconocido (emils), actualizado por última vez por GG el abr 17, 2024 3 min de lectura

Summary

A very common task is to forward only a certain set of VLANs over a Wireless Point-to-Point (PtP) link. This can be done using bridge VLAN filtering and should be used instead of any other methods (including bridging VLAN interfaces). Let's say we need to forward over a Wireless link to 2 different VLANs and all other VLAN IDs should be dropped. VLAN 10 is going to be our Internet traffic while VLAN 99 is going to be for our management traffic. Below you can find the network topology:

Configuration

Start by creating a new bridge on AP and ST and add ether1 and wlan1 ports to it:
/interface bridge
add name=bridge protocol-mode=none
/interface bridge port
add bridge=bridge interface=ether1
add bridge=bridge interface=wlan1


You can enable RSTP if it is required, but generally, RSTP is not required for PtP links since there should not be any way for a loop to occur.


For security reasons you should enable ingress-filtering since you are expecting only tagged traffic, then you can set the bridge to filter out all untagged traffic. Do the following on AP and ST:
/interface bridge port
set [find where interface=ether1 or interface=wlan1] frame-types=admit-only-vlan-tagged ingress-filtering=yes


Set up the bridge VLAN table. Since VLAN99 is going to be our management traffic, then we need to allow this VLAN ID to be able to access the bridge interface, otherwise, the traffic will be dropped as soon as you will try to access the device. VLAN10 does not need to access the bridge since it is only meant to be forwarded to the other end. To achieve such functionality add these entries to the bridge VLAN table on AP and ST:


/interface bridge vlan
add bridge=bridge tagged=ether1,wlan1 vlan-ids=10
add bridge=bridge tagged=ether1,wlan1,bridge vlan-ids=99


You can limit from which interfaces it will be allowed to access the device. For example, if you don't want the device to be accessible from wlan1, then you can remove the interface from the corresponding bridge VLAN entry.

For devices with hardware offloaded VLAN filtering and wireless interface support (e.g. RB4011 with RTL8367 switch chip, or LtAP with MT7621 switch chip), more attention needs to be paid. Packets going from HW offloaded ports to wireless can be filtered, if the VLAN access to the CPU is not allowed. It is possible to allow CPU access for a certain VLAN by adding the bridge interface as a VLAN member (similar to the VLAN99 example) or disabling HW offloading on bridge ports.


All devices (R1, R2, AP, and ST) need a VLAN interface created to be able to access the device through the specific VLAN ID. For AP and ST create the VLAN interface on top of the bridge interface and assign an IP address to it:
/interface vlan
add interface=bridge name=MGMT vlan-id=99
/ip address
add address=192.168.99.X/24 interface=MGMT

For R1 and R2 do the same, but the interface, on which you need to create the VLAN interface, will probably change, depending on your setup:
/interface vlan
add interface=ether1 name=MGMT vlan-id=99
/ip address
add address=192.168.99.X/24 interface=MGMT


To allow more VLANs to be forwarded, you simply need to specify more VLAN IDs in the bridge VLAN table, you can specify multiple VLANs divided by coma or even VLAN ranges.


Setup the Wireless link on AP:
/interface wireless security-profiles
add authentication-types=wpa2-psk mode=dynamic-keys name=wlan_sec wpa2-pre-shared-key=use_a_long_password_here
/interface wireless
set wlan1 band=5ghz-a/n/ac channel-width=20/40/80mhz-Ceee disabled=no mode=bridge scan-list=5180 security-profile=wlan_sec ssid=ptp_test

Setup the Wireless link on ST:
/interface wireless security-profiles
add authentication-types=wpa2-psk mode=dynamic-keys name=wlan_sec wpa2-pre-shared-key=use_a_long_password_here
/interface wireless
set wlan1 band=5ghz-a/n/ac channel-width=20/40/80mhz-Ceee disabled=no mode=station-bridge scan-list=5180 security-profile=wlan_sec ssid=ptp_test


For each type of setup, there are different requirements, for PtP links NV2 wireless protocol is commonly used. You can read more about NV2 on the NV2 Manual page.

When links are set up, you can enable bridge VLAN filtering on AP and ST:
/interface bridge
set bridge vlan-filtering=yes


Double-check the bridge VLAN table before enabling VLAN filtering. A misconfigured bridge VLAN table can lead to the device being inaccessible and a configuration reset might be required.




    Creado por Edgars P., actualizado por última vez por GG el abr 17, 2024 7 min de lectura

    How WMM works
    How VLAN priority works
    How to set priority
        Set VLAN or WMM priority based on specific matchers
        Custom priority mapping
        Translating WMM priority to VLAN priority inside a bridge
    Priority from DSCP
        Set VLAN or WMM priority from DSCP
    DSCP from Priority
        Set DSCP from VLAN or WMM priority
    Combining priority setting and handling solutions
    See also

How WMM works

WMM works by dividing traffic into 4 access categories: background, best effort, video, voice. QoS policy (different handling of access categories) is applied on transmitted packets, therefore the transmitting device is treating different packets differently, e.g. AP does not have control over how clients are transmitting packets, and clients do not have control over how AP transmits packets.

Mikrotik AP and client classify packets based on the priority assigned to them, according to the table (as per WMM specification): 1,2 - background 0,3 - best effort 4,5 - video 6,7 - voice.

To be able to use multiple WMM access categories, not just the best effort where all packets with default priority 0 go, priority must be set for those packets. By default, all packets (incoming and locally generated) inside the router have priority 0.

The "Better" access category for a packet does not necessarily mean that it will be sent over the air before all other packets with the "worse" access category. WMM works by executing the DCF method for medium access with different settings for each access category (EDCF), which means that the "better" access category has a higher probability of getting access to medium - WMM enabled station can be considered to be 4 stations, one per access category, and the ones with "better" access category use settings that make them more likely to get chance to transmit (by using shorter backoff timeouts) when all are contending for medium. Details can be studied in 802.11e and WMM specifications.

WMM support can be enabled using the wmm-support setting. It only applies to bands B and G. Other bands will have it enabled regardless of this setting 
How VLAN priority works

The VLAN priority is a 3-bit field called Priority Code Point (PCP) within a VLAN-tagged header and values are between 0 and 7. It is used for implementing QoS on bridges and switches. MikroTik devices by default are sending VLAN packets (locally generated or encapsulated) with a priority of 0. The RouterOS bridge forwards VLAN tagged packets unaltered, which means that received VLAN tagged packets with a certain VLAN priority will leave the bridge with the same VLAN priority. The only exception is when the bridge untags the packet, in this situation VLAN priority is not preserved due to the missing VLAN header. 

More details can be studied in the IEEE 802.1p specification.
How to set priority

Priority of packets can be set using action=set-priority in IP firewall mangle rules or bridge filter/nat rules. Priority can be set to a specific value or taken from the ingress priority using the from-ingress setting. Ingress priority is the priority value that was detected on the incoming packet, if available. Currently, there are 2 sources of ingress priority - priority in the VLAN header and priority from the WMM packet received over a wireless interface. For all other packets ingress priority is 0.

Note that ingress priority value is not automatically copied to IP mangle priority value, the correct rule needs to be set up to do this.

There are 2 ways to control priority - assign priority with rules with particular matchers (protocol, addresses, etc.) or set it from ingress priority. Both options require setting up correct rules.

This essentially means that if it is not possible or wanted to classify packets by rules, the configuration of the network must be such that the router can extract ingress priority from incoming frames. Remember there are currently 2 sources for this - VLAN tag in packets and received WMM packets.

Do not mix the priority of queues with the priority assigned to packets. Priorities of queues work separately and specify the "importance" of the queue and have meaning only within a particular queue setup. Think of packet priority as some kind of mark, that gets attached to the packet by rules. Also, take into account that this mark currently is only used for outgoing packets when going over WMM enabled link, and in case VLAN tagged packet is sent out (no matter if that packet is tagged locally or bridged).
Set VLAN or WMM priority based on specific matchers

It is possible to change the VLAN and WMM priorities based on specific matchers in IP mangle or bridge filter/nat rules. In this example, all outgoing ICMP packets will be sent with a VLAN or WMM priority using the IP mangle rule:
/ip firewall mangle
add action=set-priority chain=output new-priority=2 protocol=icmp
Custom priority mapping

Sometimes certain VLAN or WMM priorities need to be changed or cleared to a default value. We can use the ingress-priority matcher in IP mangle or bridge firewall/nat rules to filter only the needed priorities and change them to a different value using the new-priority action setting. For example, forwarded VLAN tagged packets over a bridge with a priority of 5, need to be changed to 0.
/interface bridge filter
add action=set-priority chain=forward ingress-priority=5 new-priority=0
Translating WMM priority to VLAN priority inside a bridge

When a wireless packet is received with an already set WMM priority, the RouterOS bridge does not automatically translate it to a VLAN header. It means, that received wireless packets with WMM priority that get VLAN tagged by the bridge will be forwarded with a VLAN priority of 0. However, we can use a bridge filter rule with from-ingress setting to keep the priority in VLAN packets. For example, we would like to forward wireless packets over ether2 with a VLAN 10 header and keep the already set WMM priority (set by the wireless client).
/interface bridge
add name=bridge1 vlan-filtering=yes
/interface bridge port
add bridge=bridge1 interface=ether2
add bridge=bridge1 interface=wlan2 pvid=10
/interface bridge vlan
add bridge=bridge1 tagged=ether2 vlan-ids=10

# translates WMM priority to VLAN priority 
/interface bridge filter
add action=set-priority chain=forward new-priority=from-ingress out-interface=ether2

The same situation applies when wireless packets are VLAN tagged by the wireless interface using the vlan-mode=use-tag and vlan-id settings. You still need to use the same bridge filter rule to translate WMM priority to VLAN priority:
/interface wireless
set [ find default-name=wlan2 ] vlan-mode=use-tag vlan-id=10

/interface bridge
add name=bridge1
/interface bridge port
add bridge=bridge1 interface=ether2
add bridge=bridge1 interface=wlan2

 # translates WMM priority to VLAN priority 
/interface bridge filter
add action=set-priority chain=forward new-priority=from-ingress out-interface=ether2

The same principles apply in the other direction. RouterOS does not automatically translate VLAN priority to WMM priority. The same rule new-priority=from-ingress can be used to translate VLAN priority to WMM priority. 

The RouterOS bridge forwards VLAN tagged packets unaltered, which means that received VLAN tagged packets with a certain VLAN priority will leave the bridge with the same VLAN priority. The only exception is when the bridge untags the packet, in this situation VLAN priority is not preserved due to the missing VLAN header. 
Priority from DSCP

Another way of setting VLAN or WMM priority is by using the DSCP field in the IP header, this can only be done by the IP firewall mangle rule with new-priority=from-dscp or new-priority=from-dscp-high-3-bits settings and set-priority action property. Note that DSCP in the IP header can have values 0-63, but priority only 0-7. When using the new-priority=from-dscp setting, the priority will be 3 low bits of the DSCP value, but when using new-priority=from-dscp-high-3-bits the priority will be 3 high bits of DSCP value.

Remember that DSCP can only be accessed on IP packets and the DSCP value in the IP header should be set somewhere (either by client devices or IP mangle rules).

It is best to set the DSCP value in the IP header of packets on some border router (e.g. main router used for connection to the Internet), based on traffic type e.g. set DSCP value for packets coming from the Internet belonging to SIP connections to 7, and 0 for the rest. This way packets must be marked only in one place. Then all APs on the network can set packet priority from the DSCP value with just one rule.
Set VLAN or WMM priority from DSCP

In this example, the AP device will set WMM priority from DSCP when packets are routed through the wireless interface.
/ip firewall mangle
add action=set-priority chain=forward new-priority=from-dscp out-interface=wlan2


When packets are forwarded through a bridge, it is possible to pass packets through IP mangle rules with use-ip-firewall=yes under the bridge settings.
DSCP from Priority

Similarly, the DSCP value can be set if the received packet contains VLAN or WMM priority. This can be achieved with IP mangle rules with new-dscp=from-priority or new-dscp=from-priority-to-high-3-bits settings and change-dscp action property. Note that priority in VLAN or WMM packets can have values 0-7, but DSCP in IP headers are 0-63. When using the new-dscp=from-priority setting, the value of priority will set the 3 low bits of the DSCP, but when using new-dscp=from-priority-to-high-3-bits  the value of priority will set the 3 high bits of the DSCP. 

However, this setting cannot directly use ingress priority from received VLAN or WMM packets. You first need to set priority using IP mangle or bridge filter/nat rules (ingress priority can be used in this case), and only then apply the DSCP rule.
Set DSCP from VLAN or WMM priority

In this example, the AP device needs to set DSCP from WMM priority when packets are routed. First, add a rule to set priority, it will be needed for the DSCP rule to correctly change the DSCP value. This rule can take priority from ingress. Then add the DSCP rule to change its value.
/ip firewall mangle
add action=set-priority chain=prerouting in-interface=wlan2 new-priority=from-ingress
add action=change-dscp chain=prerouting in-interface=wlan2 new-dscp=from-priority

When packets are forwarded through a bridge, it is possible to pass packets through IP mangle rules with use-ip-firewall=yes under the bridge settings.
Combining priority setting and handling solutions

Complex networks and different situations can be handled by combining different approaches of carrying priority information to ensure QoS and optimize the use of resources, based on the "building blocks" described above. Several suggestions:

    The fewer number of filter rules in the whole network, the better (faster). Try classifying packets only when necessary, prefer to do that on fast routers as most probably connection tracking will be required.
    Use DSCP to carry priority information in IP packets forwarded in your network, this way you can use it when needed.
    Use VLANs where necessary, as they also carry priority information, make sure Ethernet bridges and switches in the way are not clearing priority information in the VLAN tag.
    Remember that QoS does not improve the throughput of links, it just treats different packets differently, and also that WMM traffic over the wireless link will discriminate regular traffic in the air.

See also

    Packet Flow in RouterOS
    IP mangle
    Bridge firewall





Firewall and Quality of Service

    Creado por Usuario desconocido (emils), actualizado por última vez por Māris B. el may 24, 2024 1 min de lectura

In This Section:

        Connection tracking
        Firewall
        Packet Flow in RouterOS
        Queues
        Firewall and QoS Case Studies
        Kid Control
        UPnP
        NAT-PMP
        IP Services








    Creado por Artūrs C., actualizado por última vez por Mārtiņš S. el may 28, 2025 6 min de lectura

    Introduction
    Connection states
    FastTrack
        Requirements
        Example
    Connection tracking settings
        Properties
    Connection List
        Properties

Introduction


Connection tracking allows the kernel to keep track of all logical network connections or sessions, and thereby relate all of the packets which may make up that connection.

NAT relies on this information to translate all related packets in the same way. 

Because of connection tracking you can use stateful firewall functionality even with stateless protocols such as UDP.

Firewall features affected by connection tracking:

    NAT
    firewall:
        connection-bytes
        connection-mark
        connection-type
        connection-state
        connection-limit
        connection-rate
        layer7-protocol
        new-connection-mark
        tarpit

List of tracked connections can be seen in /ip firewall connection for IPv4 and /ipv6 firewall connection for IPv6.
      [admin@3C22-atombumba] /ip firewall connection> print
      Flags: S - seen-reply, A - assured
      #    PR.. SRC-ADDRESS           DST-ADDRESS           TCP-STATE   TIMEOUT
      0    udp  10.5.8.176:5678       255.255.255.255:5678              0s
      1    udp  10.5.101.3:646        224.0.0.2:646                     5s
      2    ospf 10.5.101.161          224.0.0.5                         9m58s
      3    udp  10.5.8.140:5678       255.255.255.255:5678              8s
      4 SA tcp  10.5.101.147:48984    10.5.101.1:8291       established 4m59s
      [admin@3C22-atombumba] /ipv6 firewall connection> print
      Flags: S - seen reply, A - assured
      #    PRO.. SRC-ADDRESS                 DST-ADDRESS                 TCP-STATE
      0    udp   fe80::d6ca:6dff:fe77:3698   ff02::1
      1    udp   fe80::d6ca:6dff:fe98:7c28   ff02::1
      2    ospf  fe80::d6ca:6dff:fe73:9822   ff02::5
Connection states

Based on connection table entries arrived packet can get assigned one of the connection states: new, invalid, established, related, or untracked.

There are two different methods when the packet is considered new. The first one is in the case of stateless connections (like UDP) when there is no connection entry in the connection table. The other one is in the case of a stateful protocol (TCP). In this case, a new packet that starts a new connection is always a TCP packet with an SYN flag.

If a packet is not new it can belong to either an established or related connection or not belong to any connection making it invalid. A packet with an established state, as most of you already guessed, belongs to an existing connection from the connection tracking table. A related state is very similar, except that the packet belongs to a connection that is related to one of the existing connections, for example, ICMP error packets or FTP data connection packets.

Connection state notrack is a special case when RAW firewall rules are used to exclude connection from connection tracking. This rule would make all forwarded traffic bypass the connection tracking, improving packet processing speed through the device.

Any other packet is considered invalid and in most cases should be dropped.

Based on this information we can set a basic set of filter rules to speed up packet filtering and reduce the load on the CPU by accepting established/related packets, dropping invalid packets, and working on more detailed filtering only for new packets.
ip firewall filter
add chain=input connection-state=invalid action=drop comment="Drop Invalid connections"
add chain=input connection-state=established,related,untracked action=accept comment="Allow Established/Related/Untracked connections

Such a rule set must not be applied on routers with asymmetric routing, because asymmetrically routed packets may be considered invalid and dropped.
FastTrack

IPv4 FastTrack is a special handler that bypasses Linux facilities allowing for faster packet forwarding. The handler is used for TCP and UDP connections marked with "fasttrack-connection" action. IPv4 FastTrack handler supports NAT (SNAT, DNAT, or both).

Note that not all packets of the connection can be FastTracked, so it is likely to see some packets going through a slow path even though the connection is marked for FastTrack. This is the reason why fasttrack-connection is usually followed by an identical "action=accept" rule.

FastTrack-ed packets are bypassing:

     firewall,
    connection tracking,
    simple queues,
    queue tree with parent=global,
    IP accounting,
    IPSec,
    hotspot universal client,
    VRF assignment

It is up to the administrator to make sure FastTrack does not interfere with other configuration.
Requirements

IPv4 FastTrack is active if the following conditions are met:

    no mesh, metarouter interface configuration;
    sniffer, torch, or traffic generator is not running;
    /tool mac-scan is not actively used;
    /tool ip-scan is not actively used;
    FastPath and Route cache is enabled under IP/Settings

Example

For example, for SOHO routers with factory default configuration, you could FastTrack all LAN traffic with this one rule placed at the top of the Firewall Filter. The same configuration accept rule is required:
/ip firewall filter add chain=forward action=fasttrack-connection connection-state=established,related
/ip firewall filter add chain=forward action=accept connection-state=established,related

    Connection is FastTracked until the connection is closed, timed-out, or router is rebooted.
    Dummy rules will disappear only after FastTrack firewall rules will be deleted/disabled and the router rebooted.
    While FastPath and FastTrack both are enabled on the device only one can be active at a time.


Queues (except Queue Trees parented to interfaces), firewall filter, and mangle rules will not be applied for FastTracked traffic.
Connection tracking settings

Connection tracking settings are managed from /ip firewall connection tracking menu.
Properties
enabled (yes | no | auto; Default: auto)	Allows to disable or enable connection tracking. With disabled connection tracking  firewall features listed above will stop working. If set to "auto" connection tracking is disabled until at least one firewall rule is added.
loose-tcp-tracking (yes; Default: yes)	

    In case loose-tcp-tracking=yes, the 2nd part (SYN,ACK) and 3rd part (ACK) of the handshake without having seen the first initial SYN will be considered ESTABLISHED
    In case loose-tcp-tracking=no, the 2nd part (SYN,ACK) and 3rd part (ACK) without having seen the first initial SYN will be considered INVALID

tcp-syn-sent-timeout (time; Default: 5s)	TCP SYN timeout.
tcp-syn-received-timeout (time; Default: 5s)	TCP SYN timeout.
tcp-established-timeout (time; Default: 1d)	Time after which established TCP connection times out.
tcp-fin-wait-timeout (time; Default: 10s)	
tcp-close-wait-timeout (time; Default: 10s)	
tcp-last-ack-timeout (time; Default: 10s)	
tcp-time-wait-timeout (time; Default: 10s)	
tcp-close-timeout (time; Default: 10s)	
udp-timeout (time; Default: 30s)	Specifies the timeout for UDP connections that have seen packets in one direction
udp-stream-timeout (time; Default: 3m)	Specifies the timeout of UDP connections that have seen packets in both directions
icmp-timeout (time; Default: 10s)	ICMP connection timeout
generic-timeout (time; Default: 10m)	Timeout for all other connection entries


Read-only properties
max-entries (integer)	

Max amount of entries that the connection tracking table can hold. This value depends on the installed amount of RAM.

Note that the system does not create a maximum-size connection tracking table when it starts, it may increase if the situation demands it and the system still has free RAM, but the size will not exceed 1048576
total-entries (integer)	Amount of connections that the connection table currently holds


Connection List

List of tracked connections ban be seen in /ip firewall connection for ipv4 and /ipv6 firewall connection for IPv6.
Properties

All properties in the connection list are read-only
assured (yes | no)	Indicates that this connection is assured and that it will not be erased if the maximum possible tracked connection count is reached.
confirmed (yes | no)	Connection is confirmed and a packet is sent out from the device
connection-mark (string)	Connection mark that was set by the mangle rule.
connection-type (pptp | ftp)	Type of connection, the property is empty if connection tracking is unable to determine a predefined connection type.
dst-address (ip)	Destination address.
dst-port (integer)	Destination port.
dstnat (yes | no)	A connection has gone through DST-NAT (for example, port forwarding).
dying (yes | no)	The connection is dying due to a connection timeout.
expected (yes | no)	Connection is set up using connection helpers (pre-defined service rules).
fasttrack (yes | no)	Whether the connection is FastTracked.
gre-key (integer)	Contents of the GRE Key field.
gre-protocol (string)	Protocol of the encapsulated payload.
gre-version (string)	A version of the GRE protocol was used in the connection.
connection-mark (string)	Connection mark assigned for the connection from firewall.
hw-offload (yes | no)	Hardware offloaded connection.
icmp-code (string)	ICMP Code Field
icmp-id (integer)	Contains the ICMP ID
icmp-type (integer)	ICMP Type Number
orig-bytes (integer)	Amount of bytes sent out from the source address using the specific connection.
orig-fasttrack-bytes (integer)	Amount of FastTracked bytes sent out from the source address using the specific connection.
orig-fasttrack-packets (integer)	Amount of FastTracked packets sent out from the source address using the specific connection.
orig-packets (integer)	Amount of packets sent out from the source address using the specific connection.
orig-rate (integer)	The data rate at which packets are sent out from the source address using the specific connection.
protocol (string)	IP protocol type
repl-bytes (integer)	Amount of bytes received from the destination address using the specific connection.
repl-fasttrack-bytes (string)	Amount of FastTracked bytes received from the destination address using the specific connection.
repl-fasttrack-packets (integer)	Amount of FastTracked packets received from the destination address using the specific connection.
repl-packets (integer)	Amount of packets received from the destination address using the specific connection.
repl-rate (string)	The data rate at which packets are received from the destination address using the specific connection.
reply-dst-address (ip)	Destination address expected of return packets.
reply-dst-port (integer)	Destination port expected of return packets.
reply-src-address (ip)	Source address expected of return packets.
reply-src-port (integer)	Source port expected of return packets.
seen-reply (yes | no)	The destination address has replied to the source address.
src-address (ip)	The source address.
src-port (integer)	The source port.
srcnat (yes | no)	Connection is going through SRC-NAT, including packets that were masqueraded through NAT.
tcp-state (string)	The current state of TCP connection :

    "established"
    "time-wait"
    "close"
    "syn-sent"
    "syn-recv"
    "fin-wait"
    "close-wait"
    "last-ack"
    "listen"

timeout (time)	Time after connection will be removed from the connection list.





    Creado por Māris B., actualizado por última vez el may 24, 2024 3 min de lectura

The firewall implements stateful (by utilizing connection tracking) and stateless packet filtering and thereby provides security functions that are used to manage data flow to, from, and through the router. Along with the Network Address Translation (NAT), it serves as a tool for preventing unauthorized access to directly attached networks and the router itself as well as a filter for outgoing traffic.

Network firewalls keep outside threats away from sensitive data available inside the network. Whenever different networks are joined together, there is always a threat that someone from outside of your network will break into your LAN. Such break-ins may result in private data being stolen and distributed, valuable data being altered or destroyed, or entire hard drives being erased. Firewalls are used as a means of preventing or minimizing the security risks inherent in connecting to other networks. A properly configured firewall plays a key role in efficient and secure network infrastructure deployment.

MikroTik RouterOS has very powerful firewall implementation with features including:

    stateless packet inspection
    stateful packet inspection 
    Layer-7 protocol detection
    peer-to-peer protocols filtering
    traffic classification by:
        source MAC address
        IP addresses (network or list) and address types (broadcast, local, multicast, unicast)
        port or port range
        IP protocols
        protocol options (ICMP type and code fields, TCP flags, IP options and MSS)
        interface the packet arrived from or left through
        internal flow and connection marks
        DSCP byte
        packet content
        rate at which packets arrive and sequence numbers
        packet size
        packet arrival time

and much more!

Firewall is split in three major modules:

    filter/raw - used to deny traffic based on configured policies. Filtering in RAW tables allow to save resources if connection tracking is not required. 
    mangle - used to mark certain connections, packets, streams, set priorities and do other tasks
    nat - used to set up address translation rules redirects and port forwarding

Chains

Firewall filtering rules are grouped together in chains. It allows a packet to be matched against one common criterion in one chain, and then passed over for processing against some other common criteria to another chain.

For example, a packet should be matched against the IP address:port pair. Of course, it could be achieved by adding as many rules with IP address:port match as required to the forward chain, but a better way could be to add one rule that matches traffic from a particular IP address. Then rules that perform matching against separate ports can be added to "mychain" chain without specifying the IP addresses.
/ip firewall filter 
add chain=mychain protocol=tcp dst-port=22 action=accept
add chain=mychain protocol=tcp dst-port=23 action=accept

add chain=input src-address=1.1.1.2/32 jump-target="mychain"


When processing a chain, rules are taken from the chain in the order they are listed, from top to bottom. If a packet matches the criteria of the rule, then the specified action is performed on it, and no more rules are processed in that chain (the exception is the passthrough action).

If a packet has not matched any rule within the chain, then it is accepted. 

Each firewall module has its own pre-defined chains:

    raw:
        prerouting
        output
    filter
        input
        forward
        output
    mangle
        prerouting
        input
        forward
        output
        postrouting
    nat
        srcnat
        dstnat


More detailed packet processing in RouterOS is described in the Packet Flow in the RouterOS diagram.



    Creado por Artūrs C., actualizado por última vez por GG el ago 13, 2024 7 min de lectura

    Introduction
    Firewall Example
        IPv4 firewall 
            Protect the router itself
            Protect the LAN devices
        IPv6 firewall 
            Protect the router itself
            Protect the LAN devices
    Matchers
    Actions
    RAW Filtering
        Basic RAW Example
    Read More

Introduction

Firewall filters are used to allow or block specific packets forwarded to your local network, originating from your router, or destined to the router.

There are two methods on how to set up filtering:

    allow specific traffic and drop everything else
    drop only malicious traffic, everything else is allowed.

Both methods have pros and cons, for example, from a security point of view first method is much more secure, but requires administrator input whenever traffic for a new service needs to be accepted. This strategy provides good control over the traffic and reduces the possibility of a breach because of service misconfiguration.

On the other hand, when securing a customer network it would be an administrative nightmare to accept all possible services that users may use. Therefore careful planning of the firewall is essential in advanced setups.

A firewall filter consists of three predefined chains that cannot be deleted:

    input - used to process packets entering the router through one of the interfaces with the destination IP address which is one of the router's addresses. Packets passing through the router are not processed against the rules of the input chain
    forward - used to process packets passing through the router
    output - used to process packets originating from the router and leaving it through one of the interfaces. Packets passing through the router are not processed against the rules of the output chain

Firewall filter configuration is accessible from ip/firewall/filter menu for IPv4 and ipv6/firewall/filter menu for IPv6.
Firewall Example

Lets look at basic firewall example to protect router itself and clients behind the router, for both IPv4 and IPv6 protocols.
IPv4 firewall 
Protect the router itself

Rules of thumb followed to set up the firewall:

    work with new connections to decrease the load on a router;
    accept what you need
    drop everything else, log=yes could be set to log some attackers, but keep in mind that it may add some load to he CPU on heavy attacks.


We always start by accepting already known and accepted connections, so the first rule should be to accept "established" and "related" connections.
/ip firewall filter
add action=accept chain=input comment="default configuration" connection-state=established,related

Now we can proceed by accepting some new connections, in our example we want to allow access ICMP protocol from any address and everything else only from 192.168.88.2-192.168.88.254 address range. For that we create an address list and two firewall rules.
/ip firewall address-list
add address=192.168.88.2-192.168.88.254 list=allowed_to_router
/ip firewall filter
add action=accept chain=input src-address-list=allowed_to_router
add action=accept chain=input protocol=icmp

And lastly we drop everything else:
add action=drop chain=input


Complete set of just created rules:
/ip firewall filter
add action=accept chain=input comment="default configuration" connection-state=established,related
add action=accept chain=input src-address-list=allowed_to_router
add action=accept chain=input protocol=icmp
add action=drop chain=input
/ip firewall address-list
add address=192.168.88.2-192.168.88.254 list=allowed_to_router


Protect the LAN devices

Concept in protecting the users is very similar, except that in this case we are blocking unwanted traffic and accepting everythign else.

At first we will create address-list with the name "not_in_internet" which we will use for the firewall filter rules:
/ip firewall address-list
add address=0.0.0.0/8 comment=RFC6890 list=not_in_internet
add address=172.16.0.0/12 comment=RFC6890 list=not_in_internet
add address=192.168.0.0/16 comment=RFC6890 list=not_in_internet
add address=10.0.0.0/8 comment=RFC6890 list=not_in_internet
add address=169.254.0.0/16 comment=RFC6890 list=not_in_internet
add address=127.0.0.0/8 comment=RFC6890 list=not_in_internet
add address=224.0.0.0/4 comment=Multicast list=not_in_internet
add address=198.18.0.0/15 comment=RFC6890 list=not_in_internet
add address=192.0.0.0/24 comment=RFC6890 list=not_in_internet
add address=192.0.2.0/24 comment=RFC6890 list=not_in_internet
add address=198.51.100.0/24 comment=RFC6890 list=not_in_internet
add address=203.0.113.0/24 comment=RFC6890 list=not_in_internet
add address=100.64.0.0/10 comment=RFC6890 list=not_in_internet
add address=240.0.0.0/4 comment=RFC6890 list=not_in_internet
add address=192.88.99.0/24 comment="6to4 relay Anycast [RFC 3068]" list=not_in_internet

Brief firewall filter rule explanation:

    packets with connection-state=established,related added to FastTrack for faster data throughput, the firewall will work with new connections only;
    drop invalid connection and log them with prefix "invalid";
    drop attempts to reach not public addresses from your local network, apply address-list=not_in_internet before, "bridge" is local network interface, log=yes attempts with prefix "!public_from_LAN";
    drop incoming packets that are not NAT`ed, ether1 is public interface, log attempts with "!NAT" prefix;
    jump to ICMP chain to drop unwanted ICMP messages
    drop incoming packets from the Internet, which are not public IP addresses, ether1 is a public interface, log attempts with prefix "!public";
    drop packets from LAN that does not have LAN IP, 192.168.88.0/24 is local network used subnet;

/ip firewall filter
add action=fasttrack-connection chain=forward comment=FastTrack connection-state=established,related
add action=accept chain=forward comment="Established, Related" connection-state=established,related
add action=drop chain=forward comment="Drop invalid" connection-state=invalid log=yes log-prefix=invalid
add action=drop chain=forward comment="Drop tries to reach not public addresses from LAN" dst-address-list=not_in_internet in-interface=bridge log=yes log-prefix=!public_from_LAN out-interface=!bridge
add action=drop chain=forward comment="Drop incoming packets that are not NAT`ted" connection-nat-state=!dstnat connection-state=new in-interface=ether1 log=yes log-prefix=!NAT
add action=jump chain=forward protocol=icmp jump-target=icmp comment="jump to ICMP filters"
add action=drop chain=forward comment="Drop incoming from internet which is not public IP" in-interface=ether1 log=yes log-prefix=!public src-address-list=not_in_internet
add action=drop chain=forward comment="Drop packets from LAN that do not have LAN IP" in-interface=bridge log=yes log-prefix=LAN_!LAN src-address=!192.168.88.0/24

Allow only needed ICMP codes in "icmp" chain:
/ip firewall filter
  add chain=icmp protocol=icmp icmp-options=0:0 action=accept \
    comment="echo reply"
  add chain=icmp protocol=icmp icmp-options=3:0 action=accept \
    comment="net unreachable"
  add chain=icmp protocol=icmp icmp-options=3:1 action=accept \
    comment="host unreachable"
  add chain=icmp protocol=icmp icmp-options=3:4 action=accept \
    comment="host unreachable fragmentation required"
  add chain=icmp protocol=icmp icmp-options=8:0 action=accept \
    comment="allow echo request"
  add chain=icmp protocol=icmp icmp-options=11:0 action=accept \
    comment="allow time exceed"
  add chain=icmp protocol=icmp icmp-options=12:0 action=accept \
    comment="allow parameter bad"
  add chain=icmp action=drop comment="deny all other types"

IPv6 firewall 
Protect the router itself

Very similar to IPv4 setup, except that we have to deal with more protocols required for IPv6 to function properly.

At first we create an address-list from which you allow access to the device:
/ipv6 firewall address-list add address=fd12:672e:6f65:8899::/64 list=allowed

Brief IPv6 firewall filter rule explanation:

    work with new packets, accept established/related packets;
    drop link-local addresses from Internet(public) interface/interface-list;
    accept access to a router from link-local addresses, accept multicast addresses for management purposes, accept your source address-list for router access;
    drop anything else;

/ipv6 firewall filter
add action=accept chain=input comment="allow established and related" connection-state=established,related
add chain=input action=accept protocol=icmpv6 comment="accept ICMPv6"
add chain=input action=accept protocol=udp port=33434-33534 comment="defconf: accept UDP traceroute"
add chain=input action=accept protocol=udp dst-port=546 src-address=fe80::/10 comment="accept DHCPv6-Client prefix delegation."
add action=drop chain=input in-interface=in_interface_name log=yes log-prefix=dropLL_from_public src-address=fe80::/10
add action=accept chain=input comment="allow allowed addresses" src-address-list=allowed
add action=drop chain=input
/ipv6 firewall address-list
add address=fe80::/16 list=allowed
add address=xxxx::/48 list=allowed
add address=ff02::/16 comment=multicast list=allowed

In certain setups where the DHCPv6 relay is used, the src address of the packets may not be from the link-local range. In that case, the src-address parameter of rule #4 must be removed or adjusted to accept the relay address.
Protect the LAN devices

This step is more important than it is for IPv4. In IPv4 setups clients mostly have addresses from local address range and are NATed to public IP, that way they are not directly reachable from the public networks. 

IPv6 is a different story. In most common setups, enabled IPv6 makes your clients available from the public networks, so proper firewall filter rules to protect your customers are mandatory.

In brief we will very basic LAN protection should:

    accept established/related and work with new packets;
    drop invalid packets;
    accept ICMPv6 packets;
    accept new connections originated only from your clients to the public network;
    drop everything else.

/ipv6 firewall filter
add action=accept chain=forward comment=established,related connection-state=established,related
add action=drop chain=forward comment=invalid connection-state=invalid log=yes log-prefix=ipv6,invalid
add action=accept chain=forward comment=icmpv6 in-interface=!in_interface_name protocol=icmpv6
add action=accept chain=forward comment="local network" in-interface=!in_interface_name src-address-list=allowed
add action=drop chain=forward log-prefix=IPV6


Matchers

All matcher properties are common and listed here.


Actions

Tables below shows list of filter specific actions and associated properties.  Other actions are listed here.


action (action name; Default: accept)	

    drop - silently drop the packet

    fasttrack-connection - process packets from a connection using FastPath by enabling FastTrack for the connection. IPv4 only.
    reject - drop the packet and send an ICMP reject message; this action allows ICMP reply specification, such as: prohibit or unreachable admin/host/network/port
    tarpit - captures and holds TCP connections (replies with SYN/ACK to the inbound TCP SYN packet). IPv4 only.

reject-with (icmp-no-route | icmp-admin-prohibited | icmp-not-neighbour | icmp-address-unreachable | icmp-port-unreachable | tcp-reset | icmp-err-src-routing-header | icmp-headers-too-long ; Default: icmp-no-route)	

Specifies ICMP error to be sent back if the packet is rejected. Applicable if action=reject

    icmp-no-route: sends ICMP address no-route message. ICMP type 2, code 0
    icmp-admin-prohibited: sends ICMP address prohibited message. ICMP type 2, code 1
    icmp-not-neighbour: sends ICMP address not-member message. ICMP type 2, code 2
    icmp-address-unreachable: sends ICMP address unreachable message. ICMP type 2, code 3
    icmp-port-unreachable: sends ICMP port unreachable message. ICMP type 2, code 4
    tcp-reset: sends ICMP resetting a TCP connection. ICMP type 2, code 6
    icmp-err-src-routing-header: sends ICMP Error in Source Routing Header message. ICMP type 2, code 7
    icmp-headers-too-long: sends ICMP Headers too long message. ICMP type 2, code 8

RAW Filtering

The firewall RAW table allows to selectively bypass or drop packets before connection tracking, that way significantly reducing the load on the CPU. The tool is very useful for DoS/DDoS attack mitigation.

RAW filter configuration is accessible from ip/firewall/raw menu for IPv4 and ipv6/firewall/raw menu for IPv6.

The RAW table does not have matchers that depend on connection tracking ( like connection-state, layer7, etc.).
If a packet is marked to bypass the connection tracking packet de-fragmentation will not occur.

Also RAW firewall can have rules only in two chains:

    prerouting - used to process any packet entering the router
    output - used to process packets originated from the router and leaving it through one of the interfaces. Packets passing through the router are not processed against the rules of the output chain

And has one specific action:
action (action name; Default: accept)	

    notrack - do not send a packet to connection tracking. Useful when you still need to use regular firewall, but do not require connection tracking.

Basic RAW Example

Let's assume that we have OSPF configuration, but due to connection tracking OSPF have adjacency problems. We can use RAW rules to fix this, by not sending OSPF packets to connection tracking.
/ip firewall raw 
add chain=prerouting protocol=ospf action=notrack
add chain=output protocol=ospf action=notrack
Read More

    Building advanced firewall
    Connection Rate
    SSH bruteforce protection
    Syn/DoS protection
	
	

    Creado por Artūrs C., actualizado por última vez por Usuario desconocido (elvijsi) el ene 20, 2025 4 min de lectura

    Introduction
    Configuration example
        Change MSS
        Marking Connections
    Mangle Actions

Introduction

Mangle is a kind of 'marker' that marks packets for future processing with special marks. Many other facilities in RouterOS make use of these marks, e.g. queue trees, NAT, routing. They identify a packet based on its mark and process it accordingly. The mangle marks exist only within the router, they are not transmitted across the network.

Additionally, the mangle facility is used to modify some fields in the IP header, like TOS (DSCP) and TTL fields.

Firewall mangle rules consist of five predefined chains that cannot be deleted:


    The PREROUTING chain: Rules in this chain apply to packets as they just arrive on the network interface;
    The INPUT chain: Rules in this chain apply to packets just before they’re given to a local process;
    The OUTPUT chain: The rules here apply to packets just after they’ve been produced by a process;
    The FORWARD chain: The rules here apply to any packets that are routed through the current host;
    The POSTROUTING chain: The rules in this chain apply to packets as they just leave the network interface;

Configuration example
Change MSS

It is a known fact that VPN links have a smaller packet size due to encapsulation overhead. A large packet with MSS that exceeds the MSS of the VPN link should be fragmented before sending it via that kind of connection. However, if the packet has a Don't Fragment flag set, it cannot be fragmented and should be discarded. On links that have broken path MTU discovery (PMTUD), it may lead to a number of problems, including problems with FTP and HTTP data transfer and e-mail services.

In the case of a link with broken PMTUD, a decrease of the MSS of the packets coming through the VPN link resolves the problem. The following example demonstrates how to decrease the MSS value via mangle:
/ip firewall mangle add out-interface=pppoe-out protocol=tcp tcp-flags=syn action=change-mss new-mss=1300 chain=forward tcp-mss=1301-65535
Marking Connections

Sometimes it is necessary to perform some actions on the packets belonging to specific connection (for example, to mark packets from/to specific host for queues), but inspecting each packets IP header is quite expensive task. We can use connection marks to optimize the setup a bit.
/ip firewall mangle 
add chain=forward in-interface=local src-address=192.168.88.123 connection-state=new action=mark-connection new-connection-mark=client_conn
add chain=forward connection-mark=client_conn action=mark-packet new-packet-mark=client_p

Warning: Packet marks are limited to a maximum of 4096 unique entries. Exceeding this limit will cause an error "bad new packet mark"
Mangle Actions

Table list mangle actions and associated properties. Other actions are listed here.
action (action name; Default: accept)	

    change-dscp - change the Differentiated Services Code Point (DSCP) field value specified by the new-dscp parameter
    change-mss - change the Maximum Segment Size field value of the packet to a value specified by the new-mss parameter
    change-ttl - change the Time to Live field value of the packet to a value specified by the new-ttl parameter
    clear-df - clear 'Do Not Fragment' Flag
    fasttrack-connection - shows fasttrack counters, useful for statistics
    mark-connection - place a mark specified by the new-connection-mark parameter on the entire connection that matches the rule
    mark-packet - place a mark specified by the new-packet-mark parameter on a packet that matches the rule
    mark-routing - place a mark specified by the new-routing-mark parameter on a packet. This kind of mark is used for policy routing purposes only. Do not apply any other routing marks besides "main" for the packets processed by FastTrack, since FastTrack can only work in the main routing table.
    route - forces packets to a specific gateway IP by ignoring normal routing decisions (prerouting chain only)
    set-priority - set priority specified by the new-priority parameter on the packets sent out through a link that is capable of transporting priority (VLAN or WMM-enabled wireless interface). Read more
    sniff-pc - send a packet to a remote RouterOS CALEA server.
    sniff-tzsp - send a packet to a remote TZSP compatible system (such as Wireshark). Set remote target with sniff-target and sniff-target-port parameters (Wireshark recommends port 37008)
    strip-ipv4-options - strip IPv4 option fields from IP header, the action does not actually remove IPv4 options but rather replaces all option octets with NOP, further matcher with ipv4-options=any will still match the packet.

new-dscp (integer: 0..63; Default: )	Sets a new DSCP value for a packet
new-mss (integer; Default: )	

Sets a new MSS for a packet.

Clamp-to-pmtu feature sets (DF) bit in the IP header to dynamically discover the PMTU of a path. Host sends all datagrams on that path with the DF bit set until receives ICMP
Destination Unreachable messages with a code meaning "fragmentation needed and DF set".  Upon receipt of such a message, the source host reduces its assumed PMTU for the path.

new-packet-mark (string; Default: )	Sets a new packet-mark value
new-priority (integer | from-dscp | from-dscp-high-3-bits | from-ingress; Default: )	Sets a new priority for a packet. This can be the VLAN, WMM, DSCP or MPLS EXP priority Read more. This property can also be used to set an internal priority.
new-routing-mark (string; Default: )	Sets a new routing-mark value (in RouterOS v7 routing mark must be created before as a new Routing table)
new-ttl (decrement | increment | set:integer; Default: )	Sets a new Time to live value 
route-dst (IP, Default:)	Matches packets with a specific gateway




    Creado por Artūrs C., actualizado por última vez por Normunds R. el nov 29, 2024 12 min de lectura

    Introduction
    Types of NAT:
        Destination NAT
        Source NAT
            Masquerade
            CGNAT (NAT444)
            Hairpin NAT
        Endpoint-Independent NAT
    NAT Helpers

Introduction

Network Address Translation is an Internet standard that allows hosts on local area networks to use one set of IP addresses for internal communications and another set of IP addresses for external communications. A LAN that uses NAT is ascribed as a natted network. For NAT to function, there should be a NAT gateway in each natted network. The NAT gateway (NAT router) performs IP address rewriting on the way while packets travel from/to LAN. In RouterOS NAT is supported for IPv4. RouterOS does not support NAT64. 

Nat matches only the first packet of the connection, connection tracking remembers the action and performs on all other packets belonging to the same connection.

Whenever NAT rules are changed or added, the connection tracking table should be cleared otherwise NAT rules may seem to be not functioning correctly until the connection entry expires.
Types of NAT:

There are two types of NAT:

    source NAT or srcnat. This type of NAT is performed on packets that are originated from a natted network. A NAT router replaces the private source address of an IP packet with a new public IP address as it travels through the router. A reverse operation is applied to the reply packets traveling in the other direction.
    destination NAT or dstnat. This type of NAT is performed on packets that are destined for the natted network. It is most commonly used to make hosts on a private network to be accessible from the Internet. A NAT router performing dstnat replaces the destination IP address of an IP packet as it travels through the router toward a private network.

Since RouterOS v7 the firewall NAT has two new INPUT and OUTPUT chains which are traversed for packets delivered to and sent from applications running on the local machine:

    input - used to process packets entering the router through one of the interfaces with the destination IP address which is one of the router's addresses. Packets passing through the router are not processed against the rules of the input chain.
    output - used to process packets that originated from the router and leave it through one of the interfaces. Packets passing through the router are not processed against the rules of the output chain.


Destination NAT

Network address translation works by modifying network address information in the packet's IP header. Let`s take a look at the common setup where a network administrator wants to access an office server from the internet.

We want to allow connections from the internet to the office server whose local IP is 10.0.0.3. In this case, we have to configure a destination address translation rule on the office gateway router:
/ip firewall nat add chain=dstnat action=dst-nat dst-address=172.16.16.1 dst-port=22 to-addresses=10.0.0.3 protocol=tcp

The rule above translates: when an incoming connection requests TCP port 22 with destination address 172.16.16.1, use the dst-nat action and depart packets to the device with local IP address 10.0.0.3 and port 22.

To allow access only from the PC at home, we can improve our dst-nat rule with "src-address=192.168.88.1" which is a Home`s PC public (this example) IP address. It is also considered to be more secure!
Source NAT

If you want to hide your local devices behind your public IP address received from the ISP, you should configure the source network address translation (masquerading) feature of the MikroTik router. 
Let`s assume you want to hide both the office computer and server behind the public IP 172.16.16.1, the rule will look like the following one:
/ip firewall nat add chain=srcnat src-address=10.0.0.0/24 action=src-nat to-addresses=172.16.16.1 out-interface=WAN

Now your ISP will see all the requests coming with IP 172.16.16.1 and they will not see your LAN network IP addresses.
Masquerade

Firewall NAT action=masquerade is a unique subversion of action=srcnat, it was designed for specific use in situations when public IP can randomly change, for example, DHCP server changes assigned IP or PPPoE tunnel after disconnect gets a different IP, in short - when public IP is dynamic.
/ip firewall nat add chain=srcnat src-address=10.0.0.0/24 action=masquerade out-interface=WAN

Every time when interface disconnects and/or its IP address changes, the router will clear all masqueraded connection tracking entries related to the interface, this way improving system recovery time after public IP change. If srcnat is used instead of masquerade, connection tracking entries remain and connections can simply resume after a link failure.

Unfortunately, this can lead to some issues with unstable links when the connection gets routed over different links after the primary link goes down. In such a scenario following things can happen:

    on disconnect, all related connection tracking entries are purged;
    next packet from every purged (previously masqueraded) connection will come into the firewall as new, and, if a primary interface is not back, a packet will be routed out via an alternative route (if you have any) thus creating a new masqueraded connection;
    the primary link comes back, routing is restored over the primary link, so packets that belong to existing connections are sent over the primary interface without being masqueraded, that way leaking local IPs to a public network.

To work around this situation blackhole route can be created as an alternative to the route that might disappear on disconnect.

Hosts behind a NAT-enabled router do not have true end-to-end connectivity. Therefore some Internet protocols might not work in scenarios with NAT. Services that require the initiation of TCP connection from outside the private network or stateless protocols such as UDP, can be disrupted. 

To overcome these limitations RouterOS includes a number of so-called NAT helpers, that enable NAT traversal for various protocols. When action=srcnat is used instead, connection tracking entries remain and connections can simply resume.

Though Source NAT and masquerading perform the same fundamental function: mapping one address space into another one, the details differ slightly. Most noticeably, masquerading chooses the source IP address for the outbound packet from the IP bound to the interface through which the packet will exit.
CGNAT (NAT444)

To combat IPv4 address exhaustion, a new RFC 6598 was deployed. The idea is to use shared 100.64.0.0/10 address space inside the carrier's network and perform NAT on the carrier's edge router to a single public IP or public IP range.

Because of the nature of such a setup, it is also called NAT444, as opposed to a NAT44 network for a 'normal' NAT environment, three different IPv4 address spaces are involved.

CGNAT configuration on RouterOS does not differ from any other regular source NAT configuration:
/ip firewall nat 
 add chain=src-nat action=srcnat src-address=100.64.0.0/10 to-address=2.2.2.2 out-interface=<public_if>

Where:

    2.2.2.2 - public IP address,
    public_if - interface on provider's edge router connected to the internet

The advantage of NAT444 is obvious, fewer public IPv4 addresses are used. But this technique comes with major drawbacks:

    The service provider router performing CGNAT needs to maintain a state table for all the address translations: this requires a lot of memory and CPU resources.
    Console gaming problems. Some games fail when two subscribers using the same outside public IPv4 address try to connect to each other.
    Tracking users for legal reasons means extra logging, as multiple households go behind one public address.
    Anything requiring incoming connections is broken. While this already was the case with regular NAT, end-users could usually still set up port forwarding on their NAT router. CGNAT makes this impossible. This means no web servers can be hosted here, and IP Phones cannot receive incoming calls by default either.
    Some web servers only allow a maximum number of connections from the same public IP address, as a means to counter DoS attacks like SYN floods. Using CGNAT this limit is reached more often and some services may be of poor quality.
    6to4 requires globally reachable addresses and will not work in networks that employ addresses with a limited topological span.


Packets with Shared Address Space source or destination addresses MUST NOT be forwarded across Service Provider boundaries. Service Providers MUST filter such packets on ingress links. In RouterOS this can be easily done with firewall filters on edge routers:
/ip firewall filter
 add chain=input src-address=100.64.0.0/10 action=drop in-interface=<public_if>
 add chain=output dst-address=100.64.0.0/10 action=drop out-interface=<public_if>
 add chain=forward src-address=100.64.0.0/10 action=drop in-interface=<public_if>
 add chain=forward src-address=100.64.0.0/10 action=drop out-interface=<public_if>
 add chain=forward dst-address=100.64.0.0/10 action=drop out-interface=<public_if>

Service providers may be required to log of MAPed addresses, in a large CGN deployed network which may be a problem. Fortunately, RFC 7422 suggests a way to manage CGN translations in such a way as to significantly reduce the amount of logging required while providing traceability for abuse response.

RFC states that instead of logging each connection, CGNs could deterministically map customer private addresses (received on the customer-facing interface of the CGN, a.k.a., internal side) to public addresses extended with port ranges.

That means that separate NAT rules have to be added to achieve individual mappings such as the ones seen in the below example:
Inside IP	Outside IP/Port range
100.64.0.1	2.2.2.2:5000-5199
100.64.0.2	2.2.2.2:5200-5399
100.64.0.3	2.2.2.2:5400-5599
100.64.0.4	2.2.2.2:5600-5799
100.64.0.5	2.2.2.2:5800-5999

Instead of writing the rules by hand, it is suggested to use a script instead. The following example could be adapted to any requirements of your setup.
{
######## Adjustable values #########
:local StartingAddress 100.64.0.1
:local ClientCount 5
:local AddressesPerClient 2
:local PublicAddress 2.2.2.2
:local StartingPort 5000
:local PortsPerAddress 200
####################################

# All client chain jump
/ip firewall nat add chain=srcnat action=jump jump-target=clients \
    src-address="$StartingAddress-$($StartingAddress + ($ClientCount * $AddressesPerClient) - 1)"

:local currentPort $StartingPort

:for c from=1 to=$ClientCount do={
    # Specific client chain jumps
    :if ($AddressesPerClient > 1) do={
      /ip firewall nat add chain=clients action=jump jump-target="client-$c" \
      src-address="$($StartingAddress + ($AddressesPerClient * ($c - 1)))-$($StartingAddress + ($AddressesPerClient * $c -1))"
    } else={
      /ip firewall nat add chain=clients action=jump jump-target="client-$c" \
      src-address="$($StartingAddress + ($AddressesPerClient * ($c - 1)))"
    }
  
    # Translation rules
    :for a from=1 to=$AddressesPerClient do={
      /ip firewall nat add chain="client-$c" action=src-nat protocol=tcp \
      src-address="$($StartingAddress + (($c -1) * $AddressesPerClient) + $a - 1)" to-address=$PublicAddress to-ports="$currentPort-$($currentPort + $PortsPerAddress - 1)"
      /ip firewall nat add chain="client-$c" action=src-nat protocol=udp \
      src-address="$($StartingAddress + (($c -1) * $AddressesPerClient) + $a - 1)" to-address=$PublicAddress to-ports="$currentPort-$($currentPort + $PortsPerAddress - 1)"
      :set currentPort ($currentPort + $PortsPerAddress)
    }
}
}

The six local values can be adjusted and the script can be either simply pasted in the terminal or it can be stored in the system script section, in case the configuration needs to be regenerated later.

After execution, you should get a set of rules:
[admin@MikroTik] > ip firewall nat print
Flags: X - disabled, I - invalid; D - dynamic 
 0    chain=srcnat action=jump jump-target=clients 
      src-address=100.64.0.1-100.64.0.10 

 1    chain=clients action=jump jump-target=client-1 
      src-address=100.64.0.1-100.64.0.2 

 2    chain=client-1 action=src-nat to-addresses=2.2.2.2 to-ports=5000-5199 
      protocol=tcp src-address=100.64.0.1 

 3    chain=client-1 action=src-nat to-addresses=2.2.2.2 to-ports=5000-5199 
      protocol=udp src-address=100.64.0.1 

 4    chain=client-1 action=src-nat to-addresses=2.2.2.2 to-ports=5200-5399 
      protocol=tcp src-address=100.64.0.2 

 5    chain=client-1 action=src-nat to-addresses=2.2.2.2 to-ports=5200-5399 
      protocol=udp src-address=100.64.0.2 

 6    chain=clients action=jump jump-target=client-2 
      src-address=100.64.0.3-100.64.0.4 

 7    chain=client-2 action=src-nat to-addresses=2.2.2.2 to-ports=5400-5599 
      protocol=tcp src-address=100.64.0.3 

 8    chain=client-2 action=src-nat to-addresses=2.2.2.2 to-ports=5400-5599 
      protocol=udp src-address=100.64.0.3 

 9    chain=client-2 action=src-nat to-addresses=2.2.2.2 to-ports=5600-5799 
      protocol=tcp src-address=100.64.0.4 

10    chain=client-2 action=src-nat to-addresses=2.2.2.2 to-ports=5600-5799 
      protocol=udp src-address=100.64.0.4 

11    chain=clients action=jump jump-target=client-3 
      src-address=100.64.0.5-100.64.0.6 

12    chain=client-3 action=src-nat to-addresses=2.2.2.2 to-ports=5800-5999 
      protocol=tcp src-address=100.64.0.5 

13    chain=client-3 action=src-nat to-addresses=2.2.2.2 to-ports=5800-5999 
      protocol=udp src-address=100.64.0.5 

14    chain=client-3 action=src-nat to-addresses=2.2.2.2 to-ports=6000-6199 
      protocol=tcp src-address=100.64.0.6 

15    chain=client-3 action=src-nat to-addresses=2.2.2.2 to-ports=6000-6199 
      protocol=udp src-address=100.64.0.6 

[...]

Hairpin NAT

Hairpin network address translation (NAT Loopback) is where the device on the LAN can access another machine on the LAN via the public IP address of the gateway router. 



In the above example, the gateway router has the following dst-nat configuration rule:
/ip firewall nat add chain=dstnat action=dst-nat dst-address=172.16.16.1 dst-port=443 to-addresses=10.0.0.3 to-ports=443 protocol=tcp

When a user from the PC at home establishes a connection to the web server, the router performs DST NAT as configured:

    the client sends a packet with a source IP address of 192.168.88.1 to a destination IP address of 172.16.16.1 on port 443 to request some web resources;
    the router destination NAT`s the packet to 10.0.0.3 and replaces the destination IP address in the packet accordingly. The source IP address stays the same: 192.168.88.1;
    the server replies to the client's request and the reply packet has a source IP address of 10.0.0.3 and a destination IP address of 192.168.88.1.
    the router determines that the packet is part of a previous connection and undoes the destination NAT, and puts the original destination IP address into the source IP address field. The destination IP address is 192.168.88.1, and the source IP address is 172.16.16.1;
    The client receives the reply packet it expects, and the connection is established;


But, there will be a problem, when a client on the same network as the web server requests a connection to the web server's public IP address: 

    the client sends a packet with a source IP address of 10.0.0.2 to a destination IP address of 172.16.16.1 on port 443 to request some web resources;
    the router destination NATs the packet to 10.0.0.3 and replaces the destination IP address in the packet accordingly. The source IP address stays the same: 10.0.0.2;
    the server replies to the client's request. However, the source IP address of the request is on the same subnet as the web server. The web server does not send the reply back to the router but sends it back directly to 10.0.0.2 with a source IP address in the reply of 10.0.0.3;
    The client receives the reply packet, but it discards it because it expects a packet back from 172.16.16.1, and not from 10.0.0.3;

To resolve this issue, we will configure a new src-nat rule (the hairpin NAT rule) as follows:
/ip firewall nat
add action=masquerade chain=srcnat dst-address=10.0.0.3 out-interface=LAN protocol=tcp src-address=10.0.0.0/24

After configuring the rule above:

    the client sends a packet with a source IP address of 10.0.0.2 to a destination IP address of 172.16.16.1 on port 443 to request some web resources;
    the router destination NATs the packet to 10.0.0.3 and replaces the destination IP address in the packet accordingly. It also source NATs the packet and replaces the source IP address in the packet with the IP address on its LAN interface. The destination IP address is 10.0.0.3, and the source IP address is 10.0.0.1;
    the web server replies to the request and sends the reply with a source IP address of 10.0.0.3 back to the router's LAN interface IP address of 10.0.0.1;
    the router determines that the packet is part of a previous connection and undoes both the source and destination NAT, and puts the original destination IP address of 10.0.0.3 into the source IP address field, and the original source IP address of 172.16.16.1 into the destination IP address field

Endpoint-Independent NAT

Endpoint-independent NAT creates mapping in the source NAT and uses the same mapping for all subsequent packets with the same source IP and port. This mapping is created with the following rule:
/ip firewall nat
add action=endpoint-independent-nat chain=srcnat out-interface=WAN protocol=udp

This mapping allows running source-independent filtering, which allows forwarding packets from any source from WAN to mapped internal IP and port. The following rule enables filtering:
/ip firewall nat
add action=endpoint-independent-nat chain=dstnat in-interface=WAN protocol=udp


Endpoint-independent NAT works only with UDP protocol.


Additionally, endpoint-independent-nat can take a few other parameters:

    randomize-port - randomize to which public port connections will be mapped.


More info https://www.ietf.org/rfc/rfc5128.txt section 2.2.3 and 2.2.5
NAT Helpers

Hosts behind a NAT-enabled router do not have true end-to-end connectivity. Therefore some Internet protocols might not work in scenarios with NAT. To overcome these limitations RouterOS includes a number of NAT helpers, that enable NAT traversal for various protocols.

Nat helpers can be managed from /ip firewall service-ports menu.

List of available nat helpers:
FTP	FTP service helper
H323	H323 service helper
IRC	IRC service helper
PPTP	PPTP (GRE) tunneling helper
UDPLITE	UDP-Lite service helper
DCCP	DCCP service helper
SCTP	SCTP service helper
SIP	SIP helper. Additional options:

    sip-direct-media allows redirecting the RTP media stream to go directly from the caller to the callee. The default value is yes.
    sip-timeout allows adjusting TTL of SIP UDP connections. Default: 1 hour. In some setups, you have to reduce that.

TFTP	TFTP service helper
RSTP	RTSP service helper


If connection tracking is not enabled then firewall service ports will be shown as inactive

udplite, dccp, and sctp are built-in services of the connection tracking. Since these are not separately loaded modules, they cannot be disabled separately, they got disabled together with the connection tracking.


NAT Actions

Table lists NAT actions and their associated properties. Other actions are listed here.
action (action name; Default: accept)	

    dst-nat - replaces the destination address and/or port of an IP packet with values specified by to-addresses and to-ports parameters
    masquerade - replaces the source port of an IP packet with one specified by to-ports parameter and replace the source address of an IP packet to the IP determined by the routing facility. 
    netmap - creates a static 1:1 mapping of one set of IP addresses to another one. Often used to distribute public IP addresses to hosts on private networks
    redirect - replaces the destination port of an IP packet with one specified by to-ports parameter and destination address to one of the router's local addresses
    same - gives a particular client the same source/destination IP address from a supplied range for each connection. This is most frequently used for services that expect the same client address for multiple connections from the same client. IPv4 only
    src-nat - replaces the source address of an IP packet with values specified by to-addresses and to-ports parameters
    endpoint-independent-nat - uses endpoint-independent mapping and filtering. Works only with UDP protocol. IPv4 only.

same-not-by-dst (yes | no; Default: )	Specifies whether to take into account or not the destination IP address when selecting a new source IP address. Applicable if action=same
to-addresses (IP address[-IP address]; Default: 0.0.0.0)	Replace the original address with the specified one. Applicable if action is dst-nat, netmap, same, src-nat
to-ports (integer[-integer]: 0..65535; Default: )	Replace the original port with the specified one. Applicable if action is dst-nat, redirect, masquerade, netmap, same, src-nat



    Creado por Māris B., actualizado por última vez por Matīss O. el ene 13, 2025 15 min de lectura

    Common Actions and Associated properties
        Stats
        Other Useful Commands
    Matchers
        Stateless Properties
        Stateful Properties

Common Actions and Associated properties
action (action name; Default: accept)	Action to take if a packet is matched by the rule:

    accept - accept the packet. A packet is not passed to the next firewall rule.
    add-dst-to-address-list - add destination address to address list specified by address-list parameter
    add-src-to-address-list - add source address to address list specified by address-list parameter
    jump - jump to the user-defined chain specified by the value of jump-target parameter
    log - add a message to the system log containing the following data: in-interface, out-interface, src-mac, protocol, src-ip:port->dst-ip:port and length of the packet. After a packet is matched it is passed to the next rule in the list, similar as passthrough
    passthrough - if a packet is matched by the rule, increase counter and go to next rule (useful for statistics)
    return - passes control back to the chain from where the jump took place

address-list (name; Default: )	

Name of the address list to be used. Applicable if action is add-dst- to-address-list or add-src-to-address-list
address-list-timeout (none-dynamic | none-static | time; Default: none-dynamic)	Time interval after which the address will be removed from the address list specified by address-list parameter. Used in conjunction with add-dst-to-address-list or add-src-to-address-list actions

    Value of none-dynamic (00:00:00) will leave the address in the address list till reboot
    Value of none-static will leave the address in the address list forever and will be included in the configuration export/backup

jump-target (name; Default: )	Name of the target chain to jump to. Applicable only if action=jump
log (yes | no; Default: no)	Add a message to the system log containing the following data: in-interface, out-interface, src-mac, protocol, src-ip:port->dst-ip:port, and length of the packet. Allows to log packets even if action is not "log", useful for debugging firewall.
log-prefix (string; Default: )	Adds specified text at the beginning of every log message. Applicable if action=log or log=yes configured.
Stats

To view matching statistics by firewall rules, run /ip firewall filter print stats command or /ipv6 firewall filter print stats for IPv6 firewall.


bytes (integer)	The total amount of bytes matched by the rule
packets (integer)	The total amount of packets matched by the rule
[admin@MikroTik] > ip firewall filter print stats 
Flags: X - disabled, I - invalid, D - dynamic 
 #    CHAIN                                                                                                                 ACTION                            BYTES         PACKETS
 0  D ;;; special dummy rule to show fasttrack counters
      forward                                                                                                               passthrough              50 507 925 242      50 048 246
 1    ;;; defconf: drop invalid
      forward                                                                                                               drop                            432 270           9 719
 2    ;;; defconf: drop invalid
      input                                                                                                                 drop                            125 943           2 434
 3    input                                                                                                                 accept                   20 090 211 549      20 009 864
 4    ;;; defconf: accept ICMP
      input                                                                                                                 accept                          634 926           7 648
 5    ;;; defconf: drop all not coming from LAN
      input                                                                                                                 drop                          4 288 079          83 428
 6    ;;; defconf: accept in ipsec policy
      forward                                                                                                               accept                                0               0
7    ;;; defconf: accept out ipsec policy
      forward                                                                                                               accept                                0               0
8    ;;; defconf: fasttrack
      forward                                                                                                               fasttrack-connection     28 505 528 775      31 504 682
9    ;;; defconf: accept established,related, untracked
      forward                                                                                                               accept                   28 505 528 775      31 504 682
10    ;;; defconf: drop all from WAN not DSTNATed
      forward                                                                                                               drop                                  0               0


Statistics parameters can be reset by following commands:
reset-counters (id)	

Reset statistics counters for specific firewall rule or list of rules.
reset-counters-all	

Reset statistics counters for all firewall rules in the table.
Other Useful Commands

By default print is equivalent to print static and shows only static rules.

To print also dynamic rules use print all.

Or to print only dynamic rules use print dynamic.
Matchers

Tables below shows all the properties that can be used as a matchers in the firewall rules.

Matchers are executed in a specific order.

For IPv4:

    Source MAC Address
    In/Out interfaces
    In/Out interface lists
    IP Range
    Address type
    Address list
    TTL
    DSCP
    Length
    TLS
    IPv4 Options
    Dst Port
    Src Port
    Any Port
    TCP Options
    TCP MSS
    ICMP Codes
    Ingress Priority
    Priority
    Packet Mark
    Realm (routing table)
    Hotsopot
    Connection Mark
    Connection State
    Connection NAT State
    Connection Bytes
    Connection Limit
    Connection Rate
    Ipsec Policy
    Helper
    String (content)
    PSD
    Layer7
    Random
    Nth
    PCC
    Limit
    Dst Limit
    Log

For IPv6:

    Address type
    Address list
    Source MAC Address
    In/Out interfaces
    In/Out interface lists
    Hop Limit
    DSCP
    Length
    TLS
    IPv6 Header
    Dst Port
    Src Port
    Any Port
    TCP Options
    TCP MSS
    ICMPv6 Codes
    Ingress Priority
    Priority
    Packet Mark
    Connection Mark
    Connection State
    Connection NAT State
    Connection Bytes
    Connection Limit
    Connection Rate
    Ipsec Policy
    Helper
    Match String (content)
    Random
    Nth
    PCC
    Limit
    Dst Limit
    Log

 

Properties are split in two parts:

    stateless - properties do not require connection tracking to function and can be used in stateless RAW firewall matching.
    stateful - properties either require connection tracking to function or is available only in stateful firewall config.

Stateless Properties


chain (name; Default: )	Specifies to which chain rule will be added. If the input does not match the name of an already defined chain, a new chain will be created
comment (string; Default: )	Descriptive comment for the rule
content (string; Default: )	Match packets that contain specified text
dscp (integer: 0..63; Default: )	Matches DSCP IP header field.
dst-address (IP/netmask | IP range; Default: )	Matches packets whose destination is equal to the specified IP or falls into the specified IP range.
dst-address-list (name; Default: )	

Matches the destination address of a packet against a user-defined address-list.

Supports only one list!
dst-address-type (unicast | local | broadcast | multicast )	Matches destination address type:

    unicast - IP address used for point to point transmission
    local - if dst-address is assigned to one of the router's interfaces
    broadcast - packet is sent to all devices in a subnet
    multicast - packet is forwarded to a defined group of devices

dst-limit (integer[/time],integer,dst-address | dst-port | src-address[/time]; Default: )	Matches packets until a given rate is exceeded. Rate is defined as packets per time interval. As opposed to the limit matcher, every flow has its own limit. Flow is defined by a mode parameter. Parameters are written in the following format: rate[/time],burst,mode[/expire].

    rate - packet count per time interval per-flow to match
    time - specifies the time interval in which the packet count rate per flow cannot be exceeded (optional, 1s will be used if not specified)
    burst - initial number of packets per flow to match: this number gets recharged by one every time/rate, up to this number
    mode - this parameter specifies what unique fields define flow (src-address, dst-address, src-and-dst-address, dst-address-and-port, addresses-and-dst-port)
    expire - specifies interval after which flow with no packets will be allowed to be deleted (optional)

dst-port (integer[-integer]: 0..65535; Default: )	List of destination port numbers or port number ranges
fragment (yes|no; Default: )	

Matches fragmented packets. The first (starting) fragment does not count. If connection tracking is enabled there will be no fragments as the system automatically assembles every packet.

IPv4 only.

header (Type[:Mode]; Mode=contains|exact; Type=hop|dst|route|frag|ah|esp|none|proto)
	

Matches IPv6 next-header.

Two types of header matching are possible controlled by "mode" parameter:

    contains - soft matching, matches at least selected headers
    exact - matches exact set of selected headers

IPv6 only.

hop-limit (Mode:Value; Mode=equal | greater-than | less-than | not-equal; Value=0..255)
	

Matches hop limit field in the IPv6 header. 

IPv6 only.
hotspot (auth | from-client | http | local-dst | to-client; Default: )	Matches packets received from HotSpot clients against various HotSpot matchers.

    auth - matches authenticated HotSpot client packets
    from-client - matches packets that are coming from the HotSpot client
    http - matches HTTP requests sent to the HotSpot server
    local-dst - matches packets that are destined to the HotSpot server
    to-client - matches packets that are sent to the HotSpot client

IPv4 Only.
icmp-options (integer:integer; Default: )	Matches ICMP type: code fields
in-bridge-port (name; Default: )	Actual interface the packet has entered the router if the incoming interface is a bridge. Works only if use-ip-firewall is enabled in bridge settings.
in-bridge-port-list (name; Default: )	Set of interfaces defined in interface list. Works the same as in-bridge-port
in-interface (name; Default: )	Interface the packet has entered the router
in-interface-list (name; Default: )	Set of interfaces defined in interface list. Works the same as in-interface
ingress-priority (integer: 0..63; Default: )	Matches the priority of an ingress packet. Priority may be derived from VLAN, WMM, DSCP, or MPLS EXP bit. read more
ipsec-policy (in | out, ipsec | none; Default: )	Matches the policy used by IPsec. Value is written in the following format: direction, policy. The direction is Used to select whether to match the policy used for decapsulation or the policy that will be used for encapsulation.

    in - valid in the PREROUTING, INPUT, and FORWARD chains
    out - valid in the POSTROUTING, OUTPUT, and FORWARD chains

    ipsec - matches if the packet is subject to IPsec processing;
    none - matches packets that are not subject to IPsec processing (for example, IPSec transport packet).

For example, if a router receives an IPsec encapsulated Gre packet, then rule ipsec-policy=in,ipsec will match Gre packet, but a rule ipsec-policy=in,none will match the ESP packet.
ipv4-options (any | loose-source-routing | no-record-route | no-router-alert | no-source-routing | no-timestamp | none | record-route | router-alert | strict-source-routing | timestamp; Default: )	Matches IPv4 header options.

    any - match packet with at least one of the ipv4 options
    loose-source-routing - match packets with a loose source routing option. This option is used to route the internet datagram based on information supplied by the source
    no-record-route - match packets with no record route option. This option is used to route the internet datagram based on information supplied by the source
    no-router-alert - match packets with no router alter option
    no-source-routing - match packets with no source routing option
    no-timestamp - match packets with no timestamp option
    record-route - match packets with record route option
    router-alert - match packets with router alter option
    strict-source-routing - match packets with a strict source routing option
    timestamp - match packets with a timestamp

IPv4 only.
limit (integer,time,integer; Default: )	Matches packets up to a limited rate (packet rate or bit rate). A rule using this matcher will match until this limit is reached. Parameters are written in the following format: rate[/time],burst:mode.

    rate - packet or bit count per time interval to match
    time - specifies the time interval in which the packet or bit rate cannot be exceeded (optional, 1s will be used if not specified)
    burst - initial number of packets or bits to match: this number gets recharged every 10ms so burst should be at least 1/100 of a rate per second
    mode - packet or bit mode

nth (integer,integer; Default: )	Matches every nth packet: nth=2,1 rule will match every first packet of 2, hence, 50% of all the traffic that is matched by the rule
out-bridge-port (name; Default: )	Actual interface the packet leaves the router if the outgoing interface is a bridge. Works only if use-ip-firewall is enabled in bridge settings.
out-bridge-port-list (name; Default: )	Set of interfaces defined in interface list. Works the same as out-bridge-port
out-interface (; Default: )	Interface the packet is leaving the router
out-interface-list (name; Default: )	Set of interfaces defined in interface list. Works the same as out-interface
packet-mark (no-mark | string; Default: )	Matches packets marked via mangle facility with particular packet mark. If no-mark is set, the rule will match any unmarked packet. 
packet-size (integer[-integer]:0..65535; Default: )	Matches packets of specified size or size range in bytes.
per-connection-classifier (ValuesToHash:Denominator/Remainder; Default: )	

PCC matcher ( or Per Stream Classifier) allows dividing traffic into equal streams with the ability to keep packets with a specific set of options in one particular stream.

Streams are hashed based on selected values to hash:

    both-addresses    
    both-addresses-and-ports    
    both-ports    
    dst-address    
    dst-address-and-port    
    dst-port    
    src-address    
    src-address-and-port    
    src-port 

 Read more >>
port (integer[-integer]: 0..65535; Default: )	Matches if any (source or destination) port matches the specified list of ports or port ranges. Applicable only if protocol is TCP or UDP
priority (integer: 0..63; Default:)	Matches the packet's priority after a new priority has been set. Priority may be derived from VLAN, WMM, DSCP, MPLS EXP bit, or from the priority that has been set using the set-priority action. Read more
protocol (name or protocol ID; Default: tcp)	Matches particular IP protocol specified by protocol name or number
psd (integer,time,integer,integer; Default: )	Attempts to detect TCP and UDP scans. Parameters are in the following format WeightThreshold, DelayThreshold, LowPortWeight, HighPortWeight

    WeightThreshold - total weight of the latest TCP/UDP packets with different destination ports coming from the same host to be treated as port scan sequence
    DelayThreshold - delay for the packets with different destination ports coming from the same host to be treated as possible port scan subsequence
    LowPortWeight - the weight of the packets with privileged (<1024) destination port
    HighPortWeight - the weight of the packet with a non-privileged destination port

IPv4 only.
random (integer: 1..99; Default: )	Matches packets randomly with a given probability
src-address (Ip/Netmask, Ip range; Default: )	Matches packets whose source is equal to a specified IP or falls into a specified IP range
src-address-list (name; Default: )	

Matches the source address of a packet against a user-defined address list.

Supports only one list!
src-address-type (unicast | local | broadcast | multicast | blackhole | prohibit | unreachable ; Default: )	

mote{ta{tableMatches source address type:

    unicast - IP address used for point to point transmission
    local - if an address is assigned to one of the router's interfaces
    broadcast - packet is sent to all devices in the subnet
    multicast - packet is forwarded to a defined group of devices

src-port (integer[-integer]: 0..65535; Default: )	List of source ports and ranges of source ports. Applicable only if a protocol is TCP or UDP
src-mac-address (MAC address; Default: )	Matches the source MAC address of the packet
tcp-flags (ack | cwr | ece | fin | psh | rst | syn | urg; Default: )	Matches specified TCP flags

    ack - acknowledging data
    cwr - congestion window reduced
    ece - ECN-echo flag (explicit congestion notification)
    fin - close connection
    psh - push function
    rst - drop connection
    syn - new connection
    urg - urgent data

tcp-mss (integer[-integer]: 0..65535; Default: )	Matches TCP MSS value of an IP packet
time (time-time,sat | fri | thu | wed | tue | mon | sun; Default: )	Allows to create a filter based on the packets' arrival time and date or, for locally generated packets, departure time and date
tls-host (string; Default: )	Allows matching HTTPS traffic based on TLS SNI hostname. Accepts GLOB syntax for wildcard matching. Note that the matcher will not be able to match the hostname if the TLS handshake frame is fragmented into multiple TCP segments (packets).

Watch our video about this value. 
ttl (integer: 0..255; Default: )	Matches packets TTL value. IPv4 Only.
Stateful Properties


connection-bytes (integer-integer; Default: )	

Matches packets only if a given amount of bytes has been transferred through the particular connection.

0 - means infinity, for example connection-bytes=2000000-0 means that the rule matches if more than 2MB has been transferred through the relevant connection
connection-limit (integer,netmask; Default: )	Matches connections per address or address block after a given value is reached. Should be used together with connection-state=new and/or with tcp-flags=syn because matcher is very resource-intensive
connection-mark (no-mark | string; Default: )	Matches packets marked via mangle facility with particular connection mark. If no-mark is set, the rule will match any unmarked connection
connection-nat-state (srcnat | dstnat; Default: )	Can match connections that are srcnatted, distracted, or both. Note that connection-state=related connections connection-nat-state is determined by the direction of the first packet. and if connection tracking needs to use dst-nat to deliver this connection to the same hosts as the main connection it will be in connection-nat-state=dstnat even if there are no dst-nat rules at all
connection-rate (Integer 0..4294967295; Default: )	Connection Rate is a firewall matcher that allows capturing traffic based on the present speed of the connection
connection-state (established | invalid | new | related | untracked; Default: )	Interprets the connection tracking analytics data for a particular packet:

    established - a packet that belongs to an existing connection
    invalid - a packet that does not have a determined state in connection tracking (usually - severe out-of-order packets, packets with wrong sequence/ack number, or in case of a resource over usage on the router), for this reason, an invalid packet will not participate in NAT (as only connection-state=new packets do), and will still contain original source IP address when routed. We strongly suggest dropping all connection-state=invalid packets in the firewall filter forward and input chains
    new - the packet has started a new connection or is otherwise associated with a connection that has not seen packets in both directions.
    related - a packet that is related to, but not parts of an existing connection, such as ICMP errors or a packet that begins an FTP data connection
    untracked - packet that was set to bypass connection tracking in firewall RAW tables.

connection-type (ftp | h323 | irc | pptp | quake3 | sip | tftp; Default: )	Matches packets from related connections based on information from their connection tracking helpers. A relevant connection helper must be enabled under the: /ip firewall service-port
layer7-protocol (name; Default: )	Layer7 filter name defined in layer7 protocol menu. Read more>>.

p2p ()
	

Matches some unencrypted P2P protocols. Deprecated in modern days since mostly everything is encrypted and requires deep packet inspection to identify.

IPv4 only.
realm (integer: 0..4294967295; Default: )	IPv4 only.
routing-mark (string; Default: )	Matches packets marked by mangle facility with particular routing mark



    Creado por Artūrs C., actualizado por última vez por GG el abr 23, 2024 2 min de lectura

    Summary
        Properties
    Examples
        Simple L7 usage example
        L7 in the input chain
        Youtube Matcher

Summary

Layer7-protocol is a method of searching for patterns in ICMP/TCP/UDP streams.

The L7 matcher is very resource-intensive. Use this feature only for very specific traffic. It is not recommended to use the L7 matcher for generic traffic, such as for blocking web pages. This will almost never work correctly and your device will exhaust its resources, trying to catch all the traffic. Use other features to block webpages by URL.

L7 matcher collects the first 10 packets of a connection or the first 2KB of a connection and searches for the pattern in the collected data. If the pattern is not found in the collected data, the matcher stops inspecting further. Allocated memory is freed and the protocol is considered unknown. You should take into account that a lot of connections will significantly increase memory and CPU usage. To avoid this, add regular firewall matchers to reduce the amount of data passed to layer-7 filters repeatedly.

An additional requirement is that the layer7 matcher must see both directions of traffic (incoming and outgoing). To satisfy this requirement l7 rules should be set in the forward chain. If the rule is set in the input/prerouting chain then the same rule must be also set in the output/postrouting chain, otherwise, the collected data may not be complete resulting in an incorrectly matched pattern.

 Layer 7 matcher is case insensitive!

Example L7 patterns compatible with RouterOS can be found on the l7-filter project page.

 In some cases when layer 7 regular expression cannot be performed, RouterOS will log topic=firewall, warning with an error message stating the problem in the message!
Properties
/ip firewall layer7-protocol


name (string; Default: )	Descriptive name of l7 pattern used by configuration in firewall rules. See example >>.
regexp (string; Default: )	POSIX compliant regular expression is used to match a pattern.
Examples
Simple L7 usage example

First, add Regexp strings to the protocols menu, to define the strings you will be looking for. In this example, we will use a pattern to match RDP packets.
/ip firewall layer7-protocol
add name=rdp regexp="rdpdr.*cliprdr.*rdpsnd"

Then, use the defined protocols in the firewall.
/ip firewall filter

# add few known protocols to reduce mem usage
add action=accept chain=forward comment="" disabled=no port=80 protocol=tcp
add action=accept chain=forward comment="" disabled=no port=443 protocol=tcp

# add l7 matcher
add action=accept chain=forward comment="" disabled=no layer7-protocol=\
    rdp protocol=tcp

As you can see before the l7 rule we added several regular rules that will match known traffic thus reducing memory usage.
L7 in the input chain

In this example, we will try to match the telnet protocol connecting to our router.
/ip firewall layer7-protocol add comment="" name=telnet regexp="^\\xff[\\xfb-\\xfe].\\xff[\\xfb-\\xfe].\\xff[\\xfb-\\xfe]"

Note that we need both directions which is why we need also the l7 rule in the output chain that sees outgoing packets.
/ip firewall filter

add action=accept chain=input comment="" disabled=no layer7-protocol=telnet \
    protocol=tcp

add action=passthrough chain=output comment="" disabled=no layer7-protocol=telnet \
    protocol=tcp
Youtube Matcher

When a user is logged in YouTube will use HTTPS, meaning that L7 will not be able to match this traffic. Only unencrypted HTTP can be matched.


/ip firewall layer7-protocol
add name=youtube regexp="(GET \\/videoplayback\\\?|GET \\/crossdomain\\.xml)"






    Creado por Artūrs C., actualizado por última vez por GG el abr 23, 2024 2 min de lectura

    Summary
    Properties

Summary
/ip firewall address-list

Firewall address lists allow a user to create lists of IP addresses grouped together under a common name. Firewall filter, mangle, and NAT facilities can then use those address lists to match packets against them.

The address list records can also be updated dynamically via the action=add-src-to-address-list or action=add-dst-to-address-list items found in NAT, Mangle, and Filter facilities.

Firewall rules with action add-src-to-address-list or add-dst-to-address-list work in passthrough mode, which means that the matched packets will be passed to the next firewall rules.
Properties
address (DNS Name | IP address/netmask | IP-IP; Default: )	A single IP address or range of IPs to add to the address list or DNS name. You can input for example, '192.168.0.0-192.168.1.255' and it will auto modify the typed entry to 192.168.0.0/23 on saving.
dynamic (yes, no)	Allows creating data entry with dynamic form.
list (string; Default: )	Name for the address list of the added IP address.
timeout (time; Default: )	Time after address will be removed from the address list. If the timeout is not specified, the address will be stored in the address list permanently.
creation-time (time; Default: )	The time when the entry was created.


If the timeout parameter is not specified, then the address will be saved to the list permanently on the disk. If a timeout is specified, the address will be stored on the RAM and will be removed after a system's reboot.

Example

The following example creates a dynamic address list of people who are connecting to port 23 (telnet) on the router and drops all further traffic from them for 5 minutes. Additionally, the address list will also contain one static address list entry of 192.0.34.166/32 (www.example.com):
/ip firewall address-list add list=drop_traffic address=192.0.34.166/32
/ip firewall address-list print
Flags: X - disabled, D - dynamic
 #   LIST         ADDRESS
 0   drop_traffic 192.0.34.166
/ip firewall mangle add action=add-src-to-address-list address-list=drop_traffic address-list-timeout=5m chain=prerouting dst-port=23 protocol=tcp
/ip firewall filter add action=drop chain=input src-address-list=drop_traffic
/ip firewall address-list print
Flags: X - disabled, D - dynamic
 #   LIST         ADDRESS
 0   drop_traffic 192.0.34.166
 1 D drop_traffic 1.1.1.1
 2 D drop_traffic 10.5.11.8

As seen in the output of the last print command, two new dynamic entries appeared in the address list (marked with a status of 'D'). Hosts with these IP addresses tried to initialize a telnet session to the router and were then subsequently dropped by the filter rule.



    Creado por Māris B., actualizado por última vez por Gļebs K. el mar 24, 2025 24 min de lectura

    Understanding Packet Flow
        Overall Packetflow Diagram
            Chains
        Flow of Routed Packet
            Forward
            Input
            Output
        Flow of Bridged Packet
            Bridge Forward
            Bridge Input
            Bridge Output
            Forward With Firewall Enabled
        Flow of Hardware Offloaded Packet
            Switch Forward
            Switch to CPU Input
            CPU Output to Switch
        Flow of MPLS Packet
            Pop Label
            Switch Label
            Push Label
        MPLS IP VPN
        Logical Interfaces
        IPSec Policies
    Fast Path
        How Fast Path Works
    FastTrack
        Configuration example: excluding specific host, from being Fast-Tracked
        Requirements
    Packet flow for the visually impaired


Understanding Packet Flow

More advanced firewall setups, or complicated tasks, such as traffic prioritization, routing policies, where it is necessary to utilize more than one RouterOS facility, require knowledge: How do these facilities work together? What happens when and why?

RouterOS packet flow diagram and flow examples will try to answer these questions.

It would be very complicated to represent what is going on with the packet in one diagram, therefore a packet flow diagram is divided into three parts:

    overall diagram;
    detailed bridging, routing, and MPLS flow diagram;
    a diagram that shows what facilities and in what order are included in prerouting, input, forward, output, and postrouting.

Overall Packetflow Diagram

Let's look at the overall diagram. It looks complicated at first, but after we go through the diagram with examples it will become much clearer.


There are 4 boxes in the center of the diagram: Bridging, Routing, Mpls decisions, and local router processes. So for example, if the packet needs to be routed over the router, a packet will flow as illustrated in the image below. Without looking deeper into each facility, the packet enters the in-interface, the router determines that it is IP traffic and needs to be routed, the packet goes through all routing processes and exits the out-interface.

Let's take a look at another example that will illustrate what happens if the packet's destination is a router. For example, the in-interface receives ICMP (ping) packet, its destination is the router itself, so the packet will go for local-in processing. After the packet is processed ICMP (ping) reply is generated inside the router (local-out processing) and will be sent out over the out-interface.

A simple explanation of each box before we go further with examples:

    physical in-interface - the starting point of the packet received by the router;
    logical in-interface - the starting point of the decapsulated packet (from tunnels, IPsec, etc);
    local in - the last point of a packet destined to router itself;
    interface HTB (Hierarchical Token Bucket) - interface queue;
    physical out-interface - last point of the packet before it is actually sent out;
    logical out-interface - last point of the packet before encapsulation (to tunnels, IPsec, etc);
    local out - the starting point of a packet generated by the router;


Now it is time to take a deeper look at what is happening inside bridging, MPLS, and routing flows.

A simple explanation of each box before we go further with examples:

    routing decision - go through routes in the routing table to find a match for the destination IP address of the packet. When a match is found - the packet will be processed further, in case of no match - the packet will be discarded.;
    mpls decision - what to do with the packet based on MPLS forwarding tables;
    bridging decision - bridge goes through the MAC address table to find a match for the destination MAC address of the packet. When a match is found - the packet will be processed further, in case of no match - multiple copies of the packet will be created and packets will be flooded (sent out via all bridge ports). A single packet copy will also reach a bridge input chain as the bridge interface itself is one of the many destinations. When using vlan-filtering=yes, packets that are not allowed due to the "/interface bridge vlan" table, will be dropped at this stage.
    use-ip-firewall - whether a 'use-ip-firewall' option is enabled in bridge settings;
    ipsec-policy - whether a packet matches any of configured IPsec policies;

Chains

RouterOS consist of a few default chains. These chains allow you to filter packets at various points:

    The PREROUTING chain: Rules in this chain apply to packets as they just arrive on the network interface. This chain is present in the nat, mangle and raw tables.
    The INPUT chain: Rules in this chain apply to packets just before they’re given to a local process. This chain is present in the mangle and filter tables.
    The OUTPUT chain: The rules here apply to packets just after they’ve been produced by a process. This chain is present in the raw, mangle, nat, and filter tables.
    The FORWARD chain: The rules here apply to any packets that are routed through the current host. This chain is only present in the mangle and filter tables.
    The POSTROUTING chain: The rules in this chain apply to packets as they just leave the network interface. This chain is present in the nat and mangle tables.

Each of the prerouting, input, forward, output, and postrouting blocks contains even more facilities, which are illustrated in the third part of the packet flow diagram:


A simple explanation of each box before we go further with examples:

    Hotspot-in - allows to capture traffic that otherwise would be discarded by connection tracking - this way our Hotspot feature is able to provide connectivity even if networks settings are an incomplete mess ;
    RAW Prerouting - RAW table prerouting chain;
    Connection tracking - packet is processed by connection tracking;
    Mangle Prerouting - Mangle prerouting chain;
    Mangle Input - Mangle input chain;
    Filter Input - Firewall filter input chain;
    HTB Global - Queue tree;
    Simple Queues - is a feature that can be used to limit traffic for a particular target;
    TTL - indicates an exact place where the Time To Live (TTL) of the routed packet is reduced by 1 if TTL becomes 0, a packet will be discarded;
    Mangle Forward - Mangle forward chain;
    Filter Forward - Filter forward chain;
    Accounting - Authentication, Authorization, and Accounting feature processing;
    RAW Output - RAW table output chain;
    Mangle Output - Mangle output chain;
    Filter Output - Firewall filter output chain;
    Routing Adjustment - this is a workaround that allows to set up policy routing in mangle chain output (routing-mark) ;
    Mangle Postrouting - Mangle postrouting chain;
    Src Nat - Network Address Translation srcnat chain;
    Dst Nat - Network Address Translation dstnat chain;
    Hotspot-out - undo all that was done by hotspot-in for the packets that are going back to the client;


Flow of Routed Packet
Forward

Now, let's take our first example where the packet gets routed over the router and look deeper through what facilities packet goes:

We already learned that packet goes into the in-interface, the router determines that it is an IP packet and needs to be routed, and here starts the complicated process:

     The packet enters prerouting processing:
        check if there is a hotspot and modify the packet for hotspot use
        process packet through RAW prerouting chain;
        send the packet through connection tracking;
        process packet through Mangle prerouting chain;
         process packet through NATs dst-nat chain;
    Run packet through routing table to make routing decision;
    The packet enters the forward process;
        check TTL value;
        process packet through Mangle forward chain;
        process packet through the Filter forward chain;
        send the packet to accounting processes;

    A packet enters postrouting process;
        process packet through Mangle postrouting chain;
        process packet through NATs src-nat chain;
        if there is a hotspot undo any modifications made in hotspot-in;
        process packet through queue tree (HTB Global);
        process packet through simple queues;

    Check if there is IPsec and then process through IPsec policies;


Input

We already learned that packet goes into the in-interface, the router determines that it is an IP packet and needs to be routed, and here starts the complicated process:

    A very similar process happens when a packet's destination is a router (routing input): Packet enters prerouting processing:
        - check if there is a hotspot and modify the packet for hotspot use;
        - process packet through RAW prerouting chain;
        - send a packet through connection tracking;
        - process packet through Mangle prerouting chain;
        - process packet through NATs dst-nat chain;

    Run packet through routing table to make routing decision;

    A Packet enters the input process;
        - process packet through Mangle input chain;
        - process packet through Filter input chain;
        - process packet through queue tree (HTB Global);
        - process packet through simple queues;

    Check if there is IPsec and then process through IPsec policies.

Output

Or when a packet is originated from the router (routing output):

    The packet is originated from the router itself
        the packet goes through the routing table to make a routing decision

    A packet enters the output process
        process packet through the Bridge decision;
        send the packet through connection tracking;
        process packet through the Mangle output chain;
        process packet through the Filter output chain;
        send the packet to routing adjustment ( policy routing)

     The packet enters postrouting process; 
        - process packet through Mangle postrouting chain;
        - process packet through NATs src-nat chain;
        - if there is a hotspot undo any modifications made in hotspot-in;
        - process packet through queue tree (HTB Global);
        - process packet through simple queues;

    Check if there is IPsec and then process through IPsec policies;



Flow of Bridged Packet

Below is discussed a general bridging process in RouterOS. Most of the packets will always follow the same processing path, but in certain configurations (e.g. with enabled VLAN filtering, horizon, STP, DHCP, or IGMP snooping) some packets can be treated differently. Please visit the bridging manual for more specific information.
Bridge Forward

Bridge forward is a process that takes place when a packet is forwarded from one bridge port to another, essentially connecting multiple devices on the same network. After receiving a packet on the in-interface, the device determines that the in-interface is a bridge port, so it gets passed through the bridging process:

    A packet goes through the bridge NAT dst-nat chain, where MAC destination and priority can be changed, apart from that, a packet can be simply accepted, dropped, or marked;
    Checks whether the use-ip-firewall option is enabled in the bridge settings;
    Run packet through the bridge host table to make a forwarding decision. A packet that ends up being flooded (e.g. broadcast, multicast, unknown unicast traffic), gets multiplied per bridge port and then processed further in the bridge forward chain. When using vlan-filtering=yes, packets that are not allowed due to the "/interface bridge vlan" table, will be dropped at this stage.
    A packet goes through the bridge filter forward chain, where priority can be changed or the packet can be simply accepted, dropped, or marked;
    Checks whether the use-ip-firewall option is enabled in the bridge settings;
    A packet goes through the bridge NAT src-nat chain, where MAC source and priority can be changed, apart from that, a packet can be simply accepted, dropped, or marked;
    Checks whether the use-ip-firewall option is enabled in the bridge settings;


For RouterOS v6:
When bridge vlan-filtering is enabled, received untagged packets might get encapsulated into the VLAN header before the "DST-NAT" block, which means these packets can be filtered using the mac-protocol=vlan and vlan-encap settings. Encapsulation can happen if the outgoing interface has frame-types set to admit-all or admit-only-untagged-and-priority-tagged.

Tagged packets might get decapsulated on the "BRIDGING DECISION" block, which means these packets will no longer match the mac-protocol=vlan and vlan-encap settings. Decapsulation can happen if the packet's VLAN ID matches the outgoing port's untagged VLAN membership.

For RouterOS v7 and newer:

When bridge vlan-filtering is enabled, received untagged packets might get encapsulated into the VLAN header on the "BRIDGING-DECISION" block, which means these packets can be filtered using the mac-protocol=vlan and vlan-encap settings.  Encapsulation can happen if the outgoing interface has frame-types set to admit-all or admit-only-untagged-and-priority-tagged.

Tagged packets might get decapsulated on the "BRIDGING DECISION" block, which means these packets will no longer match the mac-protocol=vlan and vlan-encap settings. Decapsulation can happen if the packet's VLAN ID matches the outgoing port's untagged VLAN membership.
Bridge Input

Bridge input is a process that takes place when a packet is destined for the bridge interface. Most commonly this happens when you need to reach some services that are running on the bridge interface (e.g. a DHCP server) or you need to route traffic to other networks. The very first steps are similar to the bridge forward process - after receiving a packet on the in-interface, the device determines that the in-interface is a bridge port, so it gets passed through the bridging process:

    A packet goes through the bridge NAT dst-nat chain, where MAC destination and priority can be changed, apart from that, a packet can be simply accepted, dropped, or marked;
    Checks whether the use-ip-firewall option is enabled in the bridge settings;
    Run packet through the bridge host table to make a forwarding decision. A packet where the destination MAC address matches the bridge MAC address will be passed to the bridge input chain. A packet that ends up being flooded (e.g. broadcast, multicast, unknown unicast traffic), also reaches the bridge input chain as the bridge interface itself is one of the many destinations;
    A packet goes through the bridge filter input chain, where priority can be changed or the packet can be simply accepted, dropped, or marked;

Bridge Output

Bridge output is a process that takes place when a packet should exit the device through one or multiple bridge ports. Most commonly this happens when a bridge interface itself tries to reach a device connected to a certain bridge port (e.g. when a DHCP server running on a bridge interface is responding to a DHCP client). After a packet is processed on other higher-level RouterOS processes and the device finally determines that the output interface is a bridge, the packet gets passed through the bridging process:

    Run packet through the bridge host table to make a forwarding decision. A packet that ends up being flooded (e.g. broadcast, multicast, unknown unicast traffic), gets multiplied per bridge port and then processed further in the bridge output chain.
    A packet goes through the bridge filter output chain, where priority can be changed or the packet can be simply accepted, dropped, or marked;
    A packet goes through the bridge NAT src-nat chain, where MAC source and priority can be changed, apart from that, a packet can be simply accepted, dropped, or marked;
    Checks whether the use-ip-firewall option is enabled in the bridge settings;

Forward With Firewall Enabled

In certain network configurations, you might need to enable additional processing on routing chains for bridged traffic, for example, to use simple queues or an IP firewall. This can be done when the use-ip-firewall is enabled under the bridge settings. Note that additional processing will consume more CPU resources to handle these packets. All the steps were already discussed in previous points, below is a recap:

    A packet goes through the bridge NAT dst-nat chain;
    With the use-ip-firewall option enabled, the packet will be further processed in the prerouting chain;
    A packet enters prerouting processing;
    Run packet through the bridge host table to make forwarding decision;
    A packet goes through the bridge filter forward chain;
    With the use-ip-firewall option enabled, the packet will be further processed in the routing forward chain;
    A packet enters routing forward processing;
    A packet goes through the bridge NAT src-nat chain;
    With the use-ip-firewall option enabled, the packet will be further processed in the postrouting chain;
    A packet enters postrouting processing;

Flow of Hardware Offloaded Packet

On the previous topic, we solely discussed a software bridging that requires the main CPU processing to forward packets through the correct bridge port. Most of the MikroTik devices are equipped with dedicated switching hardware, the so-called switch chip or switch ASIC. This allows us to offload some of the bridging functions, like packet forwarding between bridge ports or packet filtering, to this specialized hardware chip without consuming any CPU resources. In RouterOS, we have named this function Bridge Hardware (HW) Offloading. Different MikroTik devices might have different switch chips and each chip has a different set of features available, so make sure to visit this article to get more details - Bridge Hardware Offloading.

Interface HTB will not work correctly when the out-interface is hardware offloaded and the bridge Fast Path is not active.

    switching decision - widely depends on the switch model. This block controls all the switching-related tasks, like host learning, packet forwarding, filtering, VLAN tagging/untagging, etc. Certain switch configurations can alter the packet flow;
    switch-cpu port - a special purpose switch port for communication between the main CPU and other switch ports. Note that the switch-cpu port does not show up anywhere on RouterOS except for the switch menu, none of the software-related configurations (e.g. interface-list) can be applied to this port. Packets that reach the CPU are automatically associated with the physical in-interface.

The hardware offloading, however, does not restrict a device to only hardware limited features, rather it is possible to take advantage of the hardware and software processing at the same time. This does require a profound understanding of how packets travel through the switch chip and when exactly they are passed to the main CPU.

Switch features found in the "/interface/ethernet/switch" menu and its sub-menus, like ACL rules, mirroring, ingress/egress rate limiters, QoS, and L3HW (except inter-VLAN routing) may not rely on bridge hardware offloading. Therefore, they can potentially be applied to interfaces not configured within a hardware-offloaded bridge.
Switch Forward

We will further discuss a packet flow when bridge hardware offloading is enabled and a packet is forwarded between two switched ports on a single switch chip. This is the most common and also the simplest example:

    The switch checks whether the in-interface is a hardware offloaded interface;
    Run a packet through the switch host table to make a forwarding decision. If the switch finds a match for the destination MAC address, the packet is sent out through the physical interface. A packet that ends up being flooded (e.g. broadcast, multicast, unknown unicast traffic) gets multiplied and sent out to every hardware offloaded switch port.

Switch to CPU Input

This process takes place when a packet is received on a physical interface and it is destined to switch-cpu port for further software processing. There are two paths to the switch-cpu. One where hardware offloading and switching is not even used (e.g. a standalone interface for routing or a bridged interface but with deliberately disabled HW offloading), so the packet is simply passed further for software processing. Another path is taken when hardware offloading is active on the in-interface. This will cause the packet to pass through the switching decision and there are various reasons why the switch might forward the packet to the switch-cpu port:

    a packet's destination MAC address match with a local MAC address, e.g. when a packet is destined to a local bridge interface;
    a packet might get flooded to all switch ports including the switch-cpu port, e.g. when broadcast, multicast, or unknown unicast traffic is received;
    a switch might have learned that some hosts can only be reached through the CPU (switch-cpu port learning is discussed in the next section), e.g. when a bridge contains HW and non-HW offloaded interfaces, such as wireless, EoIP, and even Ethernet interfaces;
    a packet is intentionally copied to the switch-cpu, e.g. for a packet inspection;
    a packet is triggered by the switch configuration and should be processed in software, e.g. a DHCP or IGMP snooping.

See the packet walkthrough when an in-interface is hardware offloaded:

    The switch checks whether the in-interface is a hardware offloaded interface;
    Run a packet through the switch host table to make a forwarding decision. In case any of the above-mentioned points are true, the packet gets forwarded to the switch-cpu port.
    The packet exits through the switch-cpu port and it will be further processed by the RouterOS packet flow.

Any received packet that was flooded by the switch chip will not get flooded again by the software bridge to the same HW offloaded switch group. This prevents the formation of duplicate packets.
CPU Output to Switch

This process takes place when a packet exits the RouterOS software processing and is received on the switch-cpu port. Again, there are two paths the packet can take. One where hardware offloading and switching are not even used (e.g. a standalone interface for routing or a bridged interface but with deliberately disabled HW offloading), so the packet is simply sent out through the physical out-interface. Another path is taken when hardware offloading is active on the out-interface. This will cause the packet to pass through the switching decision. Just like any other switch port, the switch will learn the source MAC addresses from packets that are received on the switch-cpu port. This does come in handy when a bridge contains HW and non-HW offloaded interfaces, so the switch can learn which frames should be forwarded to the CPU. See the packet walkthrough when an out-interface is hardware offloaded:

    A packet that exits the RouterOS software processing is received on the switch-cpu port;
    The switch checks whether the out-interface is a hardware offloaded interface;
    Run a packet through the switch host table to make a forwarding decision. If the switch finds a match for the destination MAC address, the packet is sent out through the physical interface. A packet that ends up being flooded (e.g. broadcast, multicast, unknown unicast traffic) gets multiplied and sent out to every hardware offloaded switch port.

A software bridge that sends a flooded packet through HW offloaded interfaces, will only send a single packet copy per HW offloaded switch group rather than per HW offloaded interface. The actual flooding will be done by the switch chip, this prevents the formation of duplicate packets.
Flow of MPLS Packet

Pop Label


Switch Label


Push Label


MPLS IP VPN

In VPNv4 setups packet arriving at PE router that needs to be forwarded to the CE router is not a typical "forward". 

If incoming label and destination is bound to the VRF Then after MPLS label is popped and:

    destination address is local to the router, then packet is moved to LOCAL_IN
    destination address is in the CE network, then packet is moved to LOCAL_OUT

Forwarded packets from MPLS cloud to the CE network will not show up in the forward.


For example traffic from src:111.15.0.1 to dst:111.13.0.1
[admin@CCR2004_2XS] /mpls/forwarding-table> print 
Flags: L - LDP, P - VPN
Columns: LABEL, VRF, PREFIX, NEXTHOPS
#   LABEL  VRF      PREFIX         NEXTHOPS                                                                                                           
0 P    17  myVrf    111.13.0.0/24  
4 L    20  main     203.0.113.2    { label=impl-null; nh=111.11.0.1; interface=sfp-sfpplus1 }
[admin@CCR2004_2XS] /mpls/forwarding-table>                                                           
...

[admin@CCR2004_2XS] /ip/route> print detail 
Flags: D - dynamic; X - disabled, I - inactive, A - active; c - connect, s - static, r - rip, b - bgp, o - ospf, i - is-is, d - dhcp, v - vpn, m - modem, y - bgp-mpls-vpn; 
H - hw-offloaded; + - ecmp 

   DAc   dst-address=111.11.0.0/24 routing-table=main gateway=sfp-sfpplus1 immediate-gw=sfp-sfpplus1 distance=0 scope=10 suppress-hw-offload=no 
         local-address=111.11.0.2%sfp-sfpplus1 
   DAc   dst-address=203.0.113.1/32 routing-table=main gateway=lo immediate-gw=lo distance=0 scope=10 suppress-hw-offload=no local-address=203.0.113.1%lo 
   DAo   dst-address=203.0.113.2/32 routing-table=main gateway=111.11.0.1%sfp-sfpplus1 immediate-gw=111.11.0.1%sfp-sfpplus1 distance=110 scope=20 target-scope=10 
         suppress-hw-offload=no 
   DAc   dst-address=111.13.0.0/24 routing-table=myVrf gateway=sfp-sfpplus2@myVrf immediate-gw=sfp-sfpplus2 distance=0 scope=10 suppress-hw-offload=no 
         local-address=111.13.0.2%sfp-sfpplus2@myVrf 
   DAy   dst-address=111.15.0.0/24 routing-table=myVrf gateway=203.0.113.2 immediate-gw=111.11.0.1%sfp-sfpplus1 distance=200 scope=40 target-scope=30 suppress-hw-offload=no [admin@CCR2004_2XS] /ip/route>              

Packet will be seen in the output and postrouting chains, because now it is locally originated packet with source MAC address equal to vrfInterface:
08:10:55 firewall,info output: in:(unknown 0) out:sfp-sfpplus2, connection-state:established src-mac f2:b5:e9:17:18:3b, proto ICMP (type 8, code 0), 111.15.0.1->111.13.0.1, len 56
08:10:55 firewall,info postrouting: in:myVrf out:sfp-sfpplus2, connection-state:established src-mac f2:b5:e9:17:18:3b, proto ICMP (type 8, code 0), 111.15.0.1->111.13.0.1, len 56

On the other hand, for packets routed in the direction CE→PE will be seen in the "forward" as any other routed IP traffic before being sent to the MPLS:
 08:10:55 firewall,info prerouting: in:sfp-sfpplus2 out:(unknown 0), connection-state:established src-mac dc:2c:6e:46:f8:93, proto ICMP (type 0, code 0), 111.13.0.1->111.15.0.1, len 56
 08:10:55 firewall,info forward: in:sfp-sfpplus2 out:sfp-sfpplus1, connection-state:established src-mac dc:2c:6e:46:f8:93, proto ICMP (type 0, code 0), 111.13.0.1->111.15.0.1, len 56
 08:10:55 firewall,info postrouting: in:sfp-sfpplus2 out:sfp-sfpplus1, connection-state:established src-mac dc:2c:6e:46:f8:93, proto ICMP (type 0, code 0), 111.13.0.1->111.15.0.1, len 56
 


But there can be an exception. If destination IP of reply packet is local to the router and connection tracking is performing NAT translation then connection tracking will "force" packet to move through the firewall prerouting/forward/postrouting chains.
Logical Interfaces

So far we looked at examples when in or out interfaces are actual physical interfaces (Ethernet, wireless), but how packets will flow if the router receives tunnel encapsulated packets?

Let's assume that there is an IPIP packet coming into the router. Since it is a regular ipv4 packet it will be processed through all routing-related facilities ( until "J" in the diagram). Then the router will look if the packet needs to be decapsulated., in this case, it is an IPIP packet so "yes" send the packet to decapsulation. After that packet will go another loop through all the facilities but this time as a decapsulated IPv4 packet.

It is very important because the packet actually travels through the firewall twice, so if there is a strict firewall, then there should be "accept" rules for IPIP encapsulated packets as well as decapsulated IP packets.

Packet encapsulation and decapsulation using a bridge with enabled vlan-filtering do not relate to logical interfaces. See more details in the bridging section.


IPSec Policies

Let's take a look at another tunnel type - IPSec. This type of VPN does not have logical interfaces but is processed in a similar manner.
Instead of logical interfaces packets are processed through IPSec policies. After routing decision (2) and input firewall processing (3), the router tries to match the source and destination to the IPsec policy. When policy matches the packet it is sent to decryption (5). After the decryption packet enters PREROUTING processing again (6) and starts another processing loop, but now with the decapsulated packet.



The same process is with encapsulation but in reverse order. The first IP packet gets processed through facilities, then matched against IPsec policies (5), encapsulated (6), and then sent to processing on the second loop (7-10).



Fast Path

From what we learned so far, it is quite obvious that such packet processing takes a lot of CPU resources. To fast things up FastPath was introduced in the first RouterOS v6. What it does is it skips processing in the Linux kernel, basically trading some RouterOS functionality for performance. For FastPath to work, interface driver support and specific configuration conditions are required.
How Fast Path Works

FastPath is an interface driver extension, that allows a driver to talk directly to specific RouterOS facilities and skip all others.

The packet can be forwarded by a fast path handler only if at least the source interface supports a fast path. For complete fast-forwarding, destination interface support is also required.

Currently, RouterOS has the following FastPath handlers:

    IPv4
    IPv4 FastTrack
    Traffic Generator
    MPLS
    Bridge


IPv4 FastPath handler is used if the following conditions are met:

    firewall rules are not configured;
    simple queue or queue trees with parent=global are not configured;
    no mesh, metarouter interface configuration;
    sniffer or torch is not running;
    connection tracking is not active;
    IP accounting is disabled;
    VRFs are not configured (/ip route vrf is empty);
    A hotspot is not used (/ip hotspot has no interfaces);
    IPSec policies are not configured;
    /tool mac-scan is not actively used;
    /tool ip-scan is not actively used.

Packets will travel the FastPath way if FastTrack is used no matter if the above conditions are met.


Traffic Generator automatically use FastPath if the interface supports this feature. 


Currently, MPLS fast-path applies to MPLS switched traffic (frames that enter router as MPLS and must leave router as MPLS) and VPLS endpoint that do VPLS encap/decap. Other MPLS ingress and egress will operate as before.


A Bridge handler is used if the following conditions are met:

    there are no bridge Calea, filter, NAT rules;
    use-ip-firewall is disabled;
    no mesh, MetaRouter interface configuration;
    sniffer, torch, and traffic generator are not running;
    bridge vlan-filtering is disabled (condition is removed since RouterOS 7.2 version);
    bridge dhcp-snooping is disabled.


FastPath on the vlan-filtering bridge does NOT support priority-tagged packets (packets with VLAN header but VLAN ID = 0). Those packets are redirected via a slow path.


Interfaces that support FastPath:
RouterBoard	Interfaces
RB6xx series	ether1,2
RB800	ether1,2
RB1100 series	ether1-11
All devices

	Ethernet interfaces
wireless interfaces
bridge interfaces
VLAN, VRRP interfaces
bonding interfaces (RX only)
PPPoE, L2TP interfaces
EoIP, GRE, IPIP, VXLAN interfaces.
VPLS (starting from v7.17)

EoIP, Gre, IPIP, VXLAN and L2TP interfaces have per-interface setting allow-fast-path. Allowing a fast path on these interfaces has a side effect of bypassing firewall, connection tracking, simple queues, queue tree with parent=global, IP accounting, IPsec, hotspot universal client, vrf assignment for encapsulated packets that go through a fast-path. Also, packet fragments cannot be received in FastPath.

Whether FastPath is being used can be verified with /interface print stats-detail

Only interface queue that guarantees FastPath is only-hardware-queue. If you need an interface queue other than hardware then the packet will not go fully FastPath, but there is not a big impact on performance, as "interface queue" is the last step in the packet flow.

The packet may go Half-FastPath by switching from FastPath to SlowPath, but not the other way around. So, for example, if the receiving interface has FastPath support, but the out interface does not, then the router will process the packet by FastPath handlers as far as it can and then proceed with SlowPath. If the receiving interface does not support FastPath but the out interface does, the packet will be processed by SlowPath all the way through the router.

FastTrack

Fasttrack can be decoded as Fast Path + Connection Tracking. It allows marking connections as "fast-tracked", marking packets that belong to fast-tracked connection will be sent fast-path way. The connection table entry for such a connection now will have a fast-tracked flag.

FastTrack packets bypass firewall, connection tracking, simple queues, queue tree with parent=global, ip traffic-flow, IP accounting, IPSec, hotspot universal client, VRF assignment, so it is up to the administrator to make sure FastTrack does not interfere with other configuration!

To mark a connection as fast-tracked new action was implemented "fasttrack-connection" for firewall filter and mangle. Currently, only IPv4 TCP and UDP connections can be fast-tracked and to maintain connection tracking entries some random packets will still be sent to a slow path. This must be taken into consideration when designing firewalls with enabled "fasttrack".

FastTrack handler also supports source and destination NAT, so special exceptions for NATed connections are not required.
Traffic that belongs to a fast-tracked connection travels in FastPath, which means that it will not be visible by other router L3 facilities (firewall, queues, IPsec, IP accounting, VRF assignment, etc). Fasttrack lookups route before routing marks have been set, so it works only with the main routing table.

The easiest way to start using this feature on home routers is to enable "fasttrack" for all established, related connections:
/ip firewall filter 
add chain=forward action=fasttrack-connection connection-state=established,related \
  comment="fasttrack established/related"
add chain=forward action=accept connection-state=established,related \
  comment="accept established/related"

Notice that the first rule marks established/related connections as fast-tracked, the second rule is still required to accept packets belonging to those connections. The reason for this is that, as was mentioned earlier, some random packets from fast-tracked connections are still sent the slow pathway and only UDP and TCP are fast-tracked, but we still want to accept packets for other protocols.

After adding the "FastTrack" rule special dummy rule appeared at the top of the list. This is not an actual rule, it is for visual information showing that some of the traffic is traveling FastPath and will not reach other firewall rules.

FastTrack can process packets only in the main routing table so it is the system administrator duty to not FastTrack connections that are going through non-main routing table (thus connections that are processed with mangle action=mark-routing rules). Otherwise packets might be misrouted though the main routing table.

These rules appear as soon as there is at least one fast-tracked connection tracking entry and will disappear after the last fast-tracked connection times out in the connection table.

The connection is FastTracked until a connection is closed, timed out or the router is rebooted.
Configuration example: excluding specific host, from being Fast-Tracked
/ip firewall filter
add action=accept chain=forward connection-state=established,related src-address=192.168.88.111
add action=accept chain=forward connection-state=established,related dst-address=192.168.88.111
add action=fasttrack-connection chain=forward connection-state=established,related hw-offload=no
add action=accept chain=forward connection-state=established,related

In this example, we exclude host 192.168.88.111, from being Fast-tracked, by first accepting it with the firewall rule, both for source and destination. The idea is - not allowing the traffic to reach the FastTrack action.

Note: the "exclusion" rules, must be placed before fasttrack filters, order is important.
Requirements

IPv4 FastTrack is active if the following conditions are met:

    no mesh, metarouter interface configuration;
    sniffer, torch, and traffic generator are not running;
    "/tool mac-scan" is not actively used;
    "/tool ip-scan" is not actively used;
    FastPath and Route cache are enabled under IP/Settings (route cache condition does not apply to RouterOS v7 or newer);
    bridge FastPath is enabled if a connection is going over the bridge interface;


Packet flow for the visually impaired

The following document in DOCX format describes the diagram in a way optimized for visually impaired people. The descriptions are by Apex CoVantage care of Benetech. They are not being updated.

    Packet flow, optimized document.
	
	
	

    Creado por Normunds R., actualizado por última vez por Mārtiņš S. el may 09, 2025 15 min de lectura

    Overview
        Rate limitation principles
    Simple Queue
        Configuration example
    Queue Tree
        Configuration example
    Queue Types
        Kinds
            FIFO
            RED
            SFQ
            PCQ
            CoDel
            FQ-Codel
            CAKE
    Interface Queue
    Queue load visualization in GUI

Overview

A queue is a collection of data packets collectively waiting to be transmitted by a network device using a pre-defined structure methodology. Queuing works almost on the same methodology used at banks or supermarkets, where the customer is treated according to its arrival.

Queues are used to:

    limit data rate for certain IP addresses, subnets, protocols, ports, etc.;
    limit peer-to-peer traffic;
    packet prioritization;
    configure traffic bursts for traffic acceleration;
    apply different time-based limits;
    share available traffic among users equally, or depending on the load of the channel

Queue implementation in MikroTik RouterOS is based on Hierarchical Token Bucket (HTB). HTB allows the creation of a hierarchical queue structure and determines relations between queues. These hierarchical structures can be attached at two different places, the Packet Flow diagram illustrates both input and postrouting chains.

There are two different ways how to configure queues in RouterOS:

    /queue simple menu - designed to ease the configuration of simple, every day queuing tasks (such as single client upload/download limitation, p2p traffic limitation, etc.).
    /queue tree menu - for implementing advanced queuing tasks (such as global prioritization policy, and user group limitations). Requires marked packet flows from  /ip firewall mangle facility.

RouterOS provides a possibility to configure queue in 8 levels -  the first level is an interface queue from the "/queue interface" menu and the other 7 are lower-level queues that can be created in Queue Simple and/or Queue Tree.
Rate limitation principles


Rate limiting is used to control the rate of traffic flow sent or received on a network interface. Traffic with rate that is less than or equal to the specified rate is sent, whereas traffic that exceeds the rate is dropped or delayed.

Rate limiting can be performed in two ways:

    discard all packets that exceed rate limit – rate-limiting (dropper or shaper) (100% rate limiter when queue-size=0)
    delay packets that exceed the specific rate limit in the queue and transmit them when it is possible – rate equalizing (scheduler) (100% rate equalizing when queue-size=unlimited)

The next figure explains the difference between rate limiting and rate equalizing:

As you can see in the first case all traffic exceeds a specific rate and is dropped. In another case, traffic exceeds a specific rate and is delayed in the queue and transmitted later when it is possible, but note that the packet can be delayed only until the queue is not full. If there is no more space in the queue buffer, packets are dropped.

For each queue we can define two rate limits:

    CIR (Committed Information Rate) – (limit-at in RouterOS) worst-case scenario, the flow will get this amount of traffic rate regardless of other traffic flows. At any given time, the bandwidth should not fall below this committed rate.
    MIR (Maximum Information Rate) – (max-limit in RouterOS) best-case scenario, the maximum available data rate for flow, if there is free any part of the bandwidth.

Simple Queue


/queue simple

A simple queue is a plain way how to limit traffic for a particular target. Also, you can use simple queues to build advanced QoS applications. They have useful integrated features:

    peer-to-peer traffic queuing;
    applying queue rules on chosen time intervals;
    prioritization;
    using multiple packet marks from /ip firewall mangle
    traffic shaping (scheduling) of bidirectional traffic (one limit for the total of upload + download)

Simple queues have a strict order - each packet must go through every queue until it reaches one queue which conditions fit packet parameters or until the end of the queues list is reached. For example, In the case of 1000 queues, a packet for the last queue will need to proceed through 999 queues before it will reach the destination. 

Simple queue target matches packets based on src and dst address. If src address matches target, then this is upload, if dst matches target, then this is download. However, if you have a connection where src and dst both match the target, then such packets will always be counted as download since both of them match dst (for each individual packet in both directions) which simply in RouterOS is the first thing compared to the target. Simple queue should be configured in a way that traffic can match only src or dst address, but not both of them at the same time.
Configuration example

In the following example, we have one SOHO device with two connected units PC and Server.

We have a 15 Mbps connection available from ISP in this case. We want to be sure the server receives enough traffic, so we will configure a simple queue with a limit-at parameter to guarantee a server receives 5Mbps:
/queue simple
add limit-at=5M/5M max-limit=15M/15M name=queue1 target=192.168.88.251/32

That is all. The server will get 5 Mbps of traffic rate regardless of other traffic flows. If you are using the default configuration, be sure the FastTrack rule is disabled for this particular traffic, otherwise, it will bypass Simple Queues and they will not work.
Queue Tree
/queue tree

The queue tree creates only a one-directional queue in one of the HTBs. It is also the only way how to add a queue on a separate interface. This way it is possible to ease mangle configuration - you don't need separate marks for download and upload - only the upload will get to the Public interface and only the download will get to a Private interface. The main difference from Simple Queues is that the Queue tree is not ordered - all traffic passes it together.
Configuration example

In the following example, we will mark all the packets coming from preconfigured in-interface-list=LAN and will limit the traffic with a queue tree based on these packet marks.

Let`s create a firewall address-list:
[admin@MikroTik] > /ip firewall address-list
add address=www.youtube.com list=Youtube
[admin@MikroTik] > ip firewall address-list print
Flags: X - disabled, D - dynamic 
 #   LIST                                                       ADDRESS                                                                        CREATION-TIME        TIMEOUT             
 0   Youtube                                                    www.youtube.com                                                                oct/17/2019 14:47:11
 1 D ;;; www.youtube.com
     Youtube                                                    216.58.211.14                                                                  oct/17/2019 14:47:11
 2 D ;;; www.youtube.com
     Youtube                                                    216.58.207.238                                                                 oct/17/2019 14:47:11
 3 D ;;; www.youtube.com
     Youtube                                                    216.58.207.206                                                                 oct/17/2019 14:47:11
 4 D ;;; www.youtube.com
     Youtube                                                    172.217.21.174                                                                 oct/17/2019 14:47:11
 5 D ;;; www.youtube.com
     Youtube                                                    216.58.211.142                                                                 oct/17/2019 14:47:11
 6 D ;;; www.youtube.com
     Youtube                                                    172.217.22.174                                                                 oct/17/2019 14:47:21
 7 D ;;; www.youtube.com
     Youtube                                                    172.217.21.142                                                                 oct/17/2019 14:52:21

Mark packets with firewall mangle facility:
[admin@MikroTik] > /ip firewall mangle
add action=mark-packet chain=forward dst-address-list=Youtube in-interface-list=LAN new-packet-mark=pmark-Youtube passthrough=yes

Configure the queue tree based on previously marked packets:
[admin@MikroTik] /queue tree
add max-limit=5M name=Limiting-Youtube packet-mark=pmark-Youtube parent=global

Check Queue tree stats to be sure traffic is matched:
[admin@MikroTik] > queue tree print stats
Flags: X - disabled, I - invalid 
 0   name="Limiting-Youtube" parent=global packet-mark=pmark-Youtube rate=0 packet-rate=0 queued-bytes=0 queued-packets=0 bytes=67887 packets=355 dropped=0 
Queue Types
/queue type

This sub-menu list by default created queue types and allows the addition of new user-specific ones.

By default, RouterOS creates the following pre-defined queue types:
[admin@MikroTik] > /queue type print
Flags: * - default 
 0 * name="default" kind=pfifo pfifo-limit=50 

 1 * name="ethernet-default" kind=pfifo pfifo-limit=50 

 2 * name="wireless-default" kind=sfq sfq-perturb=5 sfq-allot=1514 

 3 * name="synchronous-default" kind=red red-limit=60 red-min-threshold=10 red-max-threshold=50 red-burst=20 red-avg-packet=1000 

 4 * name="hotspot-default" kind=sfq sfq-perturb=5 sfq-allot=1514 

 5 * name="pcq-upload-default" kind=pcq pcq-rate=0 pcq-limit=50KiB pcq-classifier=src-address pcq-total-limit=2000KiB pcq-burst-rate=0 pcq-burst-threshold=0 pcq-burst-time=10s pcq-src-address-mask=32 
     pcq-dst-address-mask=32 pcq-src-address6-mask=128 pcq-dst-address6-mask=128 

 6 * name="pcq-download-default" kind=pcq pcq-rate=0 pcq-limit=50KiB pcq-classifier=dst-address pcq-total-limit=2000KiB pcq-burst-rate=0 pcq-burst-threshold=0 pcq-burst-time=10s pcq-src-address-mask=32 
     pcq-dst-address-mask=32 pcq-src-address6-mask=128 pcq-dst-address6-mask=128 

 7 * name="only-hardware-queue" kind=none 

 8 * name="multi-queue-ethernet-default" kind=mq-pfifo mq-pfifo-limit=50 

 9 * name="default-small" kind=pfifo pfifo-limit=10

All MikroTik products have the default queue type "only-hardware-queue" with "kind=none". "only-hardware-queue" leaves the interface with only hardware transmit descriptor ring buffer which acts as a queue in itself. Usually, at least 100 packets can be queued for transmit in the transmit descriptor ring buffer. Transmit descriptor ring buffer size and the number of packets that can be queued in it varies for different types of ethernet MACs. Having no software queue is especially beneficial on SMP systems because it removes the requirement to synchronize access to it from different CPUs/cores which is resource-intensive. Having the possibility to set "only-hardware-queue" requires support in an ethernet driver so it is available only for some ethernet interfaces mostly found on RouterBOARDs.

A "multi-queue-ethernet-default" can be beneficial on SMP systems with ethernet interfaces that have support for multiple transmit queues and have a Linux driver support for multiple transmit queues. By having one software queue for each hardware queue there might be less time spent on synchronizing access to them.

Improvement from only-hardware-queue and multi-queue-ethernet-default is present only when there is no "/queue tree" entry with a particular interface as a parent.
Kinds

Queue kinds are packet processing algorithms. Kind describe which packet will be transmitted next in the line. RouterOS supports the following Queueing kinds:

    FIFO (BFIFO, PFIFO, MQ PFIFO)
    RED
    SFQ
    PCQ

FIFO

These kinds are based on the FIFO algorithm (First-In-First-Out). The difference between PFIFO and BFIFO is that one is measured in packets and the other one in bytes. These queues use pfifo-limit and bfifo-limit parameters.

Every packet that cannot be enqueued (if the queue is full), is dropped. Large queue sizes can increase latency but utilize the channel better.

MQ-PFIFO is pfifo with support for multiple transmit queues. This queue is beneficial on SMP systems with ethernet interfaces that have support for multiple transmit queues and have a Linux driver support for multiple transmit queues (mostly on x86 platforms). This kind uses the mq-pfifo-limit parameter.
RED

Random Early Drop is a queuing mechanism that tries to avoid network congestion by controlling the average queue size. The average queue size is compared to two thresholds: a minimum (minth) and a maximum (maxth) threshold. If the average queue size (avgq) is less than the minimum threshold, no packets are dropped. When the average queue size is greater than the maximum threshold, all incoming packets are dropped. But if the average queue size is between the minimum and maximum thresholds packets are randomly dropped with probability Pd where probability is exact a function of the average queue size: Pd = Pmax(avgq – minth)/ (maxth - minth). If the average queue grows, the probability of dropping incoming packets grows too. Pmax - ratio, which can adjust the packet discarding probability abruptness, (the simplest case Pmax can be equal to one. The 8.2 diagram shows the packet drop probability in the RED algorithm.


SFQ

Stochastic Fairness Queuing (SFQ) is ensured by hashing and round-robin algorithms. SFQ is called "Stochastic" because it does not really allocate a queue for each flow, it has an algorithm that divides traffic over a limited number of queues (1024) using a hashing algorithm.

Traffic flow may be uniquely identified by 4 options (src-address, dst-address, src-port, and dst-port), so these parameters are used by the SFQ hashing algorithm to classify packets into one of 1024 possible sub-streams. Then round-robin algorithm will start to distribute available bandwidth to all sub-streams, on each round giving sfq-allot bytes of traffic. The whole SFQ queue can contain 128 packets and there are 1024 sub-streams available. The 8.3 diagram shows the SFQ operation:

PCQ

PCQ algorithm is very simple - at first, it uses selected classifiers to distinguish one sub-stream from another, then applies individual FIFO queue size and limitation on every sub-stream, then groups all sub-streams together and applies global queue size and limitation.

PCQ parameters:

    pcq-classifier (dst-address | dst-port | src-address | src-port; default: "") : selection of sub-stream identifiers
    pcq-rate (number): maximal available data rate of each sub-steam
    pcq-limit (number): queue size of single sub-stream (in KiB)
    pcq-total-limit (number): maximum amount of queued data in all sub-streams (in KiB)

 It is possible to assign a speed limitation to sub-streams with the pcq-rate option. If "pcq-rate=0" sub-streams will divide available traffic equally.

For example, instead of having 100 queues with 1000kbps limitation for download, we can have one PCQ queue with 100 sub-streams

PCQ has burst implementation identical to Simple Queues and Queue Tree:

    pcq-burst-rate (number): maximal upload/download data rate which can be reached while the burst for substream is allowed
    pcq-burst-threshold (number): this is the value of burst on/off switch
    pcq-burst-time (time): a period of time (in seconds) over which the average data rate is calculated. (This is NOT the time of the actual burst)

PCQ also allows using different size IPv4 and IPv6 networks as sub-stream identifiers. Before it was locked to a single IP address. This is done mainly for IPv6 as customers from an ISP point of view will be represented by /64 network, but devices in customers network will be /128. PCQ can be used for both of these scenarios and more. PCQ parameters:

    pcq-dst-address-mask (number): the size of the IPv4 network that will be used as a dst-address sub-stream identifier
    pcq-src-address-mask (number): the size of the IPv4 network that will be used as an src-address sub-stream identifier
    pcq-dst-address6-mask (number): the size of the IPV6 network that will be used as a dst-address sub-stream identifier
    pcq-src-address6-mask (number): the size of the IPV6 network that will be used as an src-address sub-stream identifier


The following queue kinds CoDel, FQ-Codel, and CAKE available since RouterOS version 7.1beta3.
CoDel

CoDel (Controlled-Delay Active Queue Management) algorithm uses the local minimum queue as a measure of the persistent queue, similarly, it uses a minimum delay parameter as a measure of the standing queue delay. Queue size is calculated using packet residence time in the queue.

Properties
codel-ce-threshold (default: )	

Marks packets above a configured threshold with ECN.
codel-ecn (default: no)	

An option is used to mark packets instead of dropping them.
codel-interval (default: 100ms)	

Interval should be set on the order of the worst-case RTT through the bottleneck giving endpoints sufficient time to react.
codel-limit (default: 1000)	Queue limit, when the limit is reached, incoming packets are dropped.
codel-target (default: 5ms)	

Represents an acceptable minimum persistent queue delay.
FQ-Codel

CoDel - Fair Queuing (FQ) with Controlled Delay (CoDel) uses a randomly determined model to classify incoming packets into different flows and is used to provide a fair share of the bandwidth to all the flows using the queue. Each flow is managed using CoDel queuing discipline which internally uses a FIFO algorithm.

Properties
fq-codel-ce-threshold (default: )	Marks packets above a configured threshold with ECN.
fq-codel-ecn (default: yes)	An option is used to mark packets instead of dropping them.
fq-codel-flows (default: 1024)	

A number of flows into which the incoming packets are classified.
fq-codel-interval (default: 100ms)	Interval should be set on the order of the worst-case RTT through the bottleneck giving endpoints sufficient time to react.
fq-codel-limit (default: 10240)	Queue limit, when the limit is reached, incoming packets are dropped.
fq-codel-memlimit (default: 32.0MiB)	

A total number of bytes that can be queued in this FQ-CoDel instance. Will be enforced from the fq-codel-limit parameter.
fq-codel-quantum (default: 1514)	

A number of bytes used as 'deficit' in the fair queuing algorithm. Default (1514 bytes) corresponds to the Ethernet MTU plus the hardware header length of 14 bytes.
fq-codel-target (default: 5ms)	Represents an acceptable minimum persistent queue delay.
CAKE

CAKE - Common Applications Kept Enhanced (CAKE) implemented as a queue discipline (qdisc) for the Linux kernel uses COBALT (AQM algorithm combining Codel and BLUE) and a variant of DRR++ for flow isolation. In other words, Cake’s fundamental design goal is user-friendliness. All settings are optional; the default settings are chosen to be practical in most common deployments. In most cases, the configuration requires only a bandwidth parameter to get useful results,

Properties
cake-ack-filter (default: none )	
cake-atm (default: )	

Compensates for ATM cell framing, which is normally found on ADSL links.
cake-autorate-ingress (yes/no, default: )	

Automatic capacity estimation based on traffic arriving at this qdisc. This is most likely to be useful with cellular links, which tend to change quality randomly.  The Bandwidth Limit parameter can be used in conjunction to specify an initial estimate. The shaper will periodically be set to a bandwidth slightly below the estimated rate.  This estimator cannot estimate the bandwidth of links downstream of itself.
cake-bandwidth (default: )	Sets the shaper bandwidth.
cake-diffserv (default: diffserv3)	

CAKE can divide traffic into "tins" based on the Diffserv field:

    diffserv4 Provides a general-purpose Diffserv implementation with four tins: Bulk (CS1), 6.25% threshold, generally low priority. Best Effort (general), 100% threshold. Video (AF4x, AF3x, CS3, AF2x, CS2, TOS4, TOS1), 50% threshold. Voice (CS7, CS6, EF, VA, CS5, CS4), 25% threshold.

    diffserv3 (default) Provides a simple, general-purpose Diffserv implementation with three tins: Bulk (CS1), 6.25% threshold, generally low priority. Best Effort (general), 100% threshold. Voice (CS7, CS6, EF, VA, TOS4), 25% threshold, reduced Codel interval.

cake-flowmode (dsthost/dual-dsthost/dual-srchost/flowblind/flows/hosts/srchost/triple-isolate, default: triple-isolate)	

    flowblind - Disables flow isolation; all traffic passes through a single queue for each tin.
    srchost - Flows are defined only by source address. 
    dsthost Flows are defined only by destination address. 
    hosts - Flows are defined by source-destination host pairs. This is host isolation, rather than flow isolation.
    flows - Flows are defined by the entire 5-tuple of source address, a destination address, transport protocol, source port, and destination port. This is the type of flow isolation performed by SFQ and fq_codel.
    dual-srchost Flows are defined by the 5-tuple, and fairness is applied first over source addresses, then over individual flows. Good for use on egress traffic from a LAN to the internet, where it'll prevent any LAN host from monopolizing the uplink, regardless of the number of flows they use.
    dual-dsthost Flows are defined by the 5-tuple, and fairness is applied first over destination addresses, then over individual flows. Good for use on ingress traffic to a LAN from the internet, where it'll prevent any LAN host from monopolizing the downlink, regardless of the number of flows they use.
    triple-isolate - Flows are defined by the 5-tuple, and fairness is applied over source *and* destination addresses intelligently (ie. not merely by host-pairs), and also over individual flows.
    nat Instructs Cake to perform a NAT lookup before applying flow- isolation rules, to determine the true addresses and port numbers of the packet, to improve fairness between hosts "inside" the NAT. This has no practical effect in "flowblind" or "flows" modes, or if NAT is performed on a different host.
    nonat (default) The cake will not perform a NAT lookup. Flow isolation will be performed using the addresses and port numbers directly visible to the interface Cake is attached to.

cake-memlimit (default: )	

Limit the memory consumed by Cake to LIMIT bytes. By default, the limit is calculated based on the bandwidth and RTT settings.
cake-mpu ( -64 ... 256, default: )	

Rounds each packet (including overhead) up to a minimum length BYTES. 
cake-nat (default: no)	

Instructs Cake to perform a NAT lookup before applying a flow-isolation rule.
cake-overhead ( -64 ... 256, default: )	

Adds BYTES to the size of each packet. BYTES may be negative.
cake-overhead-scheme (default: )	
cake-rtt (default: 100ms )	

Manually specify an RTT. Default 100ms is suitable for most Internet traffic.
cake-rtt-scheme (datacentre/internet/interplanetary/lan/metro/none/oceanic/regional/satellite, default: )	

    datacentre - For extremely high-performance 10GigE+ networks only. Equivalent to RTT 100us.
    lan - For pure Ethernet (not Wi-Fi) networks, at home or in the office. Don't use this when shaping for an Internet access link. Equivalent to RTT 1ms.
    metro - For traffic mostly within a single city. Equivalent to RTT 10ms. regional For traffic mostly within a European-sized country. Equivalent to RTT 30ms.
    internet (default) This is suitable for most Internet traffic. Equivalent to RTT 100ms.
    oceanic - For Internet traffic with generally above-average latency, such as that suffered by Australasian residents. Equivalent to RTT 300ms.
    satellite - For traffic via geostationary satellites. Equivalent to RTT 1000ms.
    interplanetary - So named because Jupiter is about 1 light-hour from Earth. Use this to (almost) completely disable AQM actions. Equivalent to RTT 3600s.

cake-wash (default: no )	

Apply the wash option to clear all extra DiffServ (but not ECN bits), after priority queuing has taken place.
Interface Queue
/queue interface

Before sending data over an interface, it is processed by the queue. This sub-menu lists all available interfaces in RouterOS and allows to change queue type for a particular interface. The list is generated automatically.
[admin@MikroTik] > queue interface print
Columns: INTERFACE, QUEUE, ACTIVE-QUEUE
# INTERFACE QUEUE ACTIVE-QUEUE
0 ether1 only-hardware-queue only-hardware-queue
1 ether2 only-hardware-queue only-hardware-queue
2 ether3 only-hardware-queue only-hardware-queue
3 ether4 only-hardware-queue only-hardware-queue
4 ether5 only-hardware-queue only-hardware-queue
5 ether6 only-hardware-queue only-hardware-queue
6 ether7 only-hardware-queue only-hardware-queue
7 ether8 only-hardware-queue only-hardware-queue
8 ether9 only-hardware-queue only-hardware-queue
9 ether10 only-hardware-queue only-hardware-queue
10 sfp-sfpplus1 only-hardware-queue only-hardware-queue
11 wlan1 wireless-default wireless-default
12 wlan2 wireless-default wireless-default 
Queue load visualization in GUI

In Winbox and Webfig, a green, yellow, or red icon visualizes each Simple and Tree queue usage based on max-limit.

	0% - 50% of max-limit used

	50%  - 75% of max-limit used 

	75% - 100% of max-limit used
	
	
	

    Creado por Artūrs C., actualizado por última vez por Druvis Timma el may 20, 2025 7 min de lectura

    Introduction
    Token Bucket algorithm (Red part of the diagram)
        Packet queue (Blue part of the diagram)
        Token rate selection (Black part of the diagram)
        The Diagram
        Bucket Size in action
            Default Queue Bucket
            Large Queue Bucket
            Large Child Queue Bucket, Small Parent Queue Bucket
    Configuration
        Dual Limitation
            Priority
        Examples
            Structure
            Example 1: Usual case
            Result of Example 1
            Example 2: Usual case with max-limit
            Result of Example 2
            Example 3: Inner queue limit-at
            Result of Example 3
            Example 4: Leaf queue limit-at
            Result of Example 4

Introduction

HTB (Hierarchical Token Bucket) is a classful queuing discipline that is useful for rate limiting and burst handling. This article will focus on those HTB aspects exclusively in RouterOS, as we use a modified version to deliver features like Simple Queue and Queue Tree. 
Token Bucket algorithm (Red part of the diagram)

The Token Bucket algorithm is based on an analogy to a bucket where tokens, represented in bytes, are added at a specific rate. The bucket itself has a specified capacity.

If the bucket fills to capacity, newly arriving tokens are dropped.

Bucket capacity = bucket-size * max-limit

    bucket size (0..10, Default:0.1)

Before allowing any packet to pass through the queue, the queue bucket is inspected to see if it already contains sufficient tokens at that moment.

If yes, the appropriate number of tokens are removed ("cashed in") and the packet is permitted to pass through the queue.

If not, the packets stay at the start of the packet waiting queue until the appropriate amount of tokens is available.

In the case of a multi-level queue structure, tokens used in a child queue are also 'charged' to their parent queues. In other words - child queues 'borrow' tokens from their parent queues.
Packet queue (Blue part of the diagram)

The size of this packet queue, the sequence, how packets are added to this queue, and when packets are discarded is determined by:

    queue-type - Queue
    queue-size - Queue Size

Token rate selection (Black part of the diagram)

The maximal token rate at any given time is equal to the highest activity of these values:

    limit-at (NUMBER/NUMBER): guaranteed upload/download data rate to a target
    max-limit (NUMBER/NUMBER): maximal upload/download data rate that is allowed for a target
    burst-limit (NUMBER/NUMBER): maximal upload/download data rate that is allowed for a target while the 'burst' is active

burst-limit is active only when 'burst' is in the allowed state - more info here: Queue Burst

In a case where limit-at is the highest value, extra tokens need to be issued to compensate for all missing tokens that were not borrowed from its parent queue.
The Diagram

Bucket Size in action

Let's have a simple setup where all traffic from and to one IP address is marked with a packet-mark:
/ip firewall mangle
add chain=forward action=mark-connection connection-mark=no-mark src-address=192.168.88.101 new-connection-mark=pc1_conn
add chain=forward action=mark-connection connection-mark=no-mark dst-address=192.168.88.101 new-connection-mark=pc1_conn
add chain=forward action=mark-packet connection-mark=pc1_conn new-packet-mark=pc1_traffic
Default Queue Bucket
/queue tree
add name=download parent=Local packet-mark=PC1-traffic max-limit=10M
add name=upload parent=Public packet-mark=PC1-traffic max-limit=10M


In this case bucket-size=0.1, so bucket-capacity= 0.1 x 10M = 1M

If the bucket is full (that is, the client was not using the full capacity of the queue for some time), the next 1Mb of traffic can pass through the queue at an unrestricted speed.
Large Queue Bucket
/queue tree
add name=download parent=Local packet-mark=PC1-traffic max-limit=10M bucket-size=10
add name=upload parent=Public packet-mark=PC1-traffic max-limit=10M bucket-size=10

Let's try to apply the same logic to a situation when bucket size is at its maximal value:


In this case bucket-size=10, so bucket-capacity= 10 x 10M = 100M

If the bucket is full (that is, the client was not using the full capacity of the queue for some time), the next 100Mb of traffic can pass through the queue at an unrestricted speed.

So you can have:

    20Mbps transfer speed for 10s
    60Mbps transfer burst for 2s
    1Gbps transfer burst for approximately 100ms

You can therefore see that the bucket permits a type of 'burstiness' of the traffic that passes through the queue. The behavior is similar to the normal burst feature but lacks the upper limit of the burst. This setback can be avoided if we utilize bucket size in the queue structure:
Large Child Queue Bucket, Small Parent Queue Bucket
/queue tree
add name=download_parent parent=Local max-limit=20M
add name=download parent=download_parent packet-mark=PC1-traffic max-limit=10M bucket-size=10
add name=upload_parent parent=Public max-limit=20M
add name=upload parent=upload_parent packet-mark=PC1-traffic max-limit=10M bucket-size=10


In this case:

    parent queue bucket-size=0.1, bucket-capacity= 0.1 x 20M = 2M
    child queue bucket-size=10, bucket-capacity= 10 x 10M = 100M

The parent will run out of tokens much faster than the child queue and as its child queue always borrows tokens from the parent queue the whole system is restricted to token-rate of the parent queue - in this case to max-limit=20M. This rate will be sustained until the child queue runs out of tokens and will be restricted to its token rate of 10Mbps.

In this way, we can have a burst at 20Mbps for up to 10 seconds.
Configuration

We have to follow three basic steps to create HTB:

    Match and mark traffic – classify traffic for further use. Consists of one or more matching parameters to select packets for the specific class;
    Create rules (policy) to mark traffic – put specific traffic classes into specific queues and define the actions that are taken for each class;
    Attach a policy for specific interface(-s) – append policy for all interfaces (global-in, global-out, or global-total), for a specific interface, or for a specific parent queue;

HTB allows to create of a hierarchical queue structure and determines relations between queues, like "parent-child" or "child-child".

As soon as the queue has at least one child it becomes an inner queue, all queues without children - are leaf queues. Leaf queues make actual traffic consumption, Inner queues are responsible only for traffic distribution. All leaf queues are treated on an equal basis.

In RouterOS, it is necessary to specify the parent option to assign a queue as a child to another queue.
Dual Limitation

Each queue in HTB has two rate limits:

    CIR (Committed Information Rate) – (limit-at in RouterOS) worst case scenario, the flow will get this amount of traffic no matter what (assuming we can actually send so much data);
    MIR (Maximal Information Rate) – (max-limit in RouterOS) best case scenario, a rate that flow can get up to if their queue's parent has spare bandwidth;

In other words, at first limit-at (CIR) of all queues will be satisfied, only then child queues will try to borrow the necessary data rate from their parents in order to reach their max-limit (MIR).

CIR will be assigned to the corresponding queue no matter what. (even if max-limit of the parent is exceeded)

That is why, to ensure optimal (as designed) usage of the dual limitation feature, we suggest sticking to these rules:

    The Sum of committed rates of all children must be less or equal to the amount of traffic that is available to parents;

CIR(parent)* ≥ CIR(child1) +...+ CIR(childN)*in case if parent is main parent CIR(parent)=MIR(parent)

    The maximal rate of any child must be less or equal to the maximal rate of the parent

MIR (parent) ≥ MIR(child1) & MIR (parent) ≥ MIR(child2) & ... & MIR (parent) ≥ MIR(childN)


Queue colors in Winbox:

    0% - 50% available traffic used - green
    51% - 75% available traffic used - yellow
    76% - 100% available traffic used - red

Priority

We already know that limit-at (CIR) to all queues will be given out no matter what.

Priority is responsible for the distribution of remaining parent queues traffic to child queues so that they are able to reach max-limit

The queue with higher priority will reach its max-limit before the queue with lower priority. 8 is the lowest priority, and 1 is the highest.

Make a note that priority only works:

    for leaf queues - priority in the inner queue has no meaning.
    if max-limit is specified (not 0)

Examples

In this section, we will analyze HTB in action. To do that we will take one HTB structure and will try to cover all the possible situations and features, by changing the amount of incoming traffic that HTB has to recycle. and changing some options.
Structure

Our HTB structure will consist of 5 queues:

    Queue01 inner queue with two children - Queue02 and Queue03
    Queue02 inner queue with two children - Queue04 and Queue05
    Queue03 leaf queue
    Queue04 leaf queue
    Queue05 leaf queue

Queue03, Queue04, and Queue05 are clients who require 10Mbps all the time Outgoing interface is able to handle 10Mbps of traffic.
Example 1: Usual case

    Queue01 limit-at=0Mbps max-limit=10Mbps
    Queue02 limit-at=4Mbps max-limit=10Mbps
    Queue03 limit-at=6Mbps max-limit=10Mbps priority=1
    Queue04 limit-at=2Mbps max-limit=10Mbps priority=3
    Queue05 limit-at=2Mbps max-limit=10Mbps priority=5

Result of Example 1

    Queue03 will receive 6Mbps
    Queue04 will receive 2Mbps
    Queue05 will receive 2Mbps
    Clarification: HTB was built in a way, that, by satisfying all limit-ats, the main queue no longer has throughput to distribute.

Example 2: Usual case with max-limit

    Queue01 limit-at=0Mbps max-limit=10Mbps
    Queue02 limit-at=4Mbps max-limit=10Mbps
    Queue03 limit-at=2Mbps max-limit=10Mbps priority=3
    Queue04 limit-at=2Mbps max-limit=10Mbps priority=1
    Queue05 limit-at=2Mbps max-limit=10Mbps priority=5

Result of Example 2

    Queue03 will receive 2Mbps
    Queue04 will receive 6Mbps
    Queue05 will receive 2Mbps
    Clarification: After satisfying all limit-ats HTB will give throughput to the queue with the highest priority.

Example 3: Inner queue limit-at

    Queue01 limit-at=0Mbps max-limit=10Mbps
    Queue02 limit-at=8Mbps max-limit=10Mbps
    Queue03 limit-at=2Mbps max-limit=10Mbps priority=1
    Queue04 limit-at=2Mbps max-limit=10Mbps priority=3
    Queue05 limit-at=2Mbps max-limit=10Mbps priority=5

Result of Example 3

    Queue03 will receive 2Mbps
    Queue04 will receive 6Mbps
    Queue05 will receive 2Mbps
    Clarification: After satisfying all limit-ats HTB will give throughput to the queue with the highest priority. But in this case, inner queue Queue02 had limit-at specified, by doing so, it reserved 8Mbps of throughput for queues Queue04 and Queue05. Of these two Queue04 has the highest priority, which is why it gets additional throughput.

Example 4: Leaf queue limit-at

    Queue01 limit-at=0Mbps max-limit=10Mbps
    Queue02 limit-at=4Mbps max-limit=10Mbps
    Queue03 limit-at=6Mbps max-limit=10Mbps priority=1
    Queue04 limit-at=2Mbps max-limit=10Mbps priority=3
    Queue05 limit-at=12Mbps max-limit=15Mbps priority=5

Result of Example 4

    Queue03 will receive ~3Mbps
    Queue04 will receive ~1Mbps
    Queue05 will receive ~6Mbps
    Clarification: Only by satisfying all limit-ats HTB was forced to allocate 20Mbps - 6Mbps to Queue03, 2Mbps to Queue04, and 12Mbps to Queue05, but our output interface is able to handle 10Mbps. As the output interface queue is usually FIFO throughput allocation will keep the ratio 6:2:12 or 3:1:6
	
	
	

    Creado por Artūrs C., actualizado por última vez por Druvis Timma el may 20, 2025 3 min de lectura

    Example
        100% Shaper
        100% Scheduler
        Default-small queue type
        Default queue type

The maximum permissible queue size could be specified as a maximum memory limit, but a lot of algorithms simplify it as a maximum number of packets, so the actual memory used varies depending on the size of the packets. 

The rest of this page demonstrates how this works with queue types like PFIFO, BFIFO, PCQ and RED, that deal with packet count.
Example

This example was created to highlight the queue size impact on traffic that was queued by a specific queue.

For a simplified visualization, let's assume we are processing data in steps and we know exactly how many packets will be received/transited in every step and there will be no dropped packet retransmission taking place.

As you can see in the picture above there are 25 steps and there are a total of 1610 incoming packets over this time frame.
100% Shaper

A queue is 100% shaper when every packet that is over the allowed limits will be dropped immediately. This way all packages that are not dropped will be sent out without any delay.

Let's apply max-limit=100 packets per step limitation to our example:


With this type of limitation, only 1250 out of 1610 packets were able to pass the queue (22,4% packet drop), but all packets arrive without delay.
100% Scheduler

A queue is 100% Scheduler when there are no packet drops at all, all packets are queued and will be sent out at the first possible moment.

In each step, the queue must send out queued packets from previous steps first and only then send out packets from this step, this way it is possible to keep the right sequence of packets.

We will again use the same limit (100 packets per step).

There was no packet loss, but 630 (39,1%) packets had 1 step delay, and the other 170 (10,6%) packets had 2 step delay. (delay = latency)
Default-small queue type

It is also possible to choose the middle way when the queue uses both of these queuing aspects (shaping and scheduling). By default, most of the queues in RouterOS have a queue size of 10.


There were 320 (19,9%) packets dropped and 80 (5,0%) packets had 1 step delay.
Default queue type

Another popular queue size in RouterOS is 50.

There were 190 (11,8%) packets dropped and 400 (24,8%) packets had 1 step delay.




    Creado por Artūrs C. el jul 22, 2022 7 min de lectura

    Introduction
    Example
        Burst-time=16s
        Burst-time=8s

Introduction

Burst is a feature that allows satisfying queue requirements for additional bandwidth even if the required rate is bigger than MIR (max-limit) for a limited period of time.

Burst can occur only if average-rate of the queue for the last burst-time seconds is smaller than burst-threshold. Burst will stop if average-rate of the queue for the last burst-time seconds is bigger or equal to burst-threshold.

The burst mechanism is simple - if a burst is allowed max-limit value is replaced by the burst-limit value. When the burst is disallowed max-limit value remains unchanged.


    burst-limit (NUMBER) : maximal upload/download data rate which can be reached while the burst is allowed;
    burst-time (TIME) : period of time, in seconds, over which the average data rate is calculated. (This is NOT the time of actual burst);
    burst-threshold (NUMBER) : this is value of burst on/off switch;
    average-rate (read-only) : Every 1/16 part of the burst-time, the router calculates the average data rate of each class over the last burst-time seconds;
    actual-rate (read-only) : actual traffic transfer rate of the queue;

Example

Values: limit-at=1M , max-limit=2M , burst-threshold=1500k , burst-limit=4M

The client will try to download two 4MB (32Mb) blocks of data, the first download will start at zero seconds, and the second download will start at 17th second. Traffic was unused at the last minute.
Burst-time=16s

As we can see as soon as the client requested bandwidth it was able to get 4Mpbs burst for 6 seconds. This is longest possible burst with given values (longest-burst-time = burst-threshold * burst-time / burst-limit). As soon as the burst runs out rest of the data will be downloaded with 2Mbps. This way block of data was downloaded in 9 seconds - without burst, it would take 16 seconds. Burst has 7 seconds to recharge before the next download will start.

Note that burst is still disallowed when download started and it kicks in only afterward - in the middle of a download. So with this example, we proved that a burst may happen in the middle of a download. The burst was ~4 seconds long and the second block was downloaded 4 seconds faster than without burst.

The average rate is calculated every 1/16 of burst time so in this case 1s
0	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0)/16=0Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
1	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+4)/16=250Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
2	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+4+4)/16=500Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
3	(0+0+0+0+0+0+0+0+0+0+0+0+0+4+4+4)/16=750Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
4	(0+0+0+0+0+0+0+0+0+0+0+0+4+4+4+4)/16=1000Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
5	(0+0+0+0+0+0+0+0+0+0+0+4+4+4+4+4)/16=1250Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
6	(0+0+0+0+0+0+0+0+0+0+4+4+4+4+4+4)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
7	(0+0+0+0+0+0+0+0+0+4+4+4+4+4+4+2)/16=1625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
8	(0+0+0+0+0+0+0+0+4+4+4+4+4+4+2+2)/16=1750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
9	(0+0+0+0+0+0+0+4+4+4+4+4+4+2+2+2)/16=1875Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
10	(0+0+0+0+0+0+4+4+4+4+4+4+2+2+2+2)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
11	(0+0+0+0+0+4+4+4+4+4+4+2+2+2+2+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
12	(0+0+0+0+4+4+4+4+4+4+2+2+2+2+0+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
13	(0+0+0+4+4+4+4+4+4+2+2+2+2+0+0+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
14	(0+0+4+4+4+4+4+4+2+2+2+2+0+0+0+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
15	(0+4+4+4+4+4+4+2+2+2+2+0+0+0+0+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
16	(4+4+4+4+4+4+2+2+2+2+0+0+0+0+0+0)/16=2Mbps	average-rate > burst-threshold → Burst not allowed	0Mbps
17	(4+4+4+4+4+2+2+2+2+0+0+0+0+0+0+0)/16=1750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
18	(4+4+4+4+2+2+2+2+0+0+0+0+0+0+0+2)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
19	(4+4+4+2+2+2+2+0+0+0+0+0+0+0+2+2)/16=1375Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
20	(4+4+2+2+2+2+0+0+0+0+0+0+0+2+2+4)/16=1375Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
21	(4+2+2+2+2+0+0+0+0+0+0+0+2+2+4+4)/16=1375Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
22	(2+2+2+2+0+0+0+0+0+0+0+2+2+4+4+4)/16=1375Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps
23	(2+2+2+0+0+0+0+0+0+0+2+2+4+4+4+4)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
24	(2+2+0+0+0+0+0+0+0+2+2+4+4+4+4+2)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
25	(2+0+0+0+0+0+0+0+2+2+4+4+4+4+2+2)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
26	(0+0+0+0+0+0+0+2+2+4+4+4+4+2+2+2)/16=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps
27	(0+0+0+0+0+0+2+2+4+4+4+4+2+2+2+2)/16=1625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
28	(0+0+0+0+0+2+2+4+4+4+4+2+2+2+2+2)/16=1750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps
29	(0+0+0+0+2+2+4+4+4+4+2+2+2+2+2+2)/16=1875Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps
30	(0+0+0+2+2+4+4+4+4+2+2+2+2+2+2+0)/16=1875Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps
31	(0+0+2+2+4+4+4+4+2+2+2+2+2+2+0+0)/16=1875Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps
Burst-time=8s

If we decrease burst-time to 8 seconds - we are able to see that in this case, bursts are only at the beginning of downloads The average rate is calculated every 1/16th of burst time, so in this case every 0.5 seconds.
0.0	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0)/8=0Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
0.5	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+2)/8=250Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
1.0	(0+0+0+0+0+0+0+0+0+0+0+0+0+0+2+2)/8=500Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
1.5	(0+0+0+0+0+0+0+0+0+0+0+0+0+2+2+2)/8=750Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
2.0	(0+0+0+0+0+0+0+0+0+0+0+0+2+2+2+2)/8=1000Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
2.5	(0+0+0+0+0+0+0+0+0+0+0+2+2+2+2+2)/8=1250Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
3.0	(0+0+0+0+0+0+0+0+0+0+2+2+2+2+2+2)/8=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
3.5	(0+0+0+0+0+0+0+0+0+2+2+2+2+2+2+1)/8=1625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
4.0	(0+0+0+0+0+0+0+0+2+2+2+2+2+2+1+1)/8=1750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
4.5	(0+0+0+0+0+0+0+2+2+2+2+2+2+1+1+1)/8=1875Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
5.0	(0+0+0+0+0+0+2+2+2+2+2+2+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
5.5	(0+0+0+0+0+2+2+2+2+2+2+1+1+1+1+1)/8=2125Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
6.0	(0+0+0+0+2+2+2+2+2+2+1+1+1+1+1+1)/8=2250Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
6.5	(0+0+0+2+2+2+2+2+2+1+1+1+1+1+1+1)/8=2375Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
7.0	(0+0+2+2+2+2+2+2+1+1+1+1+1+1+1+1)/8=2500Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
7.5	(0+2+2+2+2+2+2+1+1+1+1+1+1+1+1+1)/8=2625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
8.0	(2+2+2+2+2+2+1+1+1+1+1+1+1+1+1+1)/8=2750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
8.5	(2+2+2+2+2+1+1+1+1+1+1+1+1+1+1+1)/8=2625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
9.0	(2+2+2+2+1+1+1+1+1+1+1+1+1+1+1+1)/8=2500Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
9.5	(2+2+2+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2375Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
10.0	(2+2+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2250Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
10.5	(2+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2125Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
11.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
11.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
12.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
12.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
13.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
13.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+0)/8=1875Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
14.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+0+0)/8=1750Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
14.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+0+0+0)/8=1625Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
15.0	(1+1+1+1+1+1+1+1+1+1+1+1+0+0+0+0)/8=1500Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
15.5	(1+1+1+1+1+1+1+1+1+1+1+0+0+0+0+0)/8=1375Kbps	average-rate < burst-threshold → Burst is allowed	0Mbps (0Mb per 0,5sek)
16.0	(1+1+1+1+1+1+1+1+1+1+0+0+0+0+0+0)/8=1250Kbps	average-rate < burst-threshold → Burst is allowed	0Mbps (0Mb per 0,5sek)
16.5	(1+1+1+1+1+1+1+1+1+0+0+0+0+0+0+0)/8=1125Kbps	average-rate < burst-threshold → Burst is allowed	0Mbps (0Mb per 0,5sek)
17.0	(1+1+1+1+1+1+1+1+0+0+0+0+0+0+0+0)/8=1000Kbps	average-rate < burst-threshold → Burst is allowed	2Mbps (1Mb per 0,5sek)
17.5	(1+1+1+1+1+1+1+0+0+0+0+0+0+0+0+1)/8=1000Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
18.0	(1+1+1+1+1+1+0+0+0+0+0+0+0+0+1+2)/8=1125Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
18.5	(1+1+1+1+1+0+0+0+0+0+0+0+0+1+2+2)/8=1250Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
19.0	(1+1+1+1+0+0+0+0+0+0+0+0+1+2+2+2)/8=1375Kbps	average-rate < burst-threshold → Burst is allowed	4Mbps (2Mb per 0,5sek)
19.5	(1+1+1+0+0+0+0+0+0+0+0+1+2+2+2+2)/8=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
20.0	(1+1+0+0+0+0+0+0+0+0+1+2+2+2+2+1)/8=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
20.5	(1+0+0+0+0+0+0+0+0+1+2+2+2+2+1+1)/8=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
21.0	(0+0+0+0+0+0+0+0+1+2+2+2+2+1+1+1)/8=1500Kbps	average-rate = burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
21.5	(0+0+0+0+0+0+0+1+2+2+2+2+1+1+1+1)/8=1625Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
22.0	(0+0+0+0+0+0+1+2+2+2+2+1+1+1+1+1)/8=1750Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
22.5	(0+0+0+0+0+1+2+2+2+2+1+1+1+1+1+1)/8=1875Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
23.0	(0+0+0+0+1+2+2+2+2+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
23.5	(0+0+0+1+2+2+2+2+1+1+1+1+1+1+1+1)/8=2125Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
24.0	(0+0+1+2+2+2+2+1+1+1+1+1+1+1+1+1)/8=2250Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
24.5	(0+1+2+2+2+2+1+1+1+1+1+1+1+1+1+1)/8=2375Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
25.0	(1+2+2+2+2+1+1+1+1+1+1+1+1+1+1+1)/8=2500Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
25.5	(2+2+2+2+1+1+1+1+1+1+1+1+1+1+1+1)/8=2500Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
26.0	(2+2+2+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2375Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
26.5	(2+2+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2250Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
27.0	(2+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2125Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
27.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
28.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
28.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
29.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
29.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
30.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	2Mbps (1Mb per 0,5sek)
30.5	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+1)/8=2000Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)
31.0	(1+1+1+1+1+1+1+1+1+1+1+1+1+1+1+0)/8=1875Kbps	average-rate > burst-threshold → Burst not allowed	0Mbps (0Mb per 0,5sek)





    Creado por Artūrs C., actualizado por última vez por Druvis Timma el may 20, 2025 2 min de lectura

Per Connection Queue (PCQ) is a queuing discipline that can be used to dynamically equalize or shape traffic for multiple users, using little administration. It is possible to divide PCQ scenarios into three major groups: equal bandwidth for a number of users, certain bandwidth equal distribution between users, and unknown bandwidth equal distribution between users.
Equal Bandwidth for a Number of Users

Use PCQ type can be used through the Queue Tree and Simple Queues to equalize the bandwidth [and set max limit] for a number of users. We will set the 64kbps download and 32kbps upload limits.

Step 1: add PCQ in Queue Types

Add two new entries - one for download and one for upload. dst-address is a classifier for the user's download traffic, and src-address for upload traffic:
/queue type add name="PCQ_download" kind=pcq pcq-rate=64000 pcq-classifier=dst-address
/queue type add name="PCQ_upload" kind=pcq pcq-rate=32000 pcq-classifier=src-address
 
Step 2: deploy the PCQ
Queue Tree option

Mark all packets with packet-marks upload/download: (let's consider that ether1-WAN is the public interface to the Internet and ether2-LAN is a local interface where clients are connected):
/ip firewall mangle add chain=prerouting action=mark-packet \
   in-interface=ether2-LAN new-packet-mark=client_upload
/ip firewall mangle add chain=prerouting action=mark-packet \
   in-interface=ether1-WAN new-packet-mark=client_download

Then, two queue rules are required, one for download and one for upload:
/queue tree add parent=global queue=PCQ_download packet-mark=client_download
/queue tree add parent=global queue=PCQ_upload packet-mark=client_upload
Simple Queues option

Alternatively you can do it with one command like so:
/queue simple add target=192.168.0.0/24 queue=PCQ_upload/PCQ_download




    Creado por Usuario desconocido (elvijsi), actualizado por última vez por Druvis Timma el may 20, 2025 3 min de lectura

Overview 

Queue types are like templates for classless queuing disciplines - the algorithms that control how packets are dropped or queued up in a memory buffer before further transmission. They are crucial for ensuring good Quality of Service, as they can not only help when bandwidth limits are exceeded, but also affect other aspects like latency.

Their complexity and attributes vary a lot. For example, a First-In-First-Out (FIFO) queue is simple and ensures fairness in the order of packet processing, but it can lead to issues such as head-of-line blocking. More complex queue types, such as those that implement fair queuing or congestion avoidance, can help manage network performance more effectively, but they may require more resources and configuration.

Therefore, the choice of queue type depends on the specific needs and characteristics of the network.
Queue types at a glance

    BFIFO (Byte-oriented First In, First Out):
        Features: BFIFO is a simple byte-oriented queuing discipline that sends out packets in the order they arrived and based on their size.
        Advantages: Simplicity and fairness in packet management.
        Disadvantages: BFIFO can lead to head-of-line blocking, where a large packet can delay all the smaller packets behind it. Also, there is no mechanism to prevent congestion or prioritize packets.

    PFIFO (Packet-oriented First In, First Out):
        Features: Like BFIFO but operates on a packet basis rather than bytes.
        Advantages: Easy to implement and understand. It's fair in terms of packet numbers.
        Disadvantages: Like BFIFO, it suffers from head-of-line blocking and doesn't have any congestion management mechanism.

    CAKE (Common Applications Kept Enhanced):
        Features: A comprehensive queue management system designed to combat bufferbloat and ensure fair queuing. It combines CoDel, FQ, and other technologies.
        Advantages: Excellent at managing latency under any network condition. It's particularly useful in consumer broadband connections.
        Disadvantages: More complex to configure than simpler queuing disciplines. Not ideal for all use cases, particularly where fine-tuned control is required.

    CoDel (Controlled Delay):
        Features: CoDel aims to improve bufferbloat by dropping packets to control queue delay.
        Advantages: Good at managing latency and avoiding bufferbloat.
        Disadvantages: CoDel on its own does not provide fair queuing.

    FQ_CoDel (Fair Queuing Controlled Delay):
        Features: Combines the latency management of CoDel with fair queuing.
        Advantages: Excellent latency management and fair distribution of bandwidth among flows. Generally considered a good default choice.
        Disadvantages: More complex than simpler queue disciplines, which can make it harder to configure.

    MQ_PFIFO (Multiqueue Packet First In, First Out):
        Features: MQ_PFIFO is an extension of PFIFO that supports multiple queues.
        Advantages: Allows different queues for different types or priorities of traffic.
        Disadvantages: Still suffers from head-of-line blocking and lacks a built-in congestion management mechanism.

    RED (Random Early Detection):
        Features: RED aims to anticipate and prevent congestion by randomly dropping packets before the queue becomes full.
        Advantages: Helps to prevent congestion and can improve overall network performance.
        Disadvantages: Configuration can be complex and needs to be tuned for the network's specific characteristics. Misconfiguration can lead to reduced performance.

    SFQ (Stochastic Fairness Queuing):
        Features: SFQ aims to ensure a fair distribution of resources among flows by assigning them to different dynamic queues.
        Advantages: Helps to prevent a single flow from dominating the connection.
        Disadvantages: SFQ does not manage latency or congestion. The number of queues can also increase memory usage.

In choosing a queue discipline, you'll need to consider the characteristics of your network and what you prioritize most, such as latency, fairness, simplicity, or congestion management.





    Creado por Usuario desconocido (elvijsi), actualizado por última vez el ago 15, 2024 14 min de lectura

CAKE (Common Applications Kept Enhanced)
Description:

CAKE (Common Applications Kept Enhanced) is a modern, advanced queue management algorithm designed to cope with varying network conditions and different types of traffic. It was developed to address the limitations of older algorithms and provide an all-in-one solution to several common network problems.

CAKE's approach is to maintain fairness, minimize bufferbloat, and manage different types of traffic with minimal configuration and tuning. This is achieved through various techniques including flow isolation, bandwidth shaping, and prioritization of small packets.
Bandwith Limit: 	This allows you to manually set the bandwidth limit for the CAKE shaper. For instance, if you're aware that your ISP provides you with a 100Mbps connection, you could set the rate to 100Mbps to prevent CAKE from trying to use more bandwidth than available.
Autorate Ingress	This is useful in situations where the connection quality varies. For example, if you're on a cellular data connection that can fluctuate wildly based on signal strength, this option allows CAKE to adjust the shaper bandwidth dynamically to match the estimated capacity of the link.
Overhead	The overhead parameter in the CAKE queue discipline allows you to specify the per-packet overhead (in bytes) to account for when shaping traffic. This is particularly important when dealing with technologies such as DSL, where protocol encapsulation adds additional bytes to each packet. Accurately accounting for these overheads will lead to more precise control of the actual bandwidth being used.
MPU	The Minimum Packet Unit (MPU) parameter allows you to round up the size of each packet to a specified minimum. This is useful for link layer technologies that have a minimum packet size. For example, if your link layer technology has a minimum packet size of 64 bytes, you can configure CAKE with mpu 64.
ATM	This is for Asynchronous Transfer Mode, a type of network technology often used in DSL broadband connections. ATM uses fixed 53-byte cells, each of which can carry 48 bytes of payload. The atm keyword compensates for this overhead.
Overhead Scheme	The overhead compensation feature in CAKE allows it to account for the extra bytes added by various link layer technologies, which can be significant in some cases. This is important because CAKE operates on the packet sizes reported by the Linux kernel, which do not include these extra bytes. If the overhead is not accounted for, CAKE's shaper might allow more data onto the link than it can actually handle, leading to unexpected packet loss.
RTT	Manually specify an RTT. This is for advanced users who know the exact RTT they want to use.
RTT Scheme	The CAKE queue discipline allows you to specify the Round Trip Time (RTT) it should consider when managing traffic. This is important because the time it takes for a packet to travel from a source to a destination and back impacts how CAKE manages network congestion. If the actual RTT of your network is close to the value you specify, both the throughput and latency of your network should be well managed.
Diffserv	Diffserv (Differentiated Services) is a mechanism used to prioritize and classify network traffic based on the Diffserv field in the IP packet header. CAKE (Common Applications Kept Enhanced) provides Diffserv support, allowing traffic to be divided into "tins" (traffic classes) and applying different treatment to each tin.
Flow Mode	When flow isolation is enabled, CAKE puts packets from different flows into different queues. Each queue maintains its own Active Queue Management (AQM) state, and packets are delivered from each queue fairly using a DRR++ (Deficit Round Robin++) algorithm. This algorithm works to minimize latency for "sparse" flows, or flows that contain fewer packets.
ACK Filter	ACK or acknowledgment filters are a feature of the Cake algorithm that allows for the handling of TCP ACK (acknowledgment) packets. TCP ACK packets are essential to the function of the TCP protocol; they acknowledge the receipt of TCP segments, providing a form of flow control. However, these packets can consume a significant portion of your upload bandwidth, especially when downloading large files. By implementing ACK filtering, Cake can compress these ACKs, reducing their impact on upload bandwidth.
NAT	

These options control how CAKE handles traffic when Network Address Translation (NAT) is being used. nat makes CAKE consider the post-NAT addresses and ports when isolating flows, which can be useful when you're shaping traffic on a router that is also performing NAT for its connected devices.
Wash	The "wash" option in the CAKE queue discipline is used to address the issue of frequently mis-marked traffic entering or exiting a DiffServ (Differentiated Services) domain. When traffic passes through networks or providers, there is a chance that the DSCP (Differentiated Services Code Point) markings could be modified or incorrectly assigned.
Overhead Schemes

The overhead compensation feature in CAKE allows it to account for the extra bytes added by various link layer technologies, which can be significant in some cases. This is important because CAKE operates on the packet sizes reported by the Linux kernel, which do not include these extra bytes. If the overhead is not accounted for, CAKE's shaper might allow more data onto the link than it can actually handle, leading to unexpected packet loss.

    Manual Overhead Specification: You can manually specify the overhead in bytes. For instance, if you know your link layer adds 18 bytes of overhead to each packet, you can configure CAKE with overhead 18. Negative values are also accepted, within a range of -64 to 256 bytes.

    MPU: The Minimum Packet Unit (MPU) parameter allows you to round up the size of each packet to a specified minimum. This is useful for link layer technologies that have a minimum packet size. For example, if your link layer technology has a minimum packet size of 64 bytes, you can configure CAKE with mpu 64.

    ATM: This is for Asynchronous Transfer Mode, a type of network technology often used in DSL broadband connections. ATM uses fixed 53-byte cells, each of which can carry 48 bytes of payload. The atm keyword compensates for this overhead.

    PTM: This is for Packet Transfer Mode, another network technology often used in VDSL2 connections. PTM uses a 64b/65b encoding scheme, which effectively reduces the usable bandwidth by a small amount. The ptm keyword compensates for this overhead.

    Failsafe Overhead Keywords: The raw and conservative keywords are provided for quick-and-dirty setup. raw turns off all overhead compensation in CAKE, and conservative compensates for more overhead than is likely to occur on any widely-deployed link technology.

    ADSL Overhead Keywords: Most ADSL modems use ATM cell framing and have additional overhead due to the PPPoA or PPPoE protocol used. Keywords such as pppoa-vcmux, pppoe-llc, etc. are provided to account for these overheads.

    VDSL2 Overhead Keywords: VDSL2 uses PTM instead of ATM and may also use PPPoE. Keywords such as pppoe-ptm and bridged-ptm are provided to account for these overheads.

    DOCSIS Cable Overhead Keyword: DOCSIS is the standard for providing Internet service over cable-TV infrastructure. The docsis keyword is provided to account for the overhead of DOCSIS.

    Ethernet Overhead Keywords: These keywords account for the overhead of Ethernet frames, including the preamble, inter-frame gap, and Frame Check Sequence. ethernet and ether-vlan are provided for Ethernet and Ethernet with VLAN respectively​1​.

RTT Schemes

The CAKE queue discipline allows you to specify the Round Trip Time (RTT) it should consider when managing traffic. This is important because the time it takes for a packet to travel from a source to a destination and back impacts how CAKE manages network congestion. If the actual RTT of your network is close to the value you specify, both the throughput and latency of your network should be well managed.

Here are the RTT settings you can use, what they mean, and when you might use them:

    rtt TIME: Manually specify an RTT. This is for advanced users who know the exact RTT they want to use.

    datacentre: This is for extremely high-performance networks, such as a 10 Gigabit Ethernet (10GigE) network in a data center. The RTT is assumed to be 100 microseconds. Example: Use this if you're managing network traffic in a high-capacity data center.

    lan: This is for pure Ethernet networks, such as those you might find in a home or office environment. The RTT is assumed to be 1 millisecond. Example: Use this if you're managing traffic on a wired home or office network, but not when shaping for an Internet access link.

    metro: This is for traffic mostly within a single city. The RTT is assumed to be 10 milliseconds. Example: Use this if you're managing traffic for a network in a single city, like a city-wide corporate network.

    regional: This is for traffic mostly within a European-sized country. The RTT is assumed to be 30 milliseconds. Example: Use this if you're managing traffic for a network that spans a country.

    internet: This is suitable for most Internet traffic. The RTT is assumed to be 100 milliseconds. Example: Use this if you're managing general Internet traffic on a typical broadband connection.

    oceanic: This is for Internet traffic with generally above-average latency, such as that suffered by Australasian residents. The RTT is assumed to be 300 milliseconds. Example: Use this if you're managing traffic in a location with high latency, like Australia or New Zealand.

    satellite: This is for traffic via geostationary satellites. The RTT is assumed to be 1000 milliseconds (1 second). Example: Use this if you're managing traffic for a network that uses a satellite internet connection.

    interplanetary: This disables Active Queue Management (AQM) actions, because the RTT is so long (3600 seconds). It's named "interplanetary" because the distance from Earth to Jupiter is about one light-hour. Example: This is not typically used in standard networking situations, but might be useful in extremely high latency situations, such as experimental long-distance communication scenarios.

Remember, these are guidelines, and the best setting depends on the specific characteristics and requirements of your network. If you are unsure, the internet setting is a good starting point for most scenarios​1​.
FLOW ISOLATION PARAMETER

When flow isolation is enabled, CAKE puts packets from different flows into different queues. Each queue maintains its own Active Queue Management (AQM) state, and packets are delivered from each queue fairly using a DRR++ (Deficit Round Robin++) algorithm. This algorithm works to minimize latency for "sparse" flows, or flows that contain fewer packets.

The key aspect here is the method by which CAKE determines different flows, known as "flow isolation." CAKE uses a set-associative hashing algorithm to reduce flow collisions.

    flowblind - This parameter disables flow isolation, and all traffic goes through a single queue for each 'tin' or traffic class. Useful in scenarios where specific flow isolation is not needed or desired, such as when you want to process all traffic the same way regardless of source or destination.
    srchost - Here, flows are determined solely by the source address. This could be beneficial on the outgoing path of an Internet Service Provider (ISP) backhaul. A telecom company might use this to ensure fair use of its backbone network by different regions or customers.
    dsthost - With this parameter, flows are characterized only by their destination address. This might be beneficial on the incoming path of an ISP backhaul. An enterprise could use this to balance incoming traffic to its different servers.
    hosts - In this case, flows are defined by source-destination host pairs. This is host isolation rather than flow isolation. This might be useful in a data center network, where you want to ensure that communication between specific pairs of servers is fair.
    flows - Flows are characterized by the entire 5-tuple: source address, destination address, transport protocol, source port, and destination port. This is the kind of flow isolation performed by SFQ and fq_codel. This could be used by a cloud provider to ensure fairness among different virtual machines communicating over various protocols and ports.
    dual-srchost - Here, flows are defined by the 5-tuple, and fairness is applied first over source addresses, then over individual flows. This is a good choice for outgoing traffic from a Local Area Network (LAN) to the Internet. A university might use this to prevent any single user or device from hogging the internet connection, no matter how many different connections they're using.
    dual-dsthost - In this case, flows are defined by the 5-tuple, and fairness is applied first over destination addresses, then over individual flows. This is suitable for incoming traffic to a LAN from the internet. A large company could use this to prevent any single server or system from overwhelming the network's incoming bandwidth.
    triple-isolate - This is the default setting where flows are defined by the 5-tuple. Fairness is applied over both source and destination addresses intelligently, as well as over individual flows. This prevents any one host on either side of the link from monopolizing it with a large number of flows. A Internet Service Provider (ISP) might use this to ensure fair service to all its customers, regardless of how many connections they have and whether they

Ack Filter

ACK or acknowledgement filters are a feature of the Cake algorithm that allows for the handling of TCP ACK (acknowledgment) packets. TCP ACK packets are essential to the function of the TCP protocol; they acknowledge the receipt of TCP segments, providing a form of flow control. However, these packets can consume a significant portion of your upload bandwidth, especially when downloading large files. By implementing ACK filtering, Cake can compress these ACKs, reducing their impact on upload bandwidth.

    ack-filter - This enables the ACK filter feature. With this option, Cake will attempt to identify and filter out ACK packets that do not convey significant new information or do not need to be sent immediately, helping to improve the utilization of the upload bandwidth.
    ack-filter-aggressive - This is a more aggressive version of the ack-filter option. It will result in more ACK packets being compressed or filtered out, which can lead to further improvements in upload bandwidth utilization but may potentially impact TCP performance.The use of the ack-filter or ack-filter-aggressive options depends on your specific network conditions and requirements. For instance, if you find that ACK packets are using a large portion of your available upload bandwidth, then enabling the ACK filter might help. On the other hand, if you're experiencing issues with TCP performance and suspect that ACK filtering might be contributing, you could try disabling it or using the less aggressive option.

Wash

The "wash" option in the CAKE queue discipline is used to address the issue of frequently mis-marked traffic entering or exiting a DiffServ (Differentiated Services) domain. When traffic passes through networks or providers, there is a chance that the DSCP (Differentiated Services Code Point) markings could be modified or incorrectly assigned.

To illustrate this with a real-life example and analogy:

Let's imagine you are running a busy airport. Different airlines have assigned different priority levels to their passengers based on their ticket classes (economy, business, first-class). These priority levels are analogous to the DSCP markings in a network.

However, as passengers move through various transit airports, there is a possibility that the assigned priority levels could be changed or mis-marked due to different airline policies or inconsistencies at the transit airports. This is similar to the mis-marking of traffic in transit networks.

Now, in the context of the airport, let's assume that upon arrival at your airport, passengers are divided into separate queues based on their priority levels. This division ensures that passengers in higher-priority classes are processed more quickly and receive better service.

However, because the priority levels assigned at previous airports may not be reliable, it becomes necessary to "wash" or clear the assigned priority levels before the passengers enter the queues at your airport. This is similar to the "wash" option in CAKE, which clears extra DSCP markings after priority queuing has taken place.

In situations where inbound traffic's DSCP markings cannot be trusted (similar to cases like Comcast Cable), it is recommended to use a single queue "besteffort" mode with the "wash" option. This means that all incoming traffic is treated as the default "best effort" class, and any potentially unreliable or mis-marked DSCP values are cleared before further processing.

In our airport analogy, using a single queue "besteffort" mode with "wash" would mean that regardless of the priority assigned at previous airports, all passengers are initially treated as standard passengers (best effort class) until their priority can be accurately determined and assigned at your airport.

This approach ensures that even if the DSCP markings of incoming traffic have been mis-marked or modified during transit, the traffic is treated fairly and uniformly within your network, without relying on potentially unreliable markings from external sources.

By applying the "wash" option in CAKE, network administrators can mitigate the impact of mis-marked or modified DSCP markings, providing a more consistent and reliable Quality of Service (QoS) treatment within their network domain.
Diffserv RFC2474 and RFC2475

Diffserv (Differentiated Services) is a mechanism used to prioritize and classify network traffic based on the Diffserv field in the IP packet header. CAKE (Common Applications Kept Enhanced) provides Diffserv support, allowing traffic to be divided into "tins" (traffic classes) and applying different treatment to each tin. Here's a breakdown of the Diffserv presets in CAKE along with real-world examples:

besteffort -The "besteffort" preset in CAKE disables priority queuing and places all traffic into a single tin. This means that all traffic is treated equally without any specific prioritization. This preset can be suitable for non-critical or low-priority traffic, such as general web browsing or background file downloads, where equal treatment is sufficient.

precedence - The "precedence" preset enables the legacy interpretation of the TOS (Type of Service) "Precedence" field. However, its usage on the modern internet is discouraged, as it is an outdated mechanism. In the past, this field was used to indicate different levels of priority, such as high, medium, or low, but it is no longer widely used or recommended.

diffserv4 - The "diffserv4" preset provides a general-purpose Diffserv implementation with four tins: 

    Bulk: This tin corresponds to CS1 (Class Selector 1) or LE (Low Extra), and it has a threshold of 6.25%. Traffic in this tin typically has a low priority.
    Best Effort: This tin is for general traffic that doesn't fall into any specific Diffserv class. It has a threshold of 100%, meaning it receives all remaining bandwidth.
    Video: This tin encompasses AF4x, AF3x, CS3, AF2x, CS2, TOS4, and TOS1. It has a threshold of 50%, providing a moderate priority for video traffic.
    Voice: This tin covers CS7, CS6, EF (Expedited Forwarding), VA (Voice Admit), CS5, and CS4. It has a threshold of 25%, giving high priority to voice traffic.

In a network where video streaming, voice over IP (VoIP), and general internet traffic coexist, this preset can ensure that video and voice traffic receive appropriate priority, while bulk and best-effort traffic are handled accordingly.

diffserv3 (default) - The "diffserv3" preset is the default Diffserv implementation in CAKE, providing three tins:

    Bulk: Similar to the "diffserv4" preset, this tin represents CS1 or LE with a 6.25% threshold, serving as a low-priority traffic class.
    Best Effort: This tin is for general traffic and has a threshold of 100%, treating all remaining traffic equally.
    Voice: This tin covers CS7, CS6, EF, VA, and TOS4. It has a threshold of 25% and applies a reduced CoDel (Controlled Delay) interval, giving high priority to voice traffic.

In a network where voice traffic requires high priority, such as a VoIP system, while other traffic falls into a general category, the "diffserv3" preset can ensure appropriate priority for voice packets while maintaining fairness for other traffic.

diffserv8 - is an more advances purpuse diffserver with 8 tins:

The 8 classes in DiffServ8 are mapped to different types of network traffic based on their importance, using decimal values for Differentiated Services Code Point (DSCP):

    Network Control (48-63): Highest priority, often used for critical network traffic like routing information.
    Telephony (46): Traffic sensitive to latency, such as VoIP.
    Signaling (32-47): Control signals for real-time applications.
    Multimedia Conferencing (24-31): Video conferencing traffic.
    Real-time Interactive (40): Interactive applications, such as gaming.
    Multimedia Streaming (16-23): Streaming video and audio.
    Low Latency Data (8-15): Traffic requiring low latency, like financial transactions.
    Best Effort (0): Default traffic class with no special priority.

"unlimited" or "autorate-ingress"

When using the "unlimited" or "autorate-ingress" option in the CAKE queue discipline, CAKE automatically determines the download speed based on observed packet arrival times. Here's how it works:

    Monitoring Packet Arrival Times: CAKE continuously monitors the arrival times of incoming packets. It keeps track of the time intervals between consecutive packets to estimate the rate at which packets are being received.

    Calculating Average Packet Arrival Rate: CAKE calculates the average packet arrival rate based on the observed arrival times. By dividing the number of received packets by the total time elapsed, it determines the average rate at which packets are arriving.

    Deriving Download Speed: From the average packet arrival rate, CAKE infers the download speed or throughput of the network connection. It assumes that the packet arrival rate corresponds to the download speed, given that each packet represents a certain amount of data.

    Dynamic Adjustment: As CAKE continues to monitor packet arrival times, it adjusts the download speed estimation dynamically. If the arrival rate increases, CAKE will update the download speed estimate to reflect the higher throughput. Conversely, if the arrival rate decreases, CAKE will adjust the estimate accordingly.

By automatically determining the download speed, CAKE adapts to changes in the network conditions and ensures that traffic shaping and queuing algorithms are adjusted to optimize the utilization of available bandwidth.

It's worth noting that while CAKE can estimate the download speed based on packet arrival times, it does not have direct knowledge of the link capacity or the true download speed as reported by the network equipment or service provider. Instead, it relies on observed packet arrival rates to approximate the download speed for traffic shaping purposes.




    Creado por Usuario desconocido (elvijsi), actualizado por última vez por GG el abr 23, 2024 3 min de lectura

PFIFO (Packet First-In, First-Out)
Description:

PFIFO (Packet First-In, First-Out) is a queue management strategy that follows the basic queue logic. The main principle of PFIFO is that the first packet to arrive is the first packet to be transmitted out. This method is simple, and straightforward, and ensures that no packet receives preferential treatment over the others.

When packets enter the queue, they are placed at the end (tail) of the queue. As space becomes available for transmission, the packets at the front (head) of the queue are transmitted first. If the queue is full when a packet arrives, the packet is dropped or other policies are followed, depending on the overall queue management strategy in place.
Characteristics:

    Simplicity: PFIFO is one of the simplest forms of queue management. It doesn't require complex algorithms or significant computational resources. This makes it easy to implement and understand.

    Fairness: All packets are treated equally, regardless of their source, destination, or content. The first packet in is the first one out.

    No Prioritization: There's no inherent capability to prioritize certain types of traffic over others. While this ensures fairness, it can be a drawback when dealing with different types of network traffic that might need prioritization.

Examples:

Imagine a line at the post office. Each person (packet) waiting in line represents a data packet waiting in the queue. The first person in line gets served first, then the next, and so on. If the post office is too busy and the line is full, any new person arriving would have to wait or leave (the packet is dropped).
Conclusion:

While PFIFO is simple and straightforward, its lack of traffic prioritization capabilities can be a downside, especially when managing network traffic that contains different types of data. In these situations, more complex queue management algorithms, such as Priority Queuing (PQ), Class-Based Weighted Fair Queuing (CBWFQ), or Low Latency Queuing (LLQ), might be more suitable.


BFIFO (Byte First-In, First-Out)
Description:

BFIFO (Byte First-In, First-Out) is another queue management strategy, similar to PFIFO in its principle of operation, but with a key difference: BFIFO operates based on the size of packets, or bytes, rather than on the number of packets.

In a BFIFO system, when packets enter the queue, they are still placed at the end, and packets at the front are transmitted first. However, the queue size is calculated in bytes, not in number of packets. When the queue reaches its maximum byte size, any new packets that arrive are dropped, or other policies are followed.
Characteristics:

    Byte-Based: Unlike PFIFO, BFIFO calculates the queue size based on bytes, which allows for more precise control of bandwidth usage.

    Fairness: BFIFO also ensures fairness as it treats all packets equally, regardless of their source, destination, or content.

    No Prioritization: Similar to PFIFO, there's no inherent capability in BFIFO to prioritize certain types of traffic over others.

Examples:

Consider a public bus as an example of a BFIFO system. The bus has a maximum capacity of passengers it can carry (similar to the byte size of the queue). Even if there is a line of people waiting (packets), if the bus is full, new passengers cannot get on (packets are dropped).
Comparison: PFIFO vs. BFIFO

While both PFIFO and BFIFO are FIFO (First-In, First-Out) strategies and follow the basic queue logic, there are some differences:

    Queue Size: PFIFO considers the queue size in terms of the number of packets, while BFIFO calculates the queue size in bytes. This means that BFIFO takes into account the size of each packet, which can allow for more accurate control of bandwidth usage.

    Packet Dropping: In PFIFO, packets are dropped when the queue is full in terms of the number of packets. In BFIFO, packets are dropped when the byte size of the queue is exceeded, even if this means dropping a packet that is larger than the remaining space in the queue.

    Fairness: Both PFIFO and BFIFO are fair in terms of the order of packet transmission – the first in is the first out. However, in a situation where packets are of different sizes, PFIFO could lead to a situation where a large packet takes up a lot of resources but is treated the same as a smaller packet. On the other hand, BFIFO's byte-based approach can provide more balanced resource usage.

    Complexity: Both strategies are simple compared to more complex queuing strategies that prioritize certain types of traffic. However, BFIFO is slightly more complex than PFIFO because it requires tracking the total size of all packets in the queue.

Overall, the choice between PFIFO and BFIFO depends on the specific requirements of your network and the characteristics of your traffic.



Firewall and QoS Case Studies

    Creado por Usuario desconocido (emils), actualizado por última vez por Serhii T. el ago 09, 2024 1 min de lectura

        Building Advanced Firewall
        Port knocking
        DDoS Protection
        Connection rate
        Bruteforce prevention

    Sin etiquetas 



    Creado por Artūrs C., actualizado por última vez por GG el abr 26, 2024 9 min de lectura

    Overview
        Interface Lists
        Protect the Device
        Protect the Clients
        Masquerade Local Network
    RAW Filtering
        IPv4 Address Lists
        IPv4 RAW Rules
        IPv6 Address Lists
        IPv6 RAW Rules

Overview

From everything we have learned so far, let's try to build an advanced firewall. In this firewall building example, we will try to use as many firewall features as we can to illustrate how they work and when they should be used the right way.

Most of the filtering will be done in the RAW firewall, a regular firewall will contain just a basic rule set to accept established, related, and untracked connections as well as dropping everything else not coming from LAN to fully protect the router.
Interface Lists

Two interface lists will be used WAN and LAN for easier future management purposes. Interfaces connected to the global internet should be added to the WAN list, in this case, it is ether1!
/interface list
  add comment=defconf name=WAN
  add comment=defconf name=LAN
/interface list member
  add comment=defconf interface=bridge list=LAN
  add comment=defconf interface=ether1 list=WAN
Protect the Device

The main goal here is to allow access to the router only from LAN and drop everything else.

Notice that ICMP is accepted here as well, it is used to accept ICMP packets that passed RAW rules.
/ip firewall filter
  add action=accept chain=input comment="defconf: accept ICMP after RAW" protocol=icmp
  add action=accept chain=input comment="defconf: accept established,related,untracked" connection-state=established,related,untracked
  add action=drop chain=input comment="defconf: drop all not coming from LAN" in-interface-list=!LAN

IPv6 part is a bit more complicated, in addition, UDP traceroute, DHCPv6 client PD, and IPSec (IKE, AH, ESP) are accepted as per RFC recommendations.
/ipv6 firewall filter
add action=accept chain=input comment="defconf: accept ICMPv6 after RAW" protocol=icmpv6
add action=accept chain=input comment="defconf: accept established,related,untracked" connection-state=established,related,untracked
add action=accept chain=input comment="defconf: accept UDP traceroute" dst-port=33434-33534 protocol=udp 
add action=accept chain=input comment="defconf: accept DHCPv6-Client prefix delegation." dst-port=546 protocol=udp src-address=fe80::/10
add action=accept chain=input comment="defconf: accept IKE" dst-port=500,4500 protocol=udp
add action=accept chain=input comment="defconf: accept IPSec AH" protocol=ipsec-ah
add action=accept chain=input comment="defconf: accept IPSec ESP" protocol=ipsec-esp
add action=drop chain=input comment="defconf: drop all not coming from LAN" in-interface-list=!LAN

In certain setups where the DHCPv6 relay is used, the src address of the packets may not be from the link-local range. In that case, the src-address parameter of rule #4 must be removed or adjusted to accept the relay address.
Protect the Clients

Before the actual set of rules, let's create a necessary address-list that contains all IPv4/6 addresses that cannot be forwarded.

Notice that in this list multicast address range is added. It is there because in most cases multicast is not used. If you intend to use multicast forwarding, then this address list entry should be disabled.
/ip firewall address-list
  add address=0.0.0.0/8 comment="defconf: RFC6890" list=no_forward_ipv4
  add address=169.254.0.0/16 comment="defconf: RFC6890" list=no_forward_ipv4
  add address=224.0.0.0/4 comment="defconf: multicast" list=no_forward_ipv4
  add address=255.255.255.255/32 comment="defconf: RFC6890" list=no_forward_ipv4

In the same case for IPv6, if multicast forwarding is used then the multicast entry should be disabled from the address-list.
/ipv6 firewall address-list
  add address=fe80::/10  comment="defconf: RFC6890 Linked-Scoped Unicast" list=no_forward_ipv6
  add address=ff00::/8  comment="defconf: multicast" list=no_forward_ipv6

Forward chain will have a bit more rules than input:

    accept established, related and untracked connections;
    FastTrack established and related connections (currently only IPv4);
    drop invalid connections;
    drop bad forward IPs, since we cannot reliably determine in RAW chains which packets are forwarded
    drop connections initiated from the internet (from the WAN side which is not destination NAT`ed);
    drop bogon IPs that should not be forwarded.

We are dropping all non-dstnated IPv4 packets to protect direct attacks on the clients if the attacker knows the internal LAN network. Typically this rule would not be necessary since RAW filters will drop such packets, however, the rule is there for double security in case RAW rules are accidentally messed up.
/ip firewall filter
  add action=accept chain=forward comment="defconf: accept all that matches IPSec policy" ipsec-policy=in,ipsec disabled=yes
  add action=fasttrack-connection chain=forward comment="defconf: fasttrack" connection-state=established,related
  add action=accept chain=forward comment="defconf: accept established,related, untracked" connection-state=established,related,untracked
  add action=drop chain=forward comment="defconf: drop invalid" connection-state=invalid
  add action=drop chain=forward comment="defconf:  drop all from WAN not DSTNATed" connection-nat-state=!dstnat connection-state=new in-interface-list=WAN
  add action=drop chain=forward src-address-list=no_forward_ipv4 comment="defconf: drop bad forward IPs"
  add action=drop chain=forward dst-address-list=no_forward_ipv4 comment="defconf: drop bad forward IPs"

IPv6 forward chain is very similar, except that IPsec and HIP are accepted as per RFC recommendations, and ICMPv6 with hop-limit=1 is dropped.
/ipv6 firewall filter
add action=accept chain=forward comment="defconf: accept established,related,untracked" connection-state=established,related,untracked
add action=drop chain=forward comment="defconf: drop invalid" connection-state=invalid
add action=drop chain=forward src-address-list=no_forward_ipv6 comment="defconf: drop bad forward IPs"
add action=drop chain=forward dst-address-list=no_forward_ipv6 comment="defconf: drop bad forward IPs"
add action=drop chain=forward comment="defconf: rfc4890 drop hop-limit=1" hop-limit=equal:1 protocol=icmpv6
add action=accept chain=forward comment="defconf: accept ICMPv6 after RAW" protocol=icmpv6
add action=accept chain=forward comment="defconf: accept HIP" protocol=139
add action=accept chain=forward comment="defconf: accept IKE" protocol=udp dst-port=500,4500
add action=accept chain=forward comment="defconf: accept AH" protocol=ipsec-ah
add action=accept chain=forward comment="defconf: accept ESP" protocol=ipsec-esp
add action=accept chain=forward comment="defconf: accept all that matches IPSec policy" ipsec-policy=in,ipsec
add action=drop chain=forward comment="defconf: drop everything else not coming from LAN" in-interface-list=!LAN

Notice the IPsec policy matcher rules. It is very important that IPsec encapsulated traffic bypass fast-track. That is why as an illustration we have added a disabled rule to accept traffic matching IPsec policies. Whenever IPsec tunnels are used on the router this rule should be enabled. For IPv6 it is much more simple since it does not have fast-track support.

Another approach to solving the IPsec problem is to add RAW rules, we will talk about this method later in the RAW section
Masquerade Local Network

For local devices behind the router to be able to access the internet, local networks must be masqueraded. In most cases, it is advised to use src-nat instead of masquerade, however in this case when the WAN address is dynamic it is the only option.
/ip firewall nat
  add action=accept chain=srcnat comment="defconf: accept all that matches IPSec policy" ipsec-policy=out,ipsec disabled=yes
  add action=masquerade chain=srcnat comment="defconf: masquerade" out-interface-list=WAN

Notice the disabled policy matcher rule, the same as in firewall filters IPSec traffic must be excluded from being NATed (except in specific scenarios where IPsec policy is configured to match NAT`ed address). So whenever IPsec tunnels are used on the router this rule must be enabled. 
RAW Filtering
IPv4 Address Lists

Before setting RAW rules, let's create some address lists necessary for our filtering policy. RFC 6890 will be used as a reference.

First, address-list contains all IPv4 addresses that cannot be used as src/dst/forwarded, etc. (will be dropped immediately if such address is seen)
/ip firewall address-list
  add address=127.0.0.0/8 comment="defconf: RFC6890" list=bad_ipv4
  add address=192.0.0.0/24 comment="defconf: RFC6890" list=bad_ipv4
  add address=192.0.2.0/24 comment="defconf: RFC6890 documentation" list=bad_ipv4
  add address=198.51.100.0/24 comment="defconf: RFC6890 documentation" list=bad_ipv4
  add address=203.0.113.0/24 comment="defconf: RFC6890 documentation" list=bad_ipv4
  add address=240.0.0.0/4 comment="defconf: RFC6890 reserved" list=bad_ipv4

Another address list contains all IPv4 addresses that cannot be routed globally.
/ip firewall address-list
  add address=0.0.0.0/8 comment="defconf: RFC6890" list=not_global_ipv4
  add address=10.0.0.0/8 comment="defconf: RFC6890" list=not_global_ipv4
  add address=100.64.0.0/10 comment="defconf: RFC6890" list=not_global_ipv4
  add address=169.254.0.0/16 comment="defconf: RFC6890" list=not_global_ipv4
  add address=172.16.0.0/12 comment="defconf: RFC6890" list=not_global_ipv4
  add address=192.0.0.0/29 comment="defconf: RFC6890" list=not_global_ipv4
  add address=192.168.0.0/16 comment="defconf: RFC6890" list=not_global_ipv4
  add address=198.18.0.0/15 comment="defconf: RFC6890 benchmark" list=not_global_ipv4
  add address=255.255.255.255/32 comment="defconf: RFC6890" list=not_global_ipv4

And last two address lists for addresses that cannot be as destination or source address.
/ip firewall address-list
  add address=224.0.0.0/4 comment="defconf: multicast" list=bad_src_ipv4
  add address=255.255.255.255/32 comment="defconf: RFC6890" list=bad_src_ipv4
add address=0.0.0.0/8 comment="defconf: RFC6890" list=bad_dst_ipv4
  add address=224.0.0.0/4 comment="defconf: RFC6890" list=bad_dst_ipv4
IPv4 RAW Rules

Raw IPv4 rules will perform the following actions:

    add disabled "accept" rule - can be used to quickly disable RAW filtering without disabling all RAW rules;
    accept DHCP discovery - most of the DHCP packets are not seen by an IP firewall, but some of them are, so make sure that they are accepted;
    drop packets that use bogon IPs;
    drop from invalid SRC and DST IPs;
    drop globally unroutable IPs coming from WAN;
    drop packets with source-address not equal to 192.168.88.0/24 (default IP range) coming from LAN;
    drop packets coming from WAN to be forwarded to 192.168.88.0/24 network, this will protect from attacks if the attacker knows the internal network;
    drop bad ICMP, UDP, and TCP;
    accept everything else coming from WAN and LAN;
    drop everything else, to make sure that any newly added interface (like PPPoE connection to service provider) is protected against accidental misconfiguration.

/ip firewall raw
add action=accept chain=prerouting comment="defconf: enable for transparent firewall" disabled=yes
add action=accept chain=prerouting comment="defconf: accept DHCP discover" dst-address=255.255.255.255 dst-port=67 in-interface-list=LAN protocol=udp src-address=0.0.0.0 src-port=68
add action=drop chain=prerouting comment="defconf: drop bogon IP's" src-address-list=bad_ipv4
add action=drop chain=prerouting comment="defconf: drop bogon IP's" dst-address-list=bad_ipv4
add action=drop chain=prerouting comment="defconf: drop bogon IP's" src-address-list=bad_src_ipv4
add action=drop chain=prerouting comment="defconf: drop bogon IP's" dst-address-list=bad_dst_ipv4
add action=drop chain=prerouting comment="defconf: drop non global from WAN" src-address-list=not_global_ipv4 in-interface-list=WAN
add action=drop chain=prerouting comment="defconf: drop forward to local lan from WAN" in-interface-list=WAN dst-address=192.168.88.0/24
add action=drop chain=prerouting comment="defconf: drop local if not from default IP range" in-interface-list=LAN src-address=!192.168.88.0/24
add action=drop chain=prerouting comment="defconf: drop bad UDP" port=0 protocol=udp
add action=jump chain=prerouting comment="defconf: jump to ICMP chain" jump-target=icmp4 protocol=icmp
add action=jump chain=prerouting comment="defconf: jump to TCP chain" jump-target=bad_tcp protocol=tcp
add action=accept chain=prerouting comment="defconf: accept everything else from LAN" in-interface-list=LAN
add action=accept chain=prerouting comment="defconf: accept everything else from WAN" in-interface-list=WAN
add action=drop chain=prerouting comment="defconf: drop the rest"

Notice that we used some optional chains, the first TCP chain to drop TCP packets known to be invalid.
/ip firewall raw
add action=drop chain=bad_tcp comment="defconf: TCP flag filter" protocol=tcp tcp-flags=!fin,!syn,!rst,!ack
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=fin,syn
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=fin,rst
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=fin,!ack
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=fin,urg
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=syn,rst
add action=drop chain=bad_tcp comment=defconf protocol=tcp tcp-flags=rst,urg
add action=drop chain=bad_tcp comment="defconf: TCP port 0 drop" port=0 protocol=tcp

And another chain for ICMP. Note that if you want a very strict firewall then such strict ICMP filtering can be used, but in most cases, it is not necessary and simply adds more load on the router's CPU. ICMP rate limit in most cases is also unnecessary since the Linux kernel is already limiting ICMP packets to 100pps.
/ip firewall raw
add action=accept chain=icmp4 comment="defconf: echo reply" icmp-options=0:0 limit=5,10:packet protocol=icmp
add action=accept chain=icmp4 comment="defconf: net unreachable" icmp-options=3:0 protocol=icmp
add action=accept chain=icmp4 comment="defconf: host unreachable" icmp-options=3:1 protocol=icmp
add action=accept chain=icmp4 comment="defconf: protocol unreachable" icmp-options=3:2 protocol=icmp
add action=accept chain=icmp4 comment="defconf: port unreachable" icmp-options=3:3 protocol=icmp
add action=accept chain=icmp4 comment="defconf: fragmentation needed" icmp-options=3:4 protocol=icmp
add action=accept chain=icmp4 comment="defconf: echo" icmp-options=8:0 limit=5,10:packet protocol=icmp
add action=accept chain=icmp4 comment="defconf: time exceeded " icmp-options=11:0-255 protocol=icmp
add action=drop chain=icmp4 comment="defconf: drop other icmp" protocol=icmp
IPv6 Address Lists

List of IPv6 addresses that should be dropped instantly
/ipv6 firewall address-list
add address=::1/128 comment="defconf: RFC6890 lo" list=bad_ipv6
add address=::ffff:0:0/96 comment="defconf: RFC6890 IPv4 mapped" list=bad_ipv6
add address=2001::/23 comment="defconf: RFC6890" list=bad_ipv6
add address=2001:db8::/32 comment="defconf: RFC6890 documentation" list=bad_ipv6
add address=2001:10::/28 comment="defconf: RFC6890 orchid" list=bad_ipv6
add address=::/96 comment="defconf: ipv4 compat" list=bad_ipv6

List of IPv6 addresses that are not globally routable
/ipv6 firewall address-list
add address=100::/64 comment="defconf: RFC6890 Discard-only" list=not_global_ipv6
add address=2001::/32 comment="defconf: RFC6890 TEREDO" list=not_global_ipv6
add address=2001:2::/48 comment="defconf: RFC6890 Benchmark" list=not_global_ipv6
add address=fc00::/7 comment="defconf: RFC6890 Unique-Local" list=not_global_ipv6

List of addresses as an invalid destination address
/ipv6 firewall address-list add address=::/128 comment="defconf: unspecified" list=bad_dst_ipv6

List of addresses as an invalid source address
/ipv6 firewall address-list
  add address=::/128 comment="defconf: unspecified" list=bad_src_ipv6
  add address=ff00::/8  comment="defconf: multicast" list=bad_src_ipv6
IPv6 RAW Rules

Raw IPv6 rules will perform the following actions:

    add disabled accept rule - can be used to quickly disable RAW filtering without disabling all RAW rules;
    drop packets that use bogon IPs;
    drop from invalid SRC and DST IPs;
    drop globally unroutable IPs coming from WAN;
    drop bad ICMP;
    accept everything else coming from WAN and LAN;
    drop everything else, to make sure that any newly added interface (like PPPoE connection to service provider) is protected against accidental misconfiguration.

/ipv6 firewall raw
add action=accept chain=prerouting comment="defconf: enable for transparent firewall" disabled=yes
add action=accept chain=prerouting comment="defconf: RFC4291, section 2.7.1" src-address=::/128 dst-address=ff02:0:0:0:0:1:ff00::/104 icmp-options=135 protocol=icmpv6
add action=drop chain=prerouting comment="defconf: drop bogon IP's" src-address-list=bad_ipv6
add action=drop chain=prerouting comment="defconf: drop bogon IP's" dst-address-list=bad_ipv6
add action=drop chain=prerouting comment="defconf: drop packets with bad SRC ipv6" src-address-list=bad_src_ipv6
add action=drop chain=prerouting comment="defconf: drop packets with bad dst ipv6" dst-address-list=bad_dst_ipv6
add action=drop chain=prerouting comment="defconf: drop non global from WAN" src-address-list=not_global_ipv6 in-interface-list=WAN
add action=jump chain=prerouting comment="defconf: jump to ICMPv6 chain" jump-target=icmp6 protocol=icmpv6
add action=accept chain=prerouting comment="defconf: accept local multicast scope" dst-address=ff02::/16
add action=drop chain=prerouting comment="defconf: drop other multicast destinations" dst-address=ff00::/8
add action=accept chain=prerouting comment="defconf: accept everything else from WAN" in-interface-list=WAN
add action=accept chain=prerouting comment="defconf: accept everything else from LAN" in-interface-list=LAN
add action=drop chain=prerouting comment="defconf: drop the rest"

Notice that the optional ICMP chain was used. If you want a very strict firewall then such strict ICMP filtering can be used, but in most cases, it is not necessary and simply adds more load on the router's CPU. ICMP rate limit in most cases is also unnecessary since the Linux kernel is already limiting ICMP packets to 100pps
/ipv6 firewall raw
# Be aware that different operating systems originate packets with different default TTL values
add action=drop chain=icmp6 comment="defconf: rfc4890 drop ll if hop-limit!=255" dst-address=fe80::/10 hop-limit=not-equal:255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: dst unreachable" icmp-options=1:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: packet too big" icmp-options=2:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: limit exceeded" icmp-options=3:0-1 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: bad header" icmp-options=4:0-2 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: Mobile home agent address discovery" icmp-options=144:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: Mobile home agent address discovery" icmp-options=145:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: Mobile prefix solic" icmp-options=146:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: Mobile prefix advert" icmp-options=147:0-255 protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: echo request limit 5,10" icmp-options=128:0-255 limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: echo reply limit 5,10" icmp-options=129:0-255 limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 router solic limit 5,10 only LAN" hop-limit=equal:255 icmp-options=133:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 router advert limit 5,10 only LAN" hop-limit=equal:255 icmp-options=134:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 neighbor solic limit 5,10 only LAN" hop-limit=equal:255 icmp-options=135:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 neighbor advert limit 5,10 only LAN" hop-limit=equal:255 icmp-options=136:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 inverse ND solic limit 5,10 only LAN" hop-limit=equal:255 icmp-options=141:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=accept chain=icmp6 comment="defconf: rfc4890 inverse ND advert limit 5,10 only LAN" hop-limit=equal:255 icmp-options=142:0-255 in-interface-list=LAN limit=5,10:packet protocol=icmpv6
add action=drop chain=icmp6 comment="defconf: drop other icmp" protocol=icmpv6




    Creado por Normunds R., actualizado por última vez por Gļebs K. el sept 02, 2024 3 min de lectura

All available public IP addresses are constantly being port scanned by bots and services like shodan.io and anyone can use this information to perform brute-force attacks and execute any known exploits. Port knocking is a cost-effective way to defend against this by not exposing any ports and simply listening to connection attempts - if the correct sequence of port connection attempts is made, the client is considered safe and added to a list of secured address list that bypass the WAN firewall rules.
Setup example

We are assuming you have already set up a firewall that drops all connection attempts from the WAN port, so you will need to add additional rules before that.
First, create a firewall rule that listens on a given port and adds the connected source IP to an address list - this is the first knock.
/ip/firewall/filter add action=add-src-to-address-list address-list=888 address-list-timeout=30s chain=input dst-port=888 in-interface-list=WAN protocol=tcp

Then add a rule that does the same on another port, but only approves IPs that are already in the first list. You can repeat this step as many times as you like.
/ip/firewall/filter add action=add-src-to-address-list address-list=555 address-list-timeout=30s chain=input dst-port=555 in-interface-list=WAN protocol=tcp src-address-list=888

Finally, the last knock will be added to an IP list that is trusted and any input is accepted.
/ip/firewall/filter add action=add-src-to-address-list address-list=secured address-list-timeout=30m chain=input dst-port=222 in-interface-list=WAN protocol=tcp src-address-list=555
/ip/firewall/filter add action=accept chain=input in-interface-list=WAN src-address-list=secured
Knock to gain access

To access the board from WAN, a port-knocking client could be used, but a simple bash one-liner with nmap can do the job.
for x in 888,555,222; do nmap -p $x -Pn xx.xx.xx.xx; done
Blacklists

Unless you are using a lot of knocks, a simple port scan could accidentally trigger the correct ports in the correct order, so it is advisable to add a blacklist as well.

At the very top of your firewall stack add a drop rule for the blacklist.
/ip/firewall/filter add action=drop chain=input disabled=yes in-interface-list=WAN src-address-list=blacklist

Then add suspicious IPs to the blacklist.

Bad ports - ones that will never be used by a trusted user and hence have a high timeout penalty.
/ip/firewall/filter add action=add-src-to-address-list address-list=blacklist address-list-timeout=1000m chain=input disabled=yes dst-port=666 in-interface-list=WAN protocol=tcp

Ports that slow down the port scanning process significantly to the point where it is pointless, but will never lock out a real user for too long. This could include every single port apart from the 'knock' ports, the key is that the source IP is not already in the secure list and hence those ports can be used after a successful knock.
/ip/firewall/filter add action=add-src-to-address-list address-list=blacklist address-list-timeout=1m chain=input disabled=yes dst-port=21,22,23,8291,10000-60000 in-interface-list=WAN protocol=tcp src-address-list=!secured

Blacklist rules from this section are added disabled=yes in order to avoid locking out the user. Enable the filter rules, once the alternative access available or use <Safe Mode>
Use a passphrase for each knock

You could go even further by sending a passphrase with each knock.

Warning

Layer7 rules are very resource-intensive. Do not use it unless you know what you are doing.


For additional security layer see the Bruteforse prevention article: Bruteforce prevention 




    Creado por Artūrs C., actualizado por última vez por Normunds R. el oct 03, 2024 2 min de lectura

Introduction

A denial-of-service (DoS) or distributed denial-of-service (DDoS) attack is a malicious attempt to disrupt normal traffic of a targeted server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of Internet traffic. There are several types of DDoS attacks, for example, HTTP flood, SYN flood, DNS amplification, etc.

Protection against DDoS
Configuration lines

These rules are only an improvement for firewall, do not forget to properly secure your device.


/ip firewall address-list
add list=ddos-attackers
add list=ddos-targets
/ip firewall filter
add action=return chain=detect-ddos dst-limit=32,32,src-and-dst-addresses/10s
add action=add-dst-to-address-list address-list=ddos-targets address-list-timeout=10m chain=detect-ddos
add action=add-src-to-address-list address-list=ddos-attackers address-list-timeout=10m chain=detect-ddos
/ip firewall raw
add action=drop chain=prerouting dst-address-list=ddos-targets src-address-list=ddos-attackers
Configuration Explained

First, we will send every new connection to the specific firewall chain where we will detect DDoS:
/ip/firewall/filter/add chain=forward connection-state=new action=jump jump-target=detect-ddos

In the newly created chain, we will add the following rule with the "dst-limit" parameter. This parameter is written in the following format: dst-limit=count[/time],burst,mode[/expire]. We will match 32 packets with 32 packet burst based on destination and source address flow, which renews every 10 seconds. The rule will work until a given rate is exceeded.
/ip/firewall/filter/add chain=detect-ddos dst-limit=32,32,src-and-dst-addresses/10s action=return

So far all the legitimate traffic should go through the "action=return", but in the case of DoS/DDoS "dst-limit" buffer will be fulfilled and a rule will not "catch" any new traffic. Here come the next rules, which will deal with the attack. Let`s start with creating a list for attackers and victims which we will drop:
ip/firewall/address-list/add list=ddos-attackers
ip/firewall/address-list/add list=ddos-targets
ip/firewall/raw/add chain=prerouting action=drop src-address-list=ddos-attackers dst-address-list=ddos-targets

With the firewall filter section, we will add attackers in the "DDoS-attackers" and victims in list "ddos-targets" list:
/ip/firewall/filter/
add action=add-dst-to-address-list address-list=ddos-targets address-list-timeout=10m chain=detect-ddos
add action=add-src-to-address-list address-list=ddos-attackers address-list-timeout=10m chain=detect-ddos
SYN Attack
SYN Flood

An SYN flood is a form of DoS attack in which an attacker sends a succession of SYN requests to a target's system in an attempt to consume enough server resources to make the system unresponsive to legitimate traffic. Fortunately, in RouterOS we have a specific feature for such an attack:
/ip/settings/set tcp-syncookies=yes

The feature works by sending back ACK packets that contain a little cryptographic hash, which the responding client will echo back with as part of its SYN-ACK packet. If the kernel doesn't see this "cookie" in the reply packet, it will assume the connection is bogus and drop it. 
SYN-ACK Flood

An SYN-ACK flood is an attack method that involves sending a target server spoofed SYN-ACK packet at a high rate. The server requires significant resources to process such packets out-of-order (not in accordance with the normal SYN, SYN-ACK, ACK TCP three-way handshake mechanism), it can become so busy handling the attack traffic, that it cannot handle legitimate traffic and hence the attackers achieve a DoS/DDoS condition. In RouterOS, we can configure similar rules from the previously mentioned example, but more specifically for SYN-ACK flood:
/ip/firewall/filter add action=return chain=detect-ddos dst-limit=32,32,src-and-dst-addresses/10s protocol=tcp tcp-flags=syn,ack




    Creado por Artūrs C., actualizado por última vez por GG el abr 26, 2024 3 min de lectura

    Introduction
    Theory
        Rule Example
    Application Example - Traffic Prioritization
        Quick Start for Impatient
            Explanation
            IP Firewall mangle
            Queue

Introduction

Connection Rate is a firewall matcher that allows capturing traffic based on the present speed of the connection.
Theory

Each entry in the connection tracking table represents bidirectional communication. Every time a packet gets associated with a particular entry, the packet size value (including the IP header) is added to the "connection-bytes" value for this entry. (in other words "connection-bytes" includes both - upload and download).

Connection Rate calculates the speed of connection based on the change of "connection-bytes". The connection rate is recalculated every second and does not have any averages.

Both options "connection-bytes" and "connection-rate" work only with TCP and UDP traffic. (you need to specify a protocol to activate these options). In the "connection-rate" you can specify a range of speed that you like to capture:
ConnectionRate ::= [!]From-To
  From,To ::= 0..4294967295    (integer number)
Rule Example

These rules will capture TCP/UDP traffic that was going through the router when the connection speed was below 100kbps:
/ip firewall filter
add action=accept chain=forward connection-rate=0-100k protocol=tcp
add action=accept chain=forward connection-rate=0-100k protocol=udp


Application Example - Traffic Prioritization

Connection-rate can be used in various ways, that still need to be realized, but the most common setup will be to detect and set lower priorities to the "heavy connections" (connections that maintain a fast rate for long periods (such as P2P, HTTP, FTP downloads). By doing this you can prioritize all other traffic that usually includes VoIP and HTTP browsing and online gaming.

The method described in this example can be used together with other ways to detect and prioritize traffic. As the connection-rate option does not have any averages we need to determine what will be the margin that identifies "heavy connections". If we assume that a normal HTTP browsing connection is less than 500kB (4Mb) long and VoIP requires no more than 200kbps speed, then every connection that after the first 500kB still has more than 200kbps speed can be assumed as "heavy".

(You might have different "connection-bytes" for HTTP browsing and different "connection-rate" for VoIP in your network - so, please, do your own research before applying this example)

For this example, let's assume that we have a 6Mbps upload and download connection to ISP.
Quick Start for Impatient
/ip firewall mangle
add chain=forward action=mark-connection connection-mark=!heavy_traffic_conn new-connection-mark=all_conn
add chain=forward action=mark-connection connection-bytes=500000-0 connection-mark=all_conn connection-rate=200k-100M new-connection-mark=heavy_traffic_conn protocol=tcp
add chain=forward action=mark-connection connection-bytes=500000-0 connection-mark=all_conn connection-rate=200k-100M new-connection-mark=heavy_traffic_conn protocol=udp
add chain=forward action=mark-packet connection-mark=heavy_traffic_conn new-packet-mark=heavy_traffic passthrough=no
add chain=forward action=mark-packet connection-mark=all_conn new-packet-mark=other_traffic passthrough=no

/queue tree
add name=upload parent=public max-limit=6M
add name=other_upload parent=upload limit-at=4M max-limit=6M packet-mark=other_traffic priority=1
add name=heavy_upload parent=upload limit-at=2M max-limit=6M packet-mark=heavy_traffic priority=8
add name=download parent=local max-limit=6M
add name=other_download parent=download limit-at=4M max-limit=6M packet-mark=other_traffic priority=1
add name=heavy_download parent=download limit-at=2M max-limit=6M packet-mark=heavy_traffic priority=8


Explanation

In mangle, we need to separate all connections into two groups, and then mark packets from their 2 groups. As we are talking about client traffic most logical place for marking would be the mangle chain forward.

Keep in mind that as soon as a "heavy" connection will have lower priority and queue will hit max-limit - heavy connection will drop speed, and connection-rate will be lower. This will result in a change to a higher priority and the connection will be able to get more traffic for a short while, when again connection-rate will rise and that again will result in a change to lower priority). To avoid this we must make sure that once detected "heavy connections" will remain marked as "heavy connections" for all times.
IP Firewall mangle

This rule will ensure that that "heavy" connections will remain heavy". and mark the rest of the connections with the default connection mark:
/ip firewall mangle
add chain=forward action=mark-connection connection-mark=!heavy_traffic_conn new-connection-mark=all_conn


These two rules will mark all heavy connections based on our standards, that every connection that after the first 500kB still has more than 200kbps speed can be assumed as "heavy":
add chain=forward action=mark-connection connection-bytes=500000-0 \
    connection-mark=all_conn connection-rate=200k-100M new-connection-mark=heavy_traffic_conn protocol=tcp
add chain=forward action=mark-connection connection-bytes=500000-0 \
    connection-mark=all_conn connection-rate=200k-100M new-connection-mark=heavy_traffic_conn protocol=udp

The last two rules in mangle will simply mark all traffic from corresponding connections:
add chain=forward action=mark-packet connection-mark=heavy_traffic_conn new-packet-mark=heavy_traffic passthrough=no
add chain=forward action=mark-packet connection-mark=all_conn new-packet-mark=other_traffic passthrough=no
Queue

This is a simple queue tree that is placed on the Interface HTB - "public" is an interface where your ISP is connected, and "local" is where are your clients. If you have more than 1 "public" or more than 1 "local" you will need to mangle upload and download separately and place the queue tree in global-out:
/queue tree
add name=upload parent=public max-limit=6M
add name=other_upload parent=upload limit-at=4M max-limit=6M packet-mark=other_traffic priority=1
add name=heavy_upload parent=upload limit-at=2M max-limit=6M packet-mark=heavy_traffic priority=8
add name=download parent=local max-limit=6M
add name=other_download parent=download limit-at=4M max-limit=6M packet-mark=other_traffic priority=1
add name=heavy_download parent=download limit-at=2M max-limit=6M packet-mark=heavy_traffic priority=8


Bruteforce prevention

    Creado por Gļebs K., actualizado por última vez por Usuario desconocido (elvijsi) el nov 25, 2024 1 min de lectura

Here is an example of how to defend against bruteforce attacks on an SSH port. Please note, that ssh allows 3 login attempts per connection, and the address lists are not cleared upon a successful login, so it is possible to blacklist yourself accidentally.

/ip firewall filter
add action=add-src-to-address-list address-list=bruteforce_blacklist address-list-timeout=1d chain=input comment=Blacklist connection-state=new dst-port=22 protocol=tcp src-address-list=connection3
add action=add-src-to-address-list address-list=connection3 address-list-timeout=1h chain=input comment="Third attempt" connection-state=new dst-port=22 protocol=tcp src-address-list=connection2
add action=add-src-to-address-list address-list=connection2 address-list-timeout=15m chain=input comment="Second attempt" connection-state=new dst-port=22 protocol=tcp src-address-list=connection1
add action=add-src-to-address-list address-list=connection1 address-list-timeout=5m chain=input comment="First attempt" connection-state=new dst-port=22 protocol=tcp
add action=accept chain=input dst-port=22 protocol=tcp src-address-list=!bruteforce_blacklist

If the timeouts were kept at 1min for all three lists - connection1/2/3 - then someone could perform 9 guesses every minute, with the above structure they can do a maximum of 3 guesses per 5min.

Address list naming is following the naming of the Port knocking article. Similar naming scheme is used, trusted address list is named as "secured".






    Creado por Usuario desconocido (emils), actualizado por última vez por GG el may 03, 2024 2 min de lectura

    Summary
    Property Description
    Devices
    Application example

Summary

Sub-menu: /ip kid-control

"Kid control" is a parental control feature to limit internet connectivity for LAN devices.
Property Description

In this menu, it is possible to create a profile for each Kid and restrict internet accessibility.
name (string)	Name of the Kid's profile
mon,tue,wed,thu,fri,sat,sun (time)	Each day of the week. Time of day, when internet access should be allowed
disabled (yes | no)	Whether restrictions are enabled
rate-limit (string)	The maximum available data rate for flow
tur-mon,tur-tue,tur-wed,tur-thu,tur-fri,tur-sat,tur-sun (time)	Time unlimited rate. Time of day, when internet access should be unlimited

Time unlimited rate parameters have higher priority than rate-limit parameter.
Devices

Sub-menu: /ip kid-control device

This sub-menu contains information if there are multiple connected devices to the internet (phone, tablet, gaming console, tv etc.). The device is identified by the MAC address that is retrieved from the ARP table. The appropriate IP address is taken from there.
name (string)	Name of the device
mac-address (string)	Devices mac-address
user (string)	To which profile append the device
reset-counters ([id, name])	Reset bytes-up and bytes-down counters.
Application example

With the following example we will restrict access for Peter's mobile phone:

    Disabled internet access on Monday, Wednesday and Friday
    Allowed unlimited internet access on:
        Tuesday
        Thursday from 11:00-22:00
        Sunday 15:00-22:00
    Limited bandwidth to 3Mbps for Peter's mobile phone on Saturday from 18:30-21:00

[admin@MikroTik] > /ip kid-control add name=Peter mon="" tur-tue="00:00-24h" wed="" tur-thu="11:00-22:00" fri="" sat="18:30-22:00" tur-sun="15h-21h" rate-limit=3M
[admin@MikroTik] > /ip kid-control device add name=Mobile-phone user=Peter mac-address=FF:FF:FF:ED:83:63

Internet access limitation is implemented by adding dynamic firewall filter rules or simple queue rules. Here are example firewall filter rules:
[admin@MikroTik] > /ip firewall filter print

1  D ;;; Mobile-phone, kid-control
      chain=forward action=reject src-address=192.168.88.254 

2  D ;;; Mobile-phone, kid-control
      chain=forward action=reject dst-address=192.168.88.254

Dynamically created simple queue:
[admin@MikroTik] > /queue simple print
Flags: X - disabled, I - invalid, D - dynamic 

 1  D ;;; Mobile-phone, kid-control
      name="queue1" target=192.168.88.254/32 parent=none packet-marks="" priority=8/8 queue=default-small/default-small limit-at=3M/3M max-limit=3M/3M burst-limit=0/0 
      burst-threshold=0/0 burst-time=0s/0s bucket-size=0.1/0.1  

It is possible to monitor how much data is used by the specific device:
[admin@MikroTik] > /ip kid-control device print stats

Flags: X - disabled, D - dynamic, B - blocked, L - limited, I - inactive 
 #    NAME                                                                                                                 IDLE-TIME    RATE-DOWN   RATE-UP   BYTES-DOWN     BYTES-UP
 1 BI Mobile-phone                                                                                                               30s         0bps      0bps    3438.1KiB       8.9KiB

It is also possible to pause Internet access for the created kids, it will restrict all access until resume is used, which will continue with configured settings:
[admin@MikroTik] > /ip kid-control pause Peter 
[admin@MikroTik] > /ip kid-control print
Flags: X - disabled, P - paused, B - blocked, L - rate-limited 
 #   NAME                                                                                                                    SUN      MON      TUE      WED      THU      FRI      SAT     
 0 PB Peter                                                                                                                 15h-21h                             11h-22h          18:30h-22h  




    Creado por GG, actualizado por última vez el sept 18, 2024 3 min de lectura

Introduction

The MikroTik RouterOS supports Universal Plug and Play architecture for transparent peer-to-peer network connectivity of personal computers and network-enabled intelligent devices or appliances.

UPnP enables data communication between any two devices under the command of any control device on the network. Universal Plug and Play is completely independent of any particular physical medium. It supports networking with automatic discovery without any initial configuration, whereby a device can dynamically join a network. DHCP and DNS servers are optional and will be used if available on the network. UPnP implements a simple yet powerful NAT traversal solution, that enables the client to get full two-way peer-to-peer network support from behind the NAT.

There are two interface types for UPnP: internal (the one local clients are connected to) and external (the one the Internet is connected to). A router may only have one active external interface with a 'public' IP address on it, and as many internal interfaces as needed, all with source-NATted 'internal' IP addresses. The protocol works by creating dynamic NAT entries.

UPnP internal interface can create NAT mapping for any subnet, not just the subnet present on the internal interface, so caution must be used when setting internal interfaces.

The UPnP protocol is used for many modern applications, like most DirectX games, as well as for various Windows Messenger features like remote assistance, application sharing, file transfer, voice, and video from behind a firewall.
Configuration
General properties
/ip upnp
allow-disable-external-interface (yes | no ; Default: yes)	whether or not the users are allowed to disable the router's external interface. This functionality (for users to be able to turn the router's external interface off without any authentication procedure) is required by the standard, but as it is sometimes not expected or unwanted in UPnP deployments which the standard was not designed for (it was designed mostly for home users to establish their own local networks), you can disable this behavior
enabled (yes | no ; Default: no)	Enable UPnP service
show-dummy-rule (yes | no ; Default: yes)	Enable a workaround for some broken implementations, which are handling the absence of UPnP rules incorrectly (for example, popping up error messages). This option will instruct the server to install a dummy (meaningless) UPnP rule that can be observed by the clients, which refuse to work correctly otherwise

If you do not disable the allow-disable-external-interface, any user from the local network will be able (without any authentication procedures) to disable the router's external interface
UPnP Interfaces
/ip upnp interfaces


interface (string; Default: )	Interface name on which uPnP will be running
type (external | internal; Default: no)	UPnP interface type:

    external - the interface a global IP address is assigned to
    internal - router's local interface the clients are connected to

forced-external-ip (Ip; Default: )	Allow specifying what public IP to use if the external interface has more than one IP available.

In more complex setups with VLANs, where the VLAN interface is considered as the LAN interface, the VLAN interface itself should be specified as the internal interface for UPnP to work properly.
Configuration Example

We have masquerading already enabled on our router:
[admin@MikroTik] ip upnp> /ip firewall src-nat print
Flags: X - disabled, I - invalid, D - dynamic
  0   chain=srcnat action=masquerade out-interface=ether1
[admin@MikroTik] ip upnp>

To enable the UPnP feature:
[admin@MikroTik] ip upnp> set enable=yes
[admin@MikroTik] ip upnp> print
                             enabled: yes
    allow-disable-external-interface: yes
                     show-dummy-rule: yes
[admin@MikroTik] ip upnp>

Now, all we have to do is to add interfaces:
[admin@MikroTik] ip upnp interfaces> add interface=ether1 type=external
[admin@MikroTik] ip upnp interfaces> add interface=ether2 type=internal
[admin@MikroTik] ip upnp interfaces> print
Flags: X - disabled
  #   INTERFACE TYPE
  0 X ether1    external
  1 X ether2    internal

[admin@MikroTik] ip upnp interfaces> enable 0,1

Now once the client from the internal interface side sends UPnP request, dynamic NAT rules will be created on the router, example rules could look something similar to these:
[admin@MikroTik] > ip firewall nat print 
Flags: X - disabled, I - invalid, D - dynamic 

0 chain=srcnat action=masquerade out-interface=ether1

1 D ;;; upnp 192.168.88.10: ApplicationX
chain=dstnat action=dst-nat to-addresses=192.168.88.10 to-ports=55000 protocol=tcp 
dst-address=10.0.0.1 in-interface=ether1 dst-port=55000

2 D ;;; upnp 192.168.88.10: ApplicationX
chain=dstnat action=dst-nat to-addresses=192.168.88.10 to-ports=55000 protocol=udp 
dst-address=10.0.0.1 in-interface=ether1 dst-port=55000

    Sin etiquetas 





    Creado por GG, actualizado por última vez el sept 18, 2024 2 min de lectura

Introduction

NAT Port Mapping Protocol (NAT-PMP) is a protocol used for transparent peer-to-peer network connectivity of personal computers and network-enabled intelligent devices or appliances. 

Protocol operates by retrieving the external IPv4 address of a NAT gateway, thus allowing a client to make its external IPv4 address and port known to peers who may wish to communicate with it by creating dynamic NAT rules.

NAT-PMP uses UDP port number 5350 - on the client, and 5351 on the server side.

There are two interface types for PMP: internal (the one local clients are connected to) and external (the one the Internet is connected to).A router may only have one active external interface with a 'public' IP address on it

A router can have only one active external interface with a 'public' IP address on it. NAT-PMP internal interface can create NAT mapping for any subnet, not just the subnet present on the internal interface, so caution must be used when setting internal interfaces.

For more details on NAT PMP see RFC 6886

NAT-PMP configuration is accessible from /ip nat-pmp menu.
Configuration Example

Let's consider that we already have this basic home setup illustrated above.

Before enabling PMP-NAT we need to masquerade outgoing LAN packets.
/ip firewall nat
add action=masquerade chain=srcnat out-interface=ether1

Now we can enable PMP and add internal, external interfaces:
/ip nat-pmp set enable=yes
/ip nat-pmp interfaces> add interface=ether1 type=external disabled=no
/ip nat-pmp interfaces> add interface=ether2 type=internal disabled=no

When the client from the internal interface side sends PMP request, dynamic NAT rules are created on the router:
[admin@MikroTik] > ip firewall nat print 
Flags: X - disabled, I - invalid, D - dynamic 

0 chain=srcnat action=masquerade out-interface=ether1

1 D ;;; nat-pmp 192.168.88.10: ApplicationX
chain=dstnat action=dst-nat to-addresses=192.168.88.10 to-ports=55000 protocol=tcp 
dst-address=10.0.0.1 in-interface=ether1 dst-port=55000

2 D ;;; nat-pmp 192.168.88.10: ApplicationX
chain=dstnat action=dst-nat to-addresses=192.168.88.10 to-ports=55000 protocol=udp 
dst-address=10.0.0.1 in-interface=ether1 dst-port=55000

Properties
General properties

Available from /ip nat-pmp menu.
enabled (yes | no ; Default: no)	Enable NAT-PMP service
NAT PMP Interfaces

Available from /ip nat-pmp interfaces menu.


interface (string; Default: )	Interface name on which PMP will be running on
type (external | internal; Default: no)	PMP interface type:

    external - the interface a global IP address is assigned to
    internal - router's local interface the clients are connected to

forced-ip (Ip; Default: )	Allow specifying what public IP to use if the external interface has more than one IP available.

In more complex setups with VLANs, where the VLAN interface is part of the LAN, for PMP to work properly, the VLAN interface itself should be specified as the internal interface.




    Creado por Māris B., actualizado por última vez el may 24, 2024 1 min de lectura

Services

This section lists protocols and ports used by various MikroTik RouterOS services. It helps you to determine why your MikroTik router listens to certain ports, and what you need to block/allow in case you want to prevent or grant access to certain services.

The default services are:
telnet	Telnet service
ftp	FTP service
www	Webfig HTTP service
ssh	SSH service
www-ssl	Webfig HTTPS service
api	API service
winbox	Responsible for Winbox tool access, as well as Tik-App smartphone app and Dude probe
api-ssl	API over SSL service
Properties

Note that it is not possible to add new services, only existing service modifications are allowed.
address (IP address/netmask | IPv6/0..128; Default: )	List of IP/IPv6 prefixes from which the service is accessible.
certificate (name; default: none)	The name of the certificate used by a particular service. Applicable only for services that depend on certificates (www-ssl, api-ssl)
name (name; default: none)	Service name
port (integer: 1..65535; Default: )	The port particular service listens on

To restrict Winbox service access to the device only from the 192.168.88.0/24 subnet, we have to configure the following:
[admin@MikroTik] > ip service set [find name~"winbox"] address=192.168.88.0/24
[admin@MikroTik] > ip service print 
Flags: X - disabled, I - invalid 
# NAME PORT ADDRESS CERTIFICATE 
0 telnet 23
1 XI ftp 21
2 XI www 80
3 ssh 22
4 XI www-ssl 443 none 
5 XI api 8728
6 winbox 8291 192.168.88.0/24 
7 XI api-ssl 8729 none

We recommend disabling unused services.